{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of Attack\n",
    "- Understand the data, size of the data (column/row), size of missing data, columns to drop\n",
    "- Data Cleaning\n",
    "    - data outliers\n",
    "    - correct the data\n",
    "    - fillna()\n",
    "- EDA, look at numarical and object(string) data seperatly, to determine\n",
    "    - normalization/scale the data\n",
    "    - determine potential feature engineering approaches\n",
    "- Feature Engineering according to the findings\n",
    "- Def function for data preprocessing\n",
    "- Run Models\n",
    "- Voting\n",
    "- Output the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas version: 1.0.1\n",
      "matplotlib version: 3.1.3\n",
      "NumPy version: 1.18.1\n",
      "SciPy version: 1.4.1\n",
      "IPython version: 7.12.0\n",
      "scikit-learn version: 0.22.1\n",
      "seaborn version: 0.10.0\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# This block is from https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "#load packages\n",
    "import sys #access to system parameters https://docs.python.org/3/library/sys.html\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "import pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import matplotlib #collection of functions for scientific and publication-ready visualization\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np #foundational package for scientific computing\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "import scipy as sp #collection of functions for scientific computing and advance mathematics\n",
    "print(\"SciPy version: {}\". format(sp.__version__)) \n",
    "\n",
    "import IPython\n",
    "from IPython import display #pretty printing of dataframes in Jupyter notebook\n",
    "print(\"IPython version: {}\". format(IPython.__version__)) \n",
    "\n",
    "import sklearn #collection of machine learning algorithms\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "import seaborn as sns #collection of functions for data visualization\n",
    "print(\"seaborn version: {}\". format(sns.__version__))\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder #OneHot Encoder\n",
    "\n",
    "\n",
    "#misc libraries\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is from https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "\n",
    "#Common Model Algorithms\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "#from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "#Configure Visualization Defaults\n",
    "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
    "%matplotlib inline\n",
    "#mpl.style.use('ggplot')\n",
    "#sns.set_style('white')\n",
    "#pylab.rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train_raw = pd.read_csv('data/train.csv')\n",
    "test_raw = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.info()\n",
    "train_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- This data consist of numaric, string (object), and the Ticket column contains a combination of string and numarical values\n",
    "- We have a total 12 columns\n",
    "- Age has some missing data, marjority of Cabin data are missing, two missing values in Embarked\n",
    "- judging from std, min and max, we can conclude that data in PassengerId are pretty evenly distributed\n",
    "\n",
    "#### Plan of action\n",
    "- Split the data by dtype (string vs numeric) for targeted actions\n",
    "- Need to handle missing data in Age, Cabin (drop, due to the large amount), and Embarked\n",
    "- Consider dropping PassengerId due to the lack of trend in the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let split the data for more targeted handling\n",
    "txt_cols = [cname for cname in train_raw.columns if train_raw[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "num_cols = [cname for cname in train_raw.columns if train_raw[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "txt_data = train_raw[txt_cols].copy()\n",
    "num_data = train_raw[num_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to make sure we didn't accidentally drop any cols\n",
    "txt_data.shape[1] + num_data.shape[1] == train_raw.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Age          714 non-null    float64\n",
      " 4   SibSp        891 non-null    int64  \n",
      " 5   Parch        891 non-null    int64  \n",
      " 6   Fare         891 non-null    float64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 48.9 KB\n"
     ]
    }
   ],
   "source": [
    "#now let us look at the numaric cols\n",
    "num_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.87%\n"
     ]
    }
   ],
   "source": [
    "age_missing_per = num_data.Age.isnull().sum()/len(num_data.Age)\n",
    "print(\"{:.2%}\".format(age_missing_per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have close to 20% of Age data that are missing from the dataset, let's think of a cleverer way to fill in the gaps\n",
    "- the idea is to find corrolating features with Age, create a lookup table to impute missing Age values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e1c0ed3bc8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to find corrolating features\n",
    "sns.heatmap(train_raw.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-0-0    324\n",
       "1-0-0    109\n",
       "2-0-0    104\n",
       "1-1-0     51\n",
       "3-1-0     46\n",
       "2-1-0     26\n",
       "3-1-1     25\n",
       "2-1-1     20\n",
       "1-0-1     19\n",
       "1-1-1     12\n",
       "3-0-2     12\n",
       "3-0-1     11\n",
       "3-2-0     10\n",
       "1-0-2      9\n",
       "3-4-2      9\n",
       "3-4-1      9\n",
       "2-1-2      8\n",
       "2-0-2      8\n",
       "2-0-1      8\n",
       "3-3-1      7\n",
       "3-8-2      7\n",
       "1-1-2      7\n",
       "3-5-2      5\n",
       "3-1-2      4\n",
       "3-3-2      4\n",
       "2-2-1      4\n",
       "1-3-2      3\n",
       "3-2-1      3\n",
       "2-2-0      3\n",
       "1-2-0      3\n",
       "3-1-5      3\n",
       "3-0-5      2\n",
       "3-2-2      2\n",
       "1-2-2      2\n",
       "3-1-4      2\n",
       "3-1-3      2\n",
       "3-0-3      1\n",
       "2-2-3      1\n",
       "2-1-3      1\n",
       "3-1-6      1\n",
       "3-0-4      1\n",
       "1-1-4      1\n",
       "2-3-0      1\n",
       "3-3-0      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we see that Pclass, Sibsp, Parch are highly corrolated with Age\n",
    "Pclass_Sibsp_Parch = train_raw['Pclass'].apply(str)+'-'+train_raw['SibSp'].apply(str)+'-'+train_raw['Parch'].apply(str)\n",
    "Pclass_Sibsp_Parch.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "300, 100, 200 have the most values, let's create a look up table with 4 classes, 300, 100, 200 and others respectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = { 'Pclass_Sibsp_Parch': Pclass_Sibsp_Parch, 'Age': train_raw.Age } \n",
    "age_psp = pd.DataFrame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_classes = ['3-0-0', '1-0-0', '2-0-0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other    354\n",
       "3-0-0    324\n",
       "1-0-0    109\n",
       "2-0-0    104\n",
       "Name: Pclass_Sibsp_Parch, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_psp['Pclass_Sibsp_Parch'] = age_psp['Pclass_Sibsp_Parch'].apply(lambda x: x if x in age_classes else 'other')\n",
    "age_psp['Pclass_Sibsp_Parch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_lookup= age_psp.groupby(\"Pclass_Sibsp_Parch\", as_index=False).mean()\n",
    "age_lookup = age_lookup.set_index('Pclass_Sibsp_Parch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data['temp_psp'] = age_psp['Pclass_Sibsp_Parch']\n",
    "num_data['temp_age_cat_mean'] = num_data['temp_psp']\n",
    "num_data['temp_age_cat_mean'] = num_data['temp_age_cat_mean'].apply(lambda x: age_lookup['Age'][x])\n",
    "num_data['Age'] = num_data['Age'].fillna(num_data['temp_age_cat_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = num_data.drop('temp_psp', axis=1)\n",
    "num_data = num_data.drop('temp_age_cat_mean', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at 'PassengerId' to decide if we should drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e1c13580c8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAN60lEQVR4nO3dX4xc5XnH8e9TbwBDCjaQrlwbdY1ikSCsJLCiEKpqDamaQBS4IBIRSt3K1d7kj5NYSkx7EfWiEkglhKIqqhVaWZUVkzioRlRNihxbVS/i1k5QDBhqB1wwEBuEMRVCSlZ9ejHHMLOzeIfdHY+f2e9HWu2c97xn9pnHx789++4cOzITSVI9vzXoAiRJc2OAS1JRBrgkFWWAS1JRBrgkFTVyJr/YpZdemmNjY3M69s033+SCCy5Y2IIKsx+d7Ec3e9Kpcj/279//amZ+YPr4GQ3wsbEx9u3bN6dj9+zZw8TExMIWVJj96GQ/utmTTpX7ERH/M9O4SyiSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVNQZvRNTkgZpbPO/DOTrHrn7lr48r1fgklRUmSvwAy+e5E8H9N3zbLRp7ZT9aGM/utmTTpvWTlEo8nriFbgkFWWAS1JRBrgkFWWAS1JRBrgkFWWAS1JRBrgkFWWAS1JRBrgkFWWAS1JRBrgkFWWAS1JRBrgkFWWAS1JRBrgkFWWAS1JRBrgkFdVTgEfEVyPiyYh4IiK+FxHnRcTqiNgbEYci4qGIOKffxUqS3jFrgEfESuDLwHhmXgUsAe4A7gHuy8w1wAlgQz8LlSR16nUJZQRYGhEjwPnAy8CNwI5m/1bgtoUvT5L0biIzZ58UsRH4a+At4N+AjcBPM/ODzf7LgH9trtCnHzsJTAKMjo5es3379jkVevy1kxx7a06HDqXRpdiPNvajmz3pNMh+rF150byOX7du3f7MHJ8+Put/0RwRy4FbgdXA68APgE/NMHXG7wSZuQXYAjA+Pp4TExO9V93mgW07uffAcP2P0vOxae2U/WhjP7rZk06D7MeROyf68ry9LKF8AnguM1/JzN8ADwMfB5Y1SyoAq4CX+lKhJGlGvQT488B1EXF+RARwE/AUsBu4vZmzHtjZnxIlSTOZNcAzcy+tX1b+DDjQHLMF+AbwtYg4DFwCPNjHOiVJ0/S0IJSZ3wS+OW34WeDaBa9IktQT78SUpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKJ6CvCIWBYROyLi6Yg4GBHXR8TFEfFYRBxqPi/vd7GSpHf0egV+P/CjzPwQ8BHgILAZ2JWZa4BdzbYk6QyZNcAj4kLgD4EHATLz15n5OnArsLWZthW4rV9FSpK6RWaefkLER4EtwFO0rr73AxuBFzNzWdu8E5nZtYwSEZPAJMDo6Og127dvn1Ohx187ybG35nToUBpdiv1oYz+62ZNOg+zH2pUXzev4devW7c/M8enjvQT4OPBT4IbM3BsR9wNvAF/qJcDbjY+P5759++b0Ah7YtpN7D4zM6dhhtGntlP1oYz+62ZNOg+zHkbtvmdfxETFjgPeyBn4UOJqZe5vtHcDVwLGIWNE8+Qrg+LwqlCS9J7MGeGb+CnghIq5ohm6itZzyCLC+GVsP7OxLhZKkGfX688SXgG0RcQ7wLPBntML/+xGxAXge+Gx/SpQkzaSnAM/Mx4Gu9RdaV+OSpAHwTkxJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKqrnAI+IJRHx84h4tNleHRF7I+JQRDwUEef0r0xJ0nTv5Qp8I3Cwbfse4L7MXAOcADYsZGGSpNPrKcAjYhVwC/DdZjuAG4EdzZStwG39KFCSNLORHud9G/g68NvN9iXA65k51WwfBVbOdGBETAKTAKOjo+zZs2dOhY4uhU1rp2afuEjYj072o5s96TTIfsw192Yza4BHxKeB45m5PyImTg3PMDVnOj4ztwBbAMbHx3NiYmKmabN6YNtO7j3Q6/eb4bdp7ZT9aGM/utmTToPsx5E7J/ryvL28mhuAz0TEzcB5wIW0rsiXRcRIcxW+CnipLxVKkmY06xp4Zt6Vmasycwy4A/hJZt4J7AZub6atB3b2rUpJUpf5vA/8G8DXIuIwrTXxBxemJElSL97TglBm7gH2NI+fBa5d+JIkSb3wTkxJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKmrWAI+IyyJid0QcjIgnI2JjM35xRDwWEYeaz8v7X64k6ZRersCngE2Z+WHgOuALEXElsBnYlZlrgF3NtiTpDJk1wDPz5cz8WfP4f4GDwErgVmBrM20rcFu/ipQkdYvM7H1yxBjw78BVwPOZuaxt34nM7FpGiYhJYBJgdHT0mu3bt8+p0OOvneTYW3M6dCiNLsV+tLEf3exJp0H2Y+3Ki+Z1/Lp16/Zn5vj08ZFenyAi3g/8EPhKZr4RET0dl5lbgC0A4+PjOTEx0euX7PDAtp3ce6DncofeprVT9qON/ehmTzoNsh9H7pzoy/P29C6UiHgfrfDelpkPN8PHImJFs38FcLwvFUqSZtTLu1ACeBA4mJnfatv1CLC+ebwe2Lnw5UmS3k0vP0/cAHweOBARjzdjfwHcDXw/IjYAzwOf7U+JkqSZzBrgmfkfwLsteN+0sOVIknrlnZiSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVNS8AjwiPhkRz0TE4YjYvFBFSZJmN+cAj4glwN8BnwKuBD4XEVcuVGGSpNObzxX4tcDhzHw2M38NbAduXZiyJEmzicyc24ERtwOfzMw/b7Y/D/x+Zn5x2rxJYLLZvAJ4Zo61Xgq8Osdjh5H96GQ/utmTTpX78XuZ+YHpgyPzeMKYYazru0FmbgG2zOPrtL5YxL7MHJ/v8wwL+9HJfnSzJ52GsR/zWUI5ClzWtr0KeGl+5UiSejWfAP8vYE1ErI6Ic4A7gEcWpixJ0mzmvISSmVMR8UXgx8AS4B8y88kFq6zbvJdhhoz96GQ/utmTTkPXjzn/ElOSNFjeiSlJRRngklTUWR/gi/F2/Yi4LCJ2R8TBiHgyIjY24xdHxGMRcaj5vLwZj4j426ZHv4iIqwf7CvonIpZExM8j4tFme3VE7G168lDzC3Ui4txm+3Czf2yQdfdDRCyLiB0R8XRzrly/2M+RiPhq83fmiYj4XkScN8znyFkd4Iv4dv0pYFNmfhi4DvhC87o3A7sycw2wq9mGVn/WNB+TwHfOfMlnzEbgYNv2PcB9TU9OABua8Q3Aicz8IHBfM2/Y3A/8KDM/BHyEVl8W7TkSESuBLwPjmXkVrTdX3MEwnyOZedZ+ANcDP27bvgu4a9B1DaAPO4E/onUX64pmbAXwTPP474HPtc1/e94wfdC612AXcCPwKK2byV4FRqafL7TeHXV983ikmReDfg0L2IsLgeemv6bFfI4AK4EXgIubP/NHgT8e5nPkrL4C550/kFOONmOLRvNj3ceAvcBoZr4M0Hz+nWbaYunTt4GvA//XbF8CvJ6ZU812++t+uyfN/pPN/GFxOfAK8I/NktJ3I+ICFvE5kpkvAn8DPA+8TOvPfD9DfI6c7QHe0+36wyoi3g/8EPhKZr5xuqkzjA1VnyLi08DxzNzfPjzD1Oxh3zAYAa4GvpOZHwPe5J3lkpkMez9o1vtvBVYDvwtcQGvpaLqhOUfO9gBftLfrR8T7aIX3tsx8uBk+FhErmv0rgOPN+GLo0w3AZyLiCK1/+fJGWlfkyyLi1A1p7a/77Z40+y8CXjuTBffZUeBoZu5ttnfQCvTFfI58AnguM1/JzN8ADwMfZ4jPkbM9wBfl7foREcCDwMHM/FbbrkeA9c3j9bTWxk+N/0nzToPrgJOnfoweFpl5V2auyswxWufBTzLzTmA3cHszbXpPTvXq9mZ+qaur08nMXwEvRMQVzdBNwFMs4nOE1tLJdRFxfvN36FRPhvccGfQifA+/mLgZ+G/gl8BfDrqeM/Sa/4DWj3K/AB5vPm6mtT63CzjUfL64mR+03q3zS+AArd/CD/x19LE/E8CjzePLgf8EDgM/AM5txs9rtg83+y8fdN196MNHgX3NefLPwPLFfo4AfwU8DTwB/BNw7jCfI95KL0lFne1LKJKkd2GAS1JRBrgkFWWAS1JRBrgkFWWAS1JRBrgkFfX/nc/fwTMy4WAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_data['PassengerId'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there is no observable trend the data, let's drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = num_data.drop('PassengerId', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name          0\n",
       "Sex           0\n",
       "Ticket        0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- large number of missing value in Cabin, let's drop it\n",
    "- only two missing value in Embarked, fill with most freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_data = txt_data.drop('Cabin', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_data['Embarked'] = txt_data['Embarked'].fillna(txt_data['Embarked'].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        0\n",
       "Sex         0\n",
       "Ticket      0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's def the data_cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean (df):\n",
    "    #create lookup table for Age\n",
    "    psp = df['Pclass'].apply(str)+'-'+df['SibSp'].apply(str)+'-'+df['Parch'].apply(str)\n",
    "    frame = { 'Pclass_Sibsp_Parch': psp, 'Age': df.Age } \n",
    "    psp_age = pd.DataFrame(frame)\n",
    "    #define age classes, other not yet included\n",
    "    age_classes = ['3-0-0', '1-0-0', '2-0-0']\n",
    "    #convert excluding items to 'other'\n",
    "    psp_age['Pclass_Sibsp_Parch'] = psp_age['Pclass_Sibsp_Parch'].apply(lambda x: x if x in age_classes else 'other')\n",
    "    #transform to a lookup table\n",
    "    am_lookup= psp_age.groupby('Pclass_Sibsp_Parch').mean()\n",
    "    #using the lookup table\n",
    "    df['temp_psp'] = psp_age['Pclass_Sibsp_Parch'] #setup a temp col with psp lables\n",
    "    df['temp_age_cat_mean'] = df['temp_psp'] #create a col for age means conversions\n",
    "    df['temp_age_cat_mean'] = df['temp_age_cat_mean'].apply(lambda x: am_lookup['Age'][x]) #convert values in this col to age means according to the psp lable\n",
    "    df['Age'] = df['Age'].fillna(df['temp_age_cat_mean']) #fill na according to the tempt mean col\n",
    "    #drop the temp cols\n",
    "    df = df.drop('temp_psp', axis=1)\n",
    "    df = df.drop('temp_age_cat_mean', axis=1)\n",
    "    \n",
    "    #found that there are missing valuse in Fare in the test dataset\n",
    "    df['Fare'] = df['Fare'].fillna(method='ffill')\n",
    "    \n",
    "    #for reasons stated above we don't want PassengerId, Cabin cols\n",
    "    df = df.drop('PassengerId', axis=1)\n",
    "    df = df.drop('Cabin', axis=1)\n",
    "    \n",
    "    #fill na for Embarked, only two \n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].value_counts().index[0])\n",
    "    \n",
    "    #do a final check\n",
    "    print(df.isnull().sum())\n",
    "    print(df.shape)\n",
    "    print(df.head())\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.715957</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.165460</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.235556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.715957    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   13.165460    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.235556    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   36.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "We have Age and Fare containing continouse valuse\n",
    "#### Action\n",
    "For classification problem, we hypothesize that discrete values will be better fit for the algorithms, let's proceed with the conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.413452</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass        Age  SibSp  Parch     Fare  FareBin  AgeBin\n",
       "0           0       3  22.000000      1      0   7.2500        1       2\n",
       "1           1       1  38.000000      1      0  71.2833        5       3\n",
       "2           1       3  26.000000      0      0   7.9250        2       2\n",
       "3           1       1  35.000000      1      0  53.1000        5       3\n",
       "4           0       3  35.000000      0      0   8.0500        2       3\n",
       "..        ...     ...        ...    ...    ...      ...      ...     ...\n",
       "886         0       2  27.000000      0      0  13.0000        3       2\n",
       "887         1       1  19.000000      0      0  30.0000        4       2\n",
       "888         0       3  26.413452      1      2  23.4500        4       2\n",
       "889         1       1  26.000000      0      0  30.0000        4       2\n",
       "890         0       3  32.000000      0      0   7.7500        1       2\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data['FareBin'] = pd.qcut(num_data['Fare'], 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "num_data['AgeBin'] = pd.cut(num_data['Age'].astype(int), 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.069834</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.049771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.379096</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>-0.408902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.069834</td>\n",
       "      <td>-0.379096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.255773</td>\n",
       "      <td>-0.188705</td>\n",
       "      <td>0.101817</td>\n",
       "      <td>0.129939</td>\n",
       "      <td>0.940683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.255773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>-0.238513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.188705</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>-0.154571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.101817</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600883</td>\n",
       "      <td>0.128427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FareBin</th>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>0.129939</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>0.600883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBin</th>\n",
       "      <td>-0.049771</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>0.940683</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.128427</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived    Pclass       Age     SibSp     Parch      Fare  \\\n",
       "Survived  1.000000 -0.338481 -0.069834 -0.035322  0.081629  0.257307   \n",
       "Pclass   -0.338481  1.000000 -0.379096  0.083081  0.018443 -0.549500   \n",
       "Age      -0.069834 -0.379096  1.000000 -0.255773 -0.188705  0.101817   \n",
       "SibSp    -0.035322  0.083081 -0.255773  1.000000  0.414838  0.159651   \n",
       "Parch     0.081629  0.018443 -0.188705  0.414838  1.000000  0.216225   \n",
       "Fare      0.257307 -0.549500  0.101817  0.159651  0.216225  1.000000   \n",
       "FareBin   0.317783 -0.705206  0.129939  0.354974  0.351317  0.600883   \n",
       "AgeBin   -0.049771 -0.408902  0.940683 -0.238513 -0.154571  0.128427   \n",
       "\n",
       "           FareBin    AgeBin  \n",
       "Survived  0.317783 -0.049771  \n",
       "Pclass   -0.705206 -0.408902  \n",
       "Age       0.129939  0.940683  \n",
       "SibSp     0.354974 -0.238513  \n",
       "Parch     0.351317 -0.154571  \n",
       "Fare      0.600883  0.128427  \n",
       "FareBin   1.000000  0.148150  \n",
       "AgeBin    0.148150  1.000000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at if the new features are actually useful\n",
    "num_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "We see that FareBin has a better corrolation with Survived, whereas AgeBin has a lower correlation coefficient than raw Age\n",
    "#### Action\n",
    "- We will keep FareBin drop Fare\n",
    "- For Age vs Agebin, since the difference is small, and both Age and AgeBin are not tightly corrolated with Survived, for the sake of consistency we will keep AgeBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we drop the original features\n",
    "num_data = num_data.drop(['Fare', 'Age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  SibSp  Parch  FareBin  AgeBin\n",
       "0           0       3      1      0        1       2\n",
       "1           1       1      1      0        5       3\n",
       "2           1       3      0      0        2       2\n",
       "3           1       1      1      0        5       3\n",
       "4           0       3      0      0        2       3\n",
       "..        ...     ...    ...    ...      ...     ...\n",
       "886         0       2      0      0        3       2\n",
       "887         1       1      0      0        4       2\n",
       "888         0       3      1      2        4       2\n",
       "889         1       1      0      0        4       2\n",
       "890         0       3      0      0        1       2\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IsAlone and FamilySize\n",
    "Inspired by the approach taken in the follow Kaggle notebooks, we would like to engineer two new feature IsAlone and FamilySize\n",
    "- [https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy](https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy)\n",
    "- https://www.notion.so/Titanic-Data-Science-Solutions-Kaggle-a5a4aa2d5e024be88263390a26db3c6d#81f0bc93036e4f4ab87c1ac22e2d0e2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "FamilySize = num_data['SibSp']+num_data['Parch']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsAlone = FamilySize>1\n",
    "IsAlone = IsAlone.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.049771</td>\n",
       "      <td>0.203367</td>\n",
       "      <td>0.016639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>-0.135207</td>\n",
       "      <td>0.065997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>0.584471</td>\n",
       "      <td>0.890712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.583398</td>\n",
       "      <td>0.783111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FareBin</th>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>0.418125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBin</th>\n",
       "      <td>-0.049771</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161040</td>\n",
       "      <td>-0.240237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsAlone</th>\n",
       "      <td>0.203367</td>\n",
       "      <td>-0.135207</td>\n",
       "      <td>0.584471</td>\n",
       "      <td>0.583398</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>-0.161040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FamilySize</th>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>0.890712</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>0.418125</td>\n",
       "      <td>-0.240237</td>\n",
       "      <td>0.690922</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Survived    Pclass     SibSp     Parch   FareBin    AgeBin  \\\n",
       "Survived    1.000000 -0.338481 -0.035322  0.081629  0.317783 -0.049771   \n",
       "Pclass     -0.338481  1.000000  0.083081  0.018443 -0.705206 -0.408902   \n",
       "SibSp      -0.035322  0.083081  1.000000  0.414838  0.354974 -0.238513   \n",
       "Parch       0.081629  0.018443  0.414838  1.000000  0.351317 -0.154571   \n",
       "FareBin     0.317783 -0.705206  0.354974  0.351317  1.000000  0.148150   \n",
       "AgeBin     -0.049771 -0.408902 -0.238513 -0.154571  0.148150  1.000000   \n",
       "IsAlone     0.203367 -0.135207  0.584471  0.583398  0.520277 -0.161040   \n",
       "FamilySize  0.016639  0.065997  0.890712  0.783111  0.418125 -0.240237   \n",
       "\n",
       "             IsAlone  FamilySize  \n",
       "Survived    0.203367    0.016639  \n",
       "Pclass     -0.135207    0.065997  \n",
       "SibSp       0.584471    0.890712  \n",
       "Parch       0.583398    0.783111  \n",
       "FareBin     0.520277    0.418125  \n",
       "AgeBin     -0.161040   -0.240237  \n",
       "IsAlone     1.000000    0.690922  \n",
       "FamilySize  0.690922    1.000000  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data['IsAlone'] = IsAlone\n",
    "num_data['FamilySize'] = FamilySize\n",
    "num_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IsAlone has pretty good corrolation with the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>113803</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>373450</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>211536</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>112053</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>111369</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>370376</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name     Sex  \\\n",
       "0                              Braund, Mr. Owen Harris    male   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female   \n",
       "2                               Heikkinen, Miss. Laina  female   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   \n",
       "4                             Allen, Mr. William Henry    male   \n",
       "..                                                 ...     ...   \n",
       "886                              Montvila, Rev. Juozas    male   \n",
       "887                       Graham, Miss. Margaret Edith  female   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   \n",
       "889                              Behr, Mr. Karl Howell    male   \n",
       "890                                Dooley, Mr. Patrick    male   \n",
       "\n",
       "               Ticket Embarked  \n",
       "0           A/5 21171        S  \n",
       "1            PC 17599        C  \n",
       "2    STON/O2. 3101282        S  \n",
       "3              113803        S  \n",
       "4              373450        S  \n",
       "..                ...      ...  \n",
       "886            211536        S  \n",
       "887            112053        S  \n",
       "888        W./C. 6607        S  \n",
       "889            111369        C  \n",
       "890            370376        Q  \n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "Sex and Embarked are ready for labling\n",
    "Need to work on Name and Ticket\n",
    "\n",
    "#### Action\n",
    "- Analysis Name and Ticket\n",
    "- Impute Sex and Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and transform the Name col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "Name values are pretty uniformly formatted\n",
    "\n",
    "#### Action\n",
    "We could use simple split() to extract the Title values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              517\n",
       "Miss            182\n",
       "Mrs             125\n",
       "Master           40\n",
       "Dr                7\n",
       "Rev               6\n",
       "Col               2\n",
       "Major             2\n",
       "Mlle              2\n",
       "Lady              1\n",
       "Mme               1\n",
       "Sir               1\n",
       "Capt              1\n",
       "Jonkheer          1\n",
       "Ms                1\n",
       "Don               1\n",
       "the Countess      1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#borrowed from https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy notebook\n",
    "#quick and dirty code split title from name: http://www.pythonforbeginners.com/dictionary/python-split\n",
    "txt_data['Title'] = txt_data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "\n",
    "txt_data.Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr        517\n",
      "Miss      182\n",
      "Mrs       125\n",
      "Master     40\n",
      "Misc       27\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "title_names = (txt_data['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n",
    "\n",
    "#apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n",
    "txt_data['Title'] = txt_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "print(txt_data['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and transform the Ticket col\n",
    "\n",
    "#### Observation\n",
    "no obvious observable patterns in the data\n",
    "\n",
    "#### Action\n",
    "look at value len to see if we could extract some patterns out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ticket_len = txt_data.Ticket.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     419\n",
       "5     131\n",
       "4     101\n",
       "8      76\n",
       "10     41\n",
       "7      27\n",
       "9      26\n",
       "17     14\n",
       "16     11\n",
       "13     10\n",
       "12     10\n",
       "15      9\n",
       "11      8\n",
       "18      6\n",
       "3       2\n",
       "Name: Ticket, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ticket_len.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is much more workable than the raw data, let's apply the same cat approach we did for Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     419\n",
       "5     131\n",
       "30    123\n",
       "4     101\n",
       "8      76\n",
       "10     41\n",
       "Name: Ticket, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_min_ti = 30\n",
    "Ticket_len_ls = (Ticket_len.value_counts() < stat_min_ti)\n",
    "Ticket_len = Ticket_len.apply(lambda x: '30' if Ticket_len_ls.loc[x] == True else x)\n",
    "Ticket_len.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_data['Ticket_len'] = Ticket_len\n",
    "txt_data = txt_data.drop(['Name', 'Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Ticket_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Misc</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "      <td>Mr</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>male</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex Embarked Title Ticket_len\n",
       "0      male        S    Mr         30\n",
       "1    female        C   Mrs          8\n",
       "2    female        S  Miss         30\n",
       "3    female        S   Mrs          6\n",
       "4      male        S    Mr          6\n",
       "..      ...      ...   ...        ...\n",
       "886    male        S  Misc          6\n",
       "887  female        S  Miss          6\n",
       "888  female        S  Miss         10\n",
       "889    male        C    Mr          6\n",
       "890    male        Q    Mr          6\n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputer only works on str or numbers\n",
    "txt_data['Ticket_len'] = txt_data['Ticket_len'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we perform data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "imp_txt_cols = OH_en.fit_transform(txt_data[['Sex','Embarked', 'Title', 'Ticket_len']])\n",
    "imp_txt_cols = pd.DataFrame(imp_txt_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <th>Ticket_len_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  \\\n",
       "0           0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "1           1.0       0.0         1.0         0.0         0.0           0.0   \n",
       "2           1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "3           1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "4           0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "..          ...       ...         ...         ...         ...           ...   \n",
       "886         0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "887         1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "888         1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "889         0.0       1.0         1.0         0.0         0.0           0.0   \n",
       "890         0.0       1.0         0.0         1.0         0.0           0.0   \n",
       "\n",
       "     Title_Misc  Title_Miss  Title_Mr  Title_Mrs  Ticket_len_10  \\\n",
       "0           0.0         0.0       1.0        0.0            0.0   \n",
       "1           0.0         0.0       0.0        1.0            0.0   \n",
       "2           0.0         1.0       0.0        0.0            0.0   \n",
       "3           0.0         0.0       0.0        1.0            0.0   \n",
       "4           0.0         0.0       1.0        0.0            0.0   \n",
       "..          ...         ...       ...        ...            ...   \n",
       "886         1.0         0.0       0.0        0.0            0.0   \n",
       "887         0.0         1.0       0.0        0.0            0.0   \n",
       "888         0.0         1.0       0.0        0.0            1.0   \n",
       "889         0.0         0.0       1.0        0.0            0.0   \n",
       "890         0.0         0.0       1.0        0.0            0.0   \n",
       "\n",
       "     Ticket_len_30  Ticket_len_4  Ticket_len_5  Ticket_len_6  Ticket_len_8  \n",
       "0              1.0           0.0           0.0           0.0           0.0  \n",
       "1              0.0           0.0           0.0           0.0           1.0  \n",
       "2              1.0           0.0           0.0           0.0           0.0  \n",
       "3              0.0           0.0           0.0           1.0           0.0  \n",
       "4              0.0           0.0           0.0           1.0           0.0  \n",
       "..             ...           ...           ...           ...           ...  \n",
       "886            0.0           0.0           0.0           1.0           0.0  \n",
       "887            0.0           0.0           0.0           1.0           0.0  \n",
       "888            0.0           0.0           0.0           0.0           0.0  \n",
       "889            0.0           0.0           0.0           1.0           0.0  \n",
       "890            0.0           0.0           0.0           1.0           0.0  \n",
       "\n",
       "[891 rows x 16 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we align the index and col names\n",
    "imp_txt_cols.index = txt_data[['Sex','Embarked', 'Title', 'Ticket_len']].index\n",
    "imp_txt_cols.columns = OH_en.get_feature_names(['Sex','Embarked', 'Title', 'Ticket_len'])\n",
    "imp_txt_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Sex' 'Embarked' 'Title' 'Ticket_len'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-251f5ea4f80a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#now we complete the txt df with the imputed cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtxt_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtxt_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Embarked'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Title'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Ticket_len'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimp_txt_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtxt_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3995\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3996\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3997\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3998\u001b[0m         )\n\u001b[0;32m   3999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3936\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Sex' 'Embarked' 'Title' 'Ticket_len'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#now we complete the txt df with the imputed cols\n",
    "txt_data = txt_data.drop(['Sex','Embarked', 'Title', 'Ticket_len'], axis=1).join(imp_txt_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <th>Ticket_len_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  \\\n",
       "0           0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "1           1.0       0.0         1.0         0.0         0.0           0.0   \n",
       "2           1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "3           1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "4           0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "..          ...       ...         ...         ...         ...           ...   \n",
       "886         0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "887         1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "888         1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "889         0.0       1.0         1.0         0.0         0.0           0.0   \n",
       "890         0.0       1.0         0.0         1.0         0.0           0.0   \n",
       "\n",
       "     Title_Misc  Title_Miss  Title_Mr  Title_Mrs  Ticket_len_10  \\\n",
       "0           0.0         0.0       1.0        0.0            0.0   \n",
       "1           0.0         0.0       0.0        1.0            0.0   \n",
       "2           0.0         1.0       0.0        0.0            0.0   \n",
       "3           0.0         0.0       0.0        1.0            0.0   \n",
       "4           0.0         0.0       1.0        0.0            0.0   \n",
       "..          ...         ...       ...        ...            ...   \n",
       "886         1.0         0.0       0.0        0.0            0.0   \n",
       "887         0.0         1.0       0.0        0.0            0.0   \n",
       "888         0.0         1.0       0.0        0.0            1.0   \n",
       "889         0.0         0.0       1.0        0.0            0.0   \n",
       "890         0.0         0.0       1.0        0.0            0.0   \n",
       "\n",
       "     Ticket_len_30  Ticket_len_4  Ticket_len_5  Ticket_len_6  Ticket_len_8  \n",
       "0              1.0           0.0           0.0           0.0           0.0  \n",
       "1              0.0           0.0           0.0           0.0           1.0  \n",
       "2              1.0           0.0           0.0           0.0           0.0  \n",
       "3              0.0           0.0           0.0           1.0           0.0  \n",
       "4              0.0           0.0           0.0           1.0           0.0  \n",
       "..             ...           ...           ...           ...           ...  \n",
       "886            0.0           0.0           0.0           1.0           0.0  \n",
       "887            0.0           0.0           0.0           1.0           0.0  \n",
       "888            0.0           0.0           0.0           0.0           0.0  \n",
       "889            0.0           0.0           0.0           1.0           0.0  \n",
       "890            0.0           0.0           0.0           1.0           0.0  \n",
       "\n",
       "[891 rows x 16 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <th>Ticket_len_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex_female</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.119224</td>\n",
       "      <td>-0.159934</td>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.686808</td>\n",
       "      <td>-0.867334</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.084090</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>0.091776</td>\n",
       "      <td>-0.045475</td>\n",
       "      <td>0.052287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_male</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.082853</td>\n",
       "      <td>-0.074115</td>\n",
       "      <td>0.119224</td>\n",
       "      <td>0.159934</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>-0.686808</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>-0.547600</td>\n",
       "      <td>-0.006179</td>\n",
       "      <td>0.084090</td>\n",
       "      <td>-0.010421</td>\n",
       "      <td>-0.091776</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>-0.052287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>0.082853</td>\n",
       "      <td>-0.082853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>-0.782742</td>\n",
       "      <td>-0.035225</td>\n",
       "      <td>0.065432</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>-0.072567</td>\n",
       "      <td>0.061395</td>\n",
       "      <td>-0.105869</td>\n",
       "      <td>-0.068141</td>\n",
       "      <td>0.361630</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>-0.339198</td>\n",
       "      <td>0.325325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.074115</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.499421</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>-0.007767</td>\n",
       "      <td>0.171117</td>\n",
       "      <td>-0.078338</td>\n",
       "      <td>-0.089739</td>\n",
       "      <td>-0.048484</td>\n",
       "      <td>-0.123085</td>\n",
       "      <td>-0.097372</td>\n",
       "      <td>0.018938</td>\n",
       "      <td>0.206393</td>\n",
       "      <td>-0.093921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>-0.119224</td>\n",
       "      <td>0.119224</td>\n",
       "      <td>-0.782742</td>\n",
       "      <td>-0.499421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024264</td>\n",
       "      <td>-0.052433</td>\n",
       "      <td>-0.130650</td>\n",
       "      <td>0.112870</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.123257</td>\n",
       "      <td>0.137152</td>\n",
       "      <td>-0.255526</td>\n",
       "      <td>-0.035339</td>\n",
       "      <td>0.167268</td>\n",
       "      <td>-0.225893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Master</th>\n",
       "      <td>-0.159934</td>\n",
       "      <td>0.159934</td>\n",
       "      <td>-0.035225</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.024264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.038326</td>\n",
       "      <td>-0.109844</td>\n",
       "      <td>-0.254903</td>\n",
       "      <td>-0.087580</td>\n",
       "      <td>0.029992</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>-0.044095</td>\n",
       "      <td>0.012919</td>\n",
       "      <td>-0.046801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Misc</th>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>0.065432</td>\n",
       "      <td>-0.007767</td>\n",
       "      <td>-0.052433</td>\n",
       "      <td>-0.038326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.089565</td>\n",
       "      <td>-0.207843</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>-0.038825</td>\n",
       "      <td>-0.032784</td>\n",
       "      <td>-0.063208</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>0.086656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Miss</th>\n",
       "      <td>0.686808</td>\n",
       "      <td>-0.686808</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>0.171117</td>\n",
       "      <td>-0.130650</td>\n",
       "      <td>-0.109844</td>\n",
       "      <td>-0.089565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.595692</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.057497</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>0.024675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mr</th>\n",
       "      <td>-0.867334</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>-0.072567</td>\n",
       "      <td>-0.078338</td>\n",
       "      <td>0.112870</td>\n",
       "      <td>-0.254903</td>\n",
       "      <td>-0.207843</td>\n",
       "      <td>-0.595692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.474952</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.083562</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>-0.041512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mrs</th>\n",
       "      <td>0.547600</td>\n",
       "      <td>-0.547600</td>\n",
       "      <td>0.061395</td>\n",
       "      <td>-0.089739</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>-0.087580</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>-0.474952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>-0.039872</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>-0.043914</td>\n",
       "      <td>0.015478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.006179</td>\n",
       "      <td>-0.105869</td>\n",
       "      <td>-0.048484</td>\n",
       "      <td>0.123257</td>\n",
       "      <td>0.029992</td>\n",
       "      <td>-0.038825</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087893</td>\n",
       "      <td>-0.078529</td>\n",
       "      <td>-0.091182</td>\n",
       "      <td>-0.206928</td>\n",
       "      <td>-0.067067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <td>-0.084090</td>\n",
       "      <td>0.084090</td>\n",
       "      <td>-0.068141</td>\n",
       "      <td>-0.123085</td>\n",
       "      <td>0.137152</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>-0.032784</td>\n",
       "      <td>-0.057497</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>-0.039872</td>\n",
       "      <td>-0.087893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.143093</td>\n",
       "      <td>-0.166150</td>\n",
       "      <td>-0.377058</td>\n",
       "      <td>-0.122208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <td>0.010421</td>\n",
       "      <td>-0.010421</td>\n",
       "      <td>0.361630</td>\n",
       "      <td>-0.097372</td>\n",
       "      <td>-0.255526</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>-0.063208</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>-0.078529</td>\n",
       "      <td>-0.143093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148449</td>\n",
       "      <td>-0.336886</td>\n",
       "      <td>-0.109188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <td>0.091776</td>\n",
       "      <td>-0.091776</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.018938</td>\n",
       "      <td>-0.035339</td>\n",
       "      <td>-0.044095</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>-0.083562</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>-0.091182</td>\n",
       "      <td>-0.166150</td>\n",
       "      <td>-0.148449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.391169</td>\n",
       "      <td>-0.126782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <td>-0.045475</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>-0.339198</td>\n",
       "      <td>0.206393</td>\n",
       "      <td>0.167268</td>\n",
       "      <td>0.012919</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>-0.043914</td>\n",
       "      <td>-0.206928</td>\n",
       "      <td>-0.377058</td>\n",
       "      <td>-0.336886</td>\n",
       "      <td>-0.391169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.287716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_8</th>\n",
       "      <td>0.052287</td>\n",
       "      <td>-0.052287</td>\n",
       "      <td>0.325325</td>\n",
       "      <td>-0.093921</td>\n",
       "      <td>-0.225893</td>\n",
       "      <td>-0.046801</td>\n",
       "      <td>0.086656</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>-0.041512</td>\n",
       "      <td>0.015478</td>\n",
       "      <td>-0.067067</td>\n",
       "      <td>-0.122208</td>\n",
       "      <td>-0.109188</td>\n",
       "      <td>-0.126782</td>\n",
       "      <td>-0.287716</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \\\n",
       "Sex_female       1.000000 -1.000000    0.082853    0.074115   -0.119224   \n",
       "Sex_male        -1.000000  1.000000   -0.082853   -0.074115    0.119224   \n",
       "Embarked_C       0.082853 -0.082853    1.000000   -0.148258   -0.782742   \n",
       "Embarked_Q       0.074115 -0.074115   -0.148258    1.000000   -0.499421   \n",
       "Embarked_S      -0.119224  0.119224   -0.782742   -0.499421    1.000000   \n",
       "Title_Master    -0.159934  0.159934   -0.035225    0.010478    0.024264   \n",
       "Title_Misc      -0.034471  0.034471    0.065432   -0.007767   -0.052433   \n",
       "Title_Miss       0.686808 -0.686808    0.026215    0.171117   -0.130650   \n",
       "Title_Mr        -0.867334  0.867334   -0.072567   -0.078338    0.112870   \n",
       "Title_Mrs        0.547600 -0.547600    0.061395   -0.089739    0.002689   \n",
       "Ticket_len_10    0.006179 -0.006179   -0.105869   -0.048484    0.123257   \n",
       "Ticket_len_30   -0.084090  0.084090   -0.068141   -0.123085    0.137152   \n",
       "Ticket_len_4     0.010421 -0.010421    0.361630   -0.097372   -0.255526   \n",
       "Ticket_len_5     0.091776 -0.091776    0.026735    0.018938   -0.035339   \n",
       "Ticket_len_6    -0.045475  0.045475   -0.339198    0.206393    0.167268   \n",
       "Ticket_len_8     0.052287 -0.052287    0.325325   -0.093921   -0.225893   \n",
       "\n",
       "               Title_Master  Title_Misc  Title_Miss  Title_Mr  Title_Mrs  \\\n",
       "Sex_female        -0.159934   -0.034471    0.686808 -0.867334   0.547600   \n",
       "Sex_male           0.159934    0.034471   -0.686808  0.867334  -0.547600   \n",
       "Embarked_C        -0.035225    0.065432    0.026215 -0.072567   0.061395   \n",
       "Embarked_Q         0.010478   -0.007767    0.171117 -0.078338  -0.089739   \n",
       "Embarked_S         0.024264   -0.052433   -0.130650  0.112870   0.002689   \n",
       "Title_Master       1.000000   -0.038326   -0.109844 -0.254903  -0.087580   \n",
       "Title_Misc        -0.038326    1.000000   -0.089565 -0.207843  -0.071411   \n",
       "Title_Miss        -0.109844   -0.089565    1.000000 -0.595692  -0.204670   \n",
       "Title_Mr          -0.254903   -0.207843   -0.595692  1.000000  -0.474952   \n",
       "Title_Mrs         -0.087580   -0.071411   -0.204670 -0.474952   1.000000   \n",
       "Ticket_len_10      0.029992   -0.038825   -0.004981 -0.008576   0.019250   \n",
       "Ticket_len_30      0.038938   -0.032784   -0.057497  0.070078  -0.039872   \n",
       "Ticket_len_4       0.007963   -0.063208    0.020804  0.002834  -0.001728   \n",
       "Ticket_len_5      -0.044095    0.056025    0.033341 -0.083562   0.078680   \n",
       "Ticket_len_6       0.012919   -0.009143   -0.008851  0.035888  -0.043914   \n",
       "Ticket_len_8      -0.046801    0.086656    0.024675 -0.041512   0.015478   \n",
       "\n",
       "               Ticket_len_10  Ticket_len_30  Ticket_len_4  Ticket_len_5  \\\n",
       "Sex_female          0.006179      -0.084090      0.010421      0.091776   \n",
       "Sex_male           -0.006179       0.084090     -0.010421     -0.091776   \n",
       "Embarked_C         -0.105869      -0.068141      0.361630      0.026735   \n",
       "Embarked_Q         -0.048484      -0.123085     -0.097372      0.018938   \n",
       "Embarked_S          0.123257       0.137152     -0.255526     -0.035339   \n",
       "Title_Master        0.029992       0.038938      0.007963     -0.044095   \n",
       "Title_Misc         -0.038825      -0.032784     -0.063208      0.056025   \n",
       "Title_Miss         -0.004981      -0.057497      0.020804      0.033341   \n",
       "Title_Mr           -0.008576       0.070078      0.002834     -0.083562   \n",
       "Title_Mrs           0.019250      -0.039872     -0.001728      0.078680   \n",
       "Ticket_len_10       1.000000      -0.087893     -0.078529     -0.091182   \n",
       "Ticket_len_30      -0.087893       1.000000     -0.143093     -0.166150   \n",
       "Ticket_len_4       -0.078529      -0.143093      1.000000     -0.148449   \n",
       "Ticket_len_5       -0.091182      -0.166150     -0.148449      1.000000   \n",
       "Ticket_len_6       -0.206928      -0.377058     -0.336886     -0.391169   \n",
       "Ticket_len_8       -0.067067      -0.122208     -0.109188     -0.126782   \n",
       "\n",
       "               Ticket_len_6  Ticket_len_8  \n",
       "Sex_female        -0.045475      0.052287  \n",
       "Sex_male           0.045475     -0.052287  \n",
       "Embarked_C        -0.339198      0.325325  \n",
       "Embarked_Q         0.206393     -0.093921  \n",
       "Embarked_S         0.167268     -0.225893  \n",
       "Title_Master       0.012919     -0.046801  \n",
       "Title_Misc        -0.009143      0.086656  \n",
       "Title_Miss        -0.008851      0.024675  \n",
       "Title_Mr           0.035888     -0.041512  \n",
       "Title_Mrs         -0.043914      0.015478  \n",
       "Ticket_len_10     -0.206928     -0.067067  \n",
       "Ticket_len_30     -0.377058     -0.122208  \n",
       "Ticket_len_4      -0.336886     -0.109188  \n",
       "Ticket_len_5      -0.391169     -0.126782  \n",
       "Ticket_len_6       1.000000     -0.287716  \n",
       "Ticket_len_8      -0.287716      1.000000  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converge to a function\n",
    "Next, let's converge what we have just done to a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_eng (clean_data):\n",
    "    #let's start with num cols\n",
    "    #create value bins for continuouse values\n",
    "    clean_data['FareBin'] = pd.qcut(clean_data['Fare'], 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    clean_data['AgeBin'] = pd.cut(clean_data['Age'].astype(int), 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    #now we drop the original features\n",
    "    clean_data = clean_data.drop(['Fare', 'Age'], axis=1)\n",
    "    \n",
    "    #create new features\n",
    "    FamilySize = clean_data['SibSp']+clean_data['Parch']+1\n",
    "    IsAlone = FamilySize>1\n",
    "    IsAlone = IsAlone.apply(int)\n",
    "    clean_data['IsAlone'] = IsAlone\n",
    "    clean_data['FamilySize'] = FamilySize\n",
    "    \n",
    "    #next we work on text data\n",
    "    #extrat title from Name\n",
    "    clean_data['Title'] = clean_data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    \n",
    "    stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "    title_names = (clean_data['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n",
    "    #apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n",
    "    clean_data['Title'] = clean_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "    \n",
    "    #cat tickets by length\n",
    "    Ticket_len = clean_data.Ticket.apply(len)\n",
    "    stat_min_ti = 30\n",
    "    Ticket_len_ls = (Ticket_len.value_counts() < stat_min_ti)\n",
    "    Ticket_len = Ticket_len.apply(lambda x: '30' if Ticket_len_ls.loc[x] == True else x)\n",
    "    Ticket_len.value_counts()\n",
    "    clean_data['Ticket_len'] = Ticket_len\n",
    "    #imputer only works on str or numbers\n",
    "    clean_data['Ticket_len'] = clean_data['Ticket_len'].astype(str)\n",
    "    clean_data = clean_data.drop(['Name', 'Ticket'], axis=1)\n",
    "    \n",
    "    #do imputation on txt data\n",
    "    OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    imp_cols = OH_en.fit_transform(clean_data[['Sex','Embarked', 'Title', 'Ticket_len']])\n",
    "    imp_cols = pd.DataFrame(imp_cols)\n",
    "    #now we align the index and col names\n",
    "    imp_cols.index = clean_data[['Sex','Embarked', 'Title', 'Ticket_len']].index\n",
    "    imp_cols.columns = OH_en.get_feature_names(['Sex','Embarked', 'Title', 'Ticket_len'])\n",
    "    clean_data = clean_data.drop(['Sex','Embarked', 'Title', 'Ticket_len'], axis=1).join(imp_cols)\n",
    "\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Ticket      0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "(891, 10)\n",
      "   Survived  Pclass                                               Name  \\\n",
      "0         0       3                            Braund, Mr. Owen Harris   \n",
      "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "2         1       3                             Heikkinen, Miss. Laina   \n",
      "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "4         0       3                           Allen, Mr. William Henry   \n",
      "\n",
      "      Sex   Age  SibSp  Parch            Ticket     Fare Embarked  \n",
      "0    male  22.0      1      0         A/5 21171   7.2500        S  \n",
      "1  female  38.0      1      0          PC 17599  71.2833        C  \n",
      "2  female  26.0      0      0  STON/O2. 3101282   7.9250        S  \n",
      "3  female  35.0      1      0            113803  53.1000        S  \n",
      "4    male  35.0      0      0            373450   8.0500        S  \n"
     ]
    }
   ],
   "source": [
    "test_data = train_raw.copy()\n",
    "test_clean = data_clean(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = f_eng(test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <th>Ticket_len_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.049771</td>\n",
       "      <td>0.203367</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.543351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022030</td>\n",
       "      <td>0.327093</td>\n",
       "      <td>-0.549199</td>\n",
       "      <td>0.339040</td>\n",
       "      <td>-0.019137</td>\n",
       "      <td>-0.081703</td>\n",
       "      <td>-0.012868</td>\n",
       "      <td>0.200178</td>\n",
       "      <td>-0.124049</td>\n",
       "      <td>0.097727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>-0.135207</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206333</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>0.142698</td>\n",
       "      <td>-0.149209</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>0.155894</td>\n",
       "      <td>0.270416</td>\n",
       "      <td>-0.377124</td>\n",
       "      <td>0.157908</td>\n",
       "      <td>-0.324370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>0.584471</td>\n",
       "      <td>0.890712</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036364</td>\n",
       "      <td>0.087932</td>\n",
       "      <td>-0.250489</td>\n",
       "      <td>0.063407</td>\n",
       "      <td>-0.011875</td>\n",
       "      <td>0.084638</td>\n",
       "      <td>-0.031555</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>-0.112502</td>\n",
       "      <td>0.132163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.583398</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067480</td>\n",
       "      <td>0.105567</td>\n",
       "      <td>-0.333905</td>\n",
       "      <td>0.225852</td>\n",
       "      <td>0.082150</td>\n",
       "      <td>0.028529</td>\n",
       "      <td>-0.041927</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>-0.033182</td>\n",
       "      <td>0.004982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FareBin</th>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>0.418125</td>\n",
       "      <td>0.244943</td>\n",
       "      <td>-0.244943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112454</td>\n",
       "      <td>0.059106</td>\n",
       "      <td>-0.312117</td>\n",
       "      <td>0.245302</td>\n",
       "      <td>-0.024758</td>\n",
       "      <td>-0.079605</td>\n",
       "      <td>-0.162293</td>\n",
       "      <td>0.263112</td>\n",
       "      <td>-0.194354</td>\n",
       "      <td>0.314787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBin</th>\n",
       "      <td>-0.049771</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161040</td>\n",
       "      <td>-0.240237</td>\n",
       "      <td>-0.093198</td>\n",
       "      <td>0.093198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176985</td>\n",
       "      <td>-0.242363</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.146407</td>\n",
       "      <td>-0.035189</td>\n",
       "      <td>-0.072051</td>\n",
       "      <td>-0.142312</td>\n",
       "      <td>0.182356</td>\n",
       "      <td>-0.062603</td>\n",
       "      <td>0.157564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsAlone</th>\n",
       "      <td>0.203367</td>\n",
       "      <td>-0.135207</td>\n",
       "      <td>0.584471</td>\n",
       "      <td>0.583398</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>-0.161040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690922</td>\n",
       "      <td>0.303646</td>\n",
       "      <td>-0.303646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>0.055127</td>\n",
       "      <td>-0.396920</td>\n",
       "      <td>0.365454</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>-0.000926</td>\n",
       "      <td>0.122750</td>\n",
       "      <td>-0.130834</td>\n",
       "      <td>0.031241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FamilySize</th>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>0.890712</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>0.418125</td>\n",
       "      <td>-0.240237</td>\n",
       "      <td>0.690922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200988</td>\n",
       "      <td>-0.200988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058565</td>\n",
       "      <td>0.112838</td>\n",
       "      <td>-0.338014</td>\n",
       "      <td>0.156168</td>\n",
       "      <td>0.032924</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>-0.042513</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>-0.093468</td>\n",
       "      <td>0.092818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_female</th>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.244943</td>\n",
       "      <td>-0.093198</td>\n",
       "      <td>0.303646</td>\n",
       "      <td>0.200988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.686808</td>\n",
       "      <td>-0.867334</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.084090</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>0.091776</td>\n",
       "      <td>-0.045475</td>\n",
       "      <td>0.052287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_male</th>\n",
       "      <td>-0.543351</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>-0.244943</td>\n",
       "      <td>0.093198</td>\n",
       "      <td>-0.303646</td>\n",
       "      <td>-0.200988</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>-0.686808</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>-0.547600</td>\n",
       "      <td>-0.006179</td>\n",
       "      <td>0.084090</td>\n",
       "      <td>-0.010421</td>\n",
       "      <td>-0.091776</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>-0.052287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>0.168240</td>\n",
       "      <td>-0.243292</td>\n",
       "      <td>-0.059528</td>\n",
       "      <td>-0.011069</td>\n",
       "      <td>0.204579</td>\n",
       "      <td>0.042419</td>\n",
       "      <td>0.095298</td>\n",
       "      <td>-0.046215</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>-0.082853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065432</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>-0.072567</td>\n",
       "      <td>0.061395</td>\n",
       "      <td>-0.105869</td>\n",
       "      <td>-0.068141</td>\n",
       "      <td>0.361630</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>-0.339198</td>\n",
       "      <td>0.325325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.221009</td>\n",
       "      <td>-0.026354</td>\n",
       "      <td>-0.081228</td>\n",
       "      <td>-0.243154</td>\n",
       "      <td>-0.088339</td>\n",
       "      <td>-0.086464</td>\n",
       "      <td>-0.058592</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.074115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007767</td>\n",
       "      <td>0.171117</td>\n",
       "      <td>-0.078338</td>\n",
       "      <td>-0.089739</td>\n",
       "      <td>-0.048484</td>\n",
       "      <td>-0.123085</td>\n",
       "      <td>-0.097372</td>\n",
       "      <td>0.018938</td>\n",
       "      <td>0.206393</td>\n",
       "      <td>-0.093921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>-0.149683</td>\n",
       "      <td>0.074053</td>\n",
       "      <td>0.068734</td>\n",
       "      <td>0.060814</td>\n",
       "      <td>-0.026202</td>\n",
       "      <td>0.018431</td>\n",
       "      <td>-0.029074</td>\n",
       "      <td>0.077359</td>\n",
       "      <td>-0.119224</td>\n",
       "      <td>0.119224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052433</td>\n",
       "      <td>-0.130650</td>\n",
       "      <td>0.112870</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.123257</td>\n",
       "      <td>0.137152</td>\n",
       "      <td>-0.255526</td>\n",
       "      <td>-0.035339</td>\n",
       "      <td>0.167268</td>\n",
       "      <td>-0.225893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Master</th>\n",
       "      <td>0.085221</td>\n",
       "      <td>0.082081</td>\n",
       "      <td>0.349559</td>\n",
       "      <td>0.267344</td>\n",
       "      <td>0.124297</td>\n",
       "      <td>-0.324075</td>\n",
       "      <td>0.267024</td>\n",
       "      <td>0.372472</td>\n",
       "      <td>-0.159934</td>\n",
       "      <td>0.159934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038326</td>\n",
       "      <td>-0.109844</td>\n",
       "      <td>-0.254903</td>\n",
       "      <td>-0.087580</td>\n",
       "      <td>0.029992</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>-0.044095</td>\n",
       "      <td>0.012919</td>\n",
       "      <td>-0.046801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Misc</th>\n",
       "      <td>0.022030</td>\n",
       "      <td>-0.206333</td>\n",
       "      <td>-0.036364</td>\n",
       "      <td>-0.067480</td>\n",
       "      <td>0.112454</td>\n",
       "      <td>0.176985</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>-0.058565</td>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.089565</td>\n",
       "      <td>-0.207843</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>-0.038825</td>\n",
       "      <td>-0.032784</td>\n",
       "      <td>-0.063208</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>0.086656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Miss</th>\n",
       "      <td>0.327093</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>0.087932</td>\n",
       "      <td>0.105567</td>\n",
       "      <td>0.059106</td>\n",
       "      <td>-0.242363</td>\n",
       "      <td>0.055127</td>\n",
       "      <td>0.112838</td>\n",
       "      <td>0.686808</td>\n",
       "      <td>-0.686808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.595692</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.057497</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>0.024675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mr</th>\n",
       "      <td>-0.549199</td>\n",
       "      <td>0.142698</td>\n",
       "      <td>-0.250489</td>\n",
       "      <td>-0.333905</td>\n",
       "      <td>-0.312117</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>-0.396920</td>\n",
       "      <td>-0.338014</td>\n",
       "      <td>-0.867334</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207843</td>\n",
       "      <td>-0.595692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.474952</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.083562</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>-0.041512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mrs</th>\n",
       "      <td>0.339040</td>\n",
       "      <td>-0.149209</td>\n",
       "      <td>0.063407</td>\n",
       "      <td>0.225852</td>\n",
       "      <td>0.245302</td>\n",
       "      <td>0.146407</td>\n",
       "      <td>0.365454</td>\n",
       "      <td>0.156168</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>-0.547600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>-0.474952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>-0.039872</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>-0.043914</td>\n",
       "      <td>0.015478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <td>-0.019137</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>-0.011875</td>\n",
       "      <td>0.082150</td>\n",
       "      <td>-0.024758</td>\n",
       "      <td>-0.035189</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.032924</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.006179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038825</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087893</td>\n",
       "      <td>-0.078529</td>\n",
       "      <td>-0.091182</td>\n",
       "      <td>-0.206928</td>\n",
       "      <td>-0.067067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <td>-0.081703</td>\n",
       "      <td>0.155894</td>\n",
       "      <td>0.084638</td>\n",
       "      <td>0.028529</td>\n",
       "      <td>-0.079605</td>\n",
       "      <td>-0.072051</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>-0.084090</td>\n",
       "      <td>0.084090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032784</td>\n",
       "      <td>-0.057497</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>-0.039872</td>\n",
       "      <td>-0.087893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.143093</td>\n",
       "      <td>-0.166150</td>\n",
       "      <td>-0.377058</td>\n",
       "      <td>-0.122208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <td>-0.012868</td>\n",
       "      <td>0.270416</td>\n",
       "      <td>-0.031555</td>\n",
       "      <td>-0.041927</td>\n",
       "      <td>-0.162293</td>\n",
       "      <td>-0.142312</td>\n",
       "      <td>-0.000926</td>\n",
       "      <td>-0.042513</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>-0.010421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063208</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>-0.078529</td>\n",
       "      <td>-0.143093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148449</td>\n",
       "      <td>-0.336886</td>\n",
       "      <td>-0.109188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <td>0.200178</td>\n",
       "      <td>-0.377124</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.263112</td>\n",
       "      <td>0.182356</td>\n",
       "      <td>0.122750</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.091776</td>\n",
       "      <td>-0.091776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>-0.083562</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>-0.091182</td>\n",
       "      <td>-0.166150</td>\n",
       "      <td>-0.148449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.391169</td>\n",
       "      <td>-0.126782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <td>-0.124049</td>\n",
       "      <td>0.157908</td>\n",
       "      <td>-0.112502</td>\n",
       "      <td>-0.033182</td>\n",
       "      <td>-0.194354</td>\n",
       "      <td>-0.062603</td>\n",
       "      <td>-0.130834</td>\n",
       "      <td>-0.093468</td>\n",
       "      <td>-0.045475</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>-0.043914</td>\n",
       "      <td>-0.206928</td>\n",
       "      <td>-0.377058</td>\n",
       "      <td>-0.336886</td>\n",
       "      <td>-0.391169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.287716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_8</th>\n",
       "      <td>0.097727</td>\n",
       "      <td>-0.324370</td>\n",
       "      <td>0.132163</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>0.314787</td>\n",
       "      <td>0.157564</td>\n",
       "      <td>0.031241</td>\n",
       "      <td>0.092818</td>\n",
       "      <td>0.052287</td>\n",
       "      <td>-0.052287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086656</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>-0.041512</td>\n",
       "      <td>0.015478</td>\n",
       "      <td>-0.067067</td>\n",
       "      <td>-0.122208</td>\n",
       "      <td>-0.109188</td>\n",
       "      <td>-0.126782</td>\n",
       "      <td>-0.287716</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Survived    Pclass     SibSp     Parch   FareBin    AgeBin  \\\n",
       "Survived       1.000000 -0.338481 -0.035322  0.081629  0.317783 -0.049771   \n",
       "Pclass        -0.338481  1.000000  0.083081  0.018443 -0.705206 -0.408902   \n",
       "SibSp         -0.035322  0.083081  1.000000  0.414838  0.354974 -0.238513   \n",
       "Parch          0.081629  0.018443  0.414838  1.000000  0.351317 -0.154571   \n",
       "FareBin        0.317783 -0.705206  0.354974  0.351317  1.000000  0.148150   \n",
       "AgeBin        -0.049771 -0.408902 -0.238513 -0.154571  0.148150  1.000000   \n",
       "IsAlone        0.203367 -0.135207  0.584471  0.583398  0.520277 -0.161040   \n",
       "FamilySize     0.016639  0.065997  0.890712  0.783111  0.418125 -0.240237   \n",
       "Sex_female     0.543351 -0.131900  0.114631  0.245489  0.244943 -0.093198   \n",
       "Sex_male      -0.543351  0.131900 -0.114631 -0.245489 -0.244943  0.093198   \n",
       "Embarked_C     0.168240 -0.243292 -0.059528 -0.011069  0.204579  0.042419   \n",
       "Embarked_Q     0.003650  0.221009 -0.026354 -0.081228 -0.243154 -0.088339   \n",
       "Embarked_S    -0.149683  0.074053  0.068734  0.060814 -0.026202  0.018431   \n",
       "Title_Master   0.085221  0.082081  0.349559  0.267344  0.124297 -0.324075   \n",
       "Title_Misc     0.022030 -0.206333 -0.036364 -0.067480  0.112454  0.176985   \n",
       "Title_Miss     0.327093 -0.000576  0.087932  0.105567  0.059106 -0.242363   \n",
       "Title_Mr      -0.549199  0.142698 -0.250489 -0.333905 -0.312117  0.169465   \n",
       "Title_Mrs      0.339040 -0.149209  0.063407  0.225852  0.245302  0.146407   \n",
       "Ticket_len_10 -0.019137  0.027858 -0.011875  0.082150 -0.024758 -0.035189   \n",
       "Ticket_len_30 -0.081703  0.155894  0.084638  0.028529 -0.079605 -0.072051   \n",
       "Ticket_len_4  -0.012868  0.270416 -0.031555 -0.041927 -0.162293 -0.142312   \n",
       "Ticket_len_5   0.200178 -0.377124  0.007149  0.003978  0.263112  0.182356   \n",
       "Ticket_len_6  -0.124049  0.157908 -0.112502 -0.033182 -0.194354 -0.062603   \n",
       "Ticket_len_8   0.097727 -0.324370  0.132163  0.004982  0.314787  0.157564   \n",
       "\n",
       "                IsAlone  FamilySize  Sex_female  Sex_male  ...  Title_Misc  \\\n",
       "Survived       0.203367    0.016639    0.543351 -0.543351  ...    0.022030   \n",
       "Pclass        -0.135207    0.065997   -0.131900  0.131900  ...   -0.206333   \n",
       "SibSp          0.584471    0.890712    0.114631 -0.114631  ...   -0.036364   \n",
       "Parch          0.583398    0.783111    0.245489 -0.245489  ...   -0.067480   \n",
       "FareBin        0.520277    0.418125    0.244943 -0.244943  ...    0.112454   \n",
       "AgeBin        -0.161040   -0.240237   -0.093198  0.093198  ...    0.176985   \n",
       "IsAlone        1.000000    0.690922    0.303646 -0.303646  ...   -0.049870   \n",
       "FamilySize     0.690922    1.000000    0.200988 -0.200988  ...   -0.058565   \n",
       "Sex_female     0.303646    0.200988    1.000000 -1.000000  ...   -0.034471   \n",
       "Sex_male      -0.303646   -0.200988   -1.000000  1.000000  ...    0.034471   \n",
       "Embarked_C     0.095298   -0.046215    0.082853 -0.082853  ...    0.065432   \n",
       "Embarked_Q    -0.086464   -0.058592    0.074115 -0.074115  ...   -0.007767   \n",
       "Embarked_S    -0.029074    0.077359   -0.119224  0.119224  ...   -0.052433   \n",
       "Title_Master   0.267024    0.372472   -0.159934  0.159934  ...   -0.038326   \n",
       "Title_Misc    -0.049870   -0.058565   -0.034471  0.034471  ...    1.000000   \n",
       "Title_Miss     0.055127    0.112838    0.686808 -0.686808  ...   -0.089565   \n",
       "Title_Mr      -0.396920   -0.338014   -0.867334  0.867334  ...   -0.207843   \n",
       "Title_Mrs      0.365454    0.156168    0.547600 -0.547600  ...   -0.071411   \n",
       "Ticket_len_10  0.018724    0.032924    0.006179 -0.006179  ...   -0.038825   \n",
       "Ticket_len_30  0.027469    0.072100   -0.084090  0.084090  ...   -0.032784   \n",
       "Ticket_len_4  -0.000926   -0.042513    0.010421 -0.010421  ...   -0.063208   \n",
       "Ticket_len_5   0.122750    0.006873    0.091776 -0.091776  ...    0.056025   \n",
       "Ticket_len_6  -0.130834   -0.093468   -0.045475  0.045475  ...   -0.009143   \n",
       "Ticket_len_8   0.031241    0.092818    0.052287 -0.052287  ...    0.086656   \n",
       "\n",
       "               Title_Miss  Title_Mr  Title_Mrs  Ticket_len_10  Ticket_len_30  \\\n",
       "Survived         0.327093 -0.549199   0.339040      -0.019137      -0.081703   \n",
       "Pclass          -0.000576  0.142698  -0.149209       0.027858       0.155894   \n",
       "SibSp            0.087932 -0.250489   0.063407      -0.011875       0.084638   \n",
       "Parch            0.105567 -0.333905   0.225852       0.082150       0.028529   \n",
       "FareBin          0.059106 -0.312117   0.245302      -0.024758      -0.079605   \n",
       "AgeBin          -0.242363  0.169465   0.146407      -0.035189      -0.072051   \n",
       "IsAlone          0.055127 -0.396920   0.365454       0.018724       0.027469   \n",
       "FamilySize       0.112838 -0.338014   0.156168       0.032924       0.072100   \n",
       "Sex_female       0.686808 -0.867334   0.547600       0.006179      -0.084090   \n",
       "Sex_male        -0.686808  0.867334  -0.547600      -0.006179       0.084090   \n",
       "Embarked_C       0.026215 -0.072567   0.061395      -0.105869      -0.068141   \n",
       "Embarked_Q       0.171117 -0.078338  -0.089739      -0.048484      -0.123085   \n",
       "Embarked_S      -0.130650  0.112870   0.002689       0.123257       0.137152   \n",
       "Title_Master    -0.109844 -0.254903  -0.087580       0.029992       0.038938   \n",
       "Title_Misc      -0.089565 -0.207843  -0.071411      -0.038825      -0.032784   \n",
       "Title_Miss       1.000000 -0.595692  -0.204670      -0.004981      -0.057497   \n",
       "Title_Mr        -0.595692  1.000000  -0.474952      -0.008576       0.070078   \n",
       "Title_Mrs       -0.204670 -0.474952   1.000000       0.019250      -0.039872   \n",
       "Ticket_len_10   -0.004981 -0.008576   0.019250       1.000000      -0.087893   \n",
       "Ticket_len_30   -0.057497  0.070078  -0.039872      -0.087893       1.000000   \n",
       "Ticket_len_4     0.020804  0.002834  -0.001728      -0.078529      -0.143093   \n",
       "Ticket_len_5     0.033341 -0.083562   0.078680      -0.091182      -0.166150   \n",
       "Ticket_len_6    -0.008851  0.035888  -0.043914      -0.206928      -0.377058   \n",
       "Ticket_len_8     0.024675 -0.041512   0.015478      -0.067067      -0.122208   \n",
       "\n",
       "               Ticket_len_4  Ticket_len_5  Ticket_len_6  Ticket_len_8  \n",
       "Survived          -0.012868      0.200178     -0.124049      0.097727  \n",
       "Pclass             0.270416     -0.377124      0.157908     -0.324370  \n",
       "SibSp             -0.031555      0.007149     -0.112502      0.132163  \n",
       "Parch             -0.041927      0.003978     -0.033182      0.004982  \n",
       "FareBin           -0.162293      0.263112     -0.194354      0.314787  \n",
       "AgeBin            -0.142312      0.182356     -0.062603      0.157564  \n",
       "IsAlone           -0.000926      0.122750     -0.130834      0.031241  \n",
       "FamilySize        -0.042513      0.006873     -0.093468      0.092818  \n",
       "Sex_female         0.010421      0.091776     -0.045475      0.052287  \n",
       "Sex_male          -0.010421     -0.091776      0.045475     -0.052287  \n",
       "Embarked_C         0.361630      0.026735     -0.339198      0.325325  \n",
       "Embarked_Q        -0.097372      0.018938      0.206393     -0.093921  \n",
       "Embarked_S        -0.255526     -0.035339      0.167268     -0.225893  \n",
       "Title_Master       0.007963     -0.044095      0.012919     -0.046801  \n",
       "Title_Misc        -0.063208      0.056025     -0.009143      0.086656  \n",
       "Title_Miss         0.020804      0.033341     -0.008851      0.024675  \n",
       "Title_Mr           0.002834     -0.083562      0.035888     -0.041512  \n",
       "Title_Mrs         -0.001728      0.078680     -0.043914      0.015478  \n",
       "Ticket_len_10     -0.078529     -0.091182     -0.206928     -0.067067  \n",
       "Ticket_len_30     -0.143093     -0.166150     -0.377058     -0.122208  \n",
       "Ticket_len_4       1.000000     -0.148449     -0.336886     -0.109188  \n",
       "Ticket_len_5      -0.148449      1.000000     -0.391169     -0.126782  \n",
       "Ticket_len_6      -0.336886     -0.391169      1.000000     -0.287716  \n",
       "Ticket_len_8      -0.109188     -0.126782     -0.287716      1.000000  \n",
       "\n",
       "[24 rows x 24 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap all preprocesses to a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_p (train, test):\n",
    "    train_c = data_clean(train)\n",
    "    train_f = f_eng(train_c)\n",
    "    y_train = train_f.Survived\n",
    "    X_train = train_f.drop('Survived', axis=1)\n",
    "    \n",
    "    test_c = data_clean(test)\n",
    "    test_f = f_eng(test_c)\n",
    "    X_test = test_f\n",
    "    \n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Ticket      0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "(891, 10)\n",
      "   Survived  Pclass                                               Name  \\\n",
      "0         0       3                            Braund, Mr. Owen Harris   \n",
      "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "2         1       3                             Heikkinen, Miss. Laina   \n",
      "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "4         0       3                           Allen, Mr. William Henry   \n",
      "\n",
      "      Sex   Age  SibSp  Parch            Ticket     Fare Embarked  \n",
      "0    male  22.0      1      0         A/5 21171   7.2500        S  \n",
      "1  female  38.0      1      0          PC 17599  71.2833        C  \n",
      "2  female  26.0      0      0  STON/O2. 3101282   7.9250        S  \n",
      "3  female  35.0      1      0            113803  53.1000        S  \n",
      "4    male  35.0      0      0            373450   8.0500        S  \n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Ticket      0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "(418, 9)\n",
      "   Pclass                                          Name     Sex   Age  SibSp  \\\n",
      "0       3                              Kelly, Mr. James    male  34.5      0   \n",
      "1       3              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1   \n",
      "2       2                     Myles, Mr. Thomas Francis    male  62.0      0   \n",
      "3       3                              Wirz, Mr. Albert    male  27.0      0   \n",
      "4       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1   \n",
      "\n",
      "   Parch   Ticket     Fare Embarked  \n",
      "0      0   330911   7.8292        Q  \n",
      "1      0   363272   7.0000        S  \n",
      "2      0   240276   9.6875        Q  \n",
      "3      0   315154   8.6625        S  \n",
      "4      1  3101298  12.2875        S  \n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test = pre_p (train_raw, test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <th>Ticket_len_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  SibSp  Parch  FareBin  AgeBin  IsAlone  FamilySize  Sex_female  \\\n",
       "0         3      1      0        1       2        1           2         0.0   \n",
       "1         1      1      0        5       3        1           2         1.0   \n",
       "2         3      0      0        2       2        0           1         1.0   \n",
       "3         1      1      0        5       3        1           2         1.0   \n",
       "4         3      0      0        2       3        0           1         0.0   \n",
       "..      ...    ...    ...      ...     ...      ...         ...         ...   \n",
       "886       2      0      0        3       2        0           1         0.0   \n",
       "887       1      0      0        4       2        0           1         1.0   \n",
       "888       3      1      2        4       2        1           4         1.0   \n",
       "889       1      0      0        4       2        0           1         0.0   \n",
       "890       3      0      0        1       2        0           1         0.0   \n",
       "\n",
       "     Sex_male  Embarked_C  ...  Title_Misc  Title_Miss  Title_Mr  Title_Mrs  \\\n",
       "0         1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "1         0.0         1.0  ...         0.0         0.0       0.0        1.0   \n",
       "2         0.0         0.0  ...         0.0         1.0       0.0        0.0   \n",
       "3         0.0         0.0  ...         0.0         0.0       0.0        1.0   \n",
       "4         1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "..        ...         ...  ...         ...         ...       ...        ...   \n",
       "886       1.0         0.0  ...         1.0         0.0       0.0        0.0   \n",
       "887       0.0         0.0  ...         0.0         1.0       0.0        0.0   \n",
       "888       0.0         0.0  ...         0.0         1.0       0.0        0.0   \n",
       "889       1.0         1.0  ...         0.0         0.0       1.0        0.0   \n",
       "890       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "\n",
       "     Ticket_len_10  Ticket_len_30  Ticket_len_4  Ticket_len_5  Ticket_len_6  \\\n",
       "0              0.0            1.0           0.0           0.0           0.0   \n",
       "1              0.0            0.0           0.0           0.0           0.0   \n",
       "2              0.0            1.0           0.0           0.0           0.0   \n",
       "3              0.0            0.0           0.0           0.0           1.0   \n",
       "4              0.0            0.0           0.0           0.0           1.0   \n",
       "..             ...            ...           ...           ...           ...   \n",
       "886            0.0            0.0           0.0           0.0           1.0   \n",
       "887            0.0            0.0           0.0           0.0           1.0   \n",
       "888            1.0            0.0           0.0           0.0           0.0   \n",
       "889            0.0            0.0           0.0           0.0           1.0   \n",
       "890            0.0            0.0           0.0           0.0           1.0   \n",
       "\n",
       "     Ticket_len_8  \n",
       "0             0.0  \n",
       "1             1.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "..            ...  \n",
       "886           0.0  \n",
       "887           0.0  \n",
       "888           0.0  \n",
       "889           0.0  \n",
       "890           0.0  \n",
       "\n",
       "[891 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model (X_tr, y_tr):\n",
    "    #this is from https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "    #Machine Learning Algorithm (MLA) Selection and Initialization\n",
    "    MLA = [\n",
    "        #Ensemble Methods\n",
    "        ensemble.AdaBoostClassifier(),\n",
    "        ensemble.BaggingClassifier(),\n",
    "        ensemble.ExtraTreesClassifier(),\n",
    "        ensemble.GradientBoostingClassifier(),\n",
    "        ensemble.RandomForestClassifier(),\n",
    "\n",
    "        #Gaussian Processes\n",
    "        gaussian_process.GaussianProcessClassifier(),\n",
    "\n",
    "        #GLM\n",
    "        linear_model.LogisticRegressionCV(),\n",
    "        linear_model.PassiveAggressiveClassifier(),\n",
    "        linear_model.RidgeClassifierCV(),\n",
    "        linear_model.SGDClassifier(),\n",
    "        linear_model.Perceptron(),\n",
    "\n",
    "        #Navies Bayes\n",
    "        naive_bayes.BernoulliNB(),\n",
    "        naive_bayes.GaussianNB(),\n",
    "\n",
    "        #Nearest Neighbor\n",
    "        neighbors.KNeighborsClassifier(),\n",
    "\n",
    "        #SVM\n",
    "        svm.SVC(probability=True),\n",
    "        svm.NuSVC(probability=True),\n",
    "        svm.LinearSVC(),\n",
    "\n",
    "        #Trees    \n",
    "        tree.DecisionTreeClassifier(),\n",
    "        tree.ExtraTreeClassifier(),\n",
    "\n",
    "        #Discriminant Analysis\n",
    "        discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "        discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "\n",
    "        #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "        XGBClassifier()    \n",
    "        ]\n",
    "    \n",
    "    #split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
    "    #note: this is an alternative to train_test_split\n",
    "    #cv_split = model_selection.ShuffleSplit(test_size = .2, train_size = .8, random_state = 0 ) # run model 10x with 80/20 split intentionally leaving out 10%\n",
    "\n",
    "    #create table to compare MLA metrics\n",
    "    MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
    "    MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "    #create table to compare MLA predictions\n",
    "    MLA_predict = y_tr\n",
    "\n",
    "    #index through MLA and save performance to table\n",
    "    row_index = 0\n",
    "    for alg in MLA:\n",
    "\n",
    "        #set name and parameters\n",
    "        MLA_name = alg.__class__.__name__\n",
    "        #print(MLA_name)\n",
    "        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "        MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "        #print(y_tr.shape)\n",
    "\n",
    "        #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "        cv_results = model_selection.cross_validate(alg, X_tr, y_tr, cv = 5, scoring='accuracy', return_train_score=True)\n",
    "        \n",
    "\n",
    "        MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
    "        MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "        MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
    "        #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "        MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "\n",
    "\n",
    "        #save MLA predictions - see section 6 for usage\n",
    "        #alg.fit(X_tr, y_tr)\n",
    "        #MLA_predict[MLA_name] = alg.predict(X_tr)\n",
    "\n",
    "        row_index+=1\n",
    "\n",
    "\n",
    "    #print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "    MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "    return MLA_compare\n",
    "    #MLA_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = base_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>0.833893</td>\n",
       "      <td>0.830507</td>\n",
       "      <td>0.0714191</td>\n",
       "      <td>0.0748039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>0.838385</td>\n",
       "      <td>0.828278</td>\n",
       "      <td>0.0809773</td>\n",
       "      <td>0.0508637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n",
       "      <td>0.832491</td>\n",
       "      <td>0.828259</td>\n",
       "      <td>0.0622931</td>\n",
       "      <td>0.147605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n",
       "      <td>0.841192</td>\n",
       "      <td>0.827173</td>\n",
       "      <td>0.0825726</td>\n",
       "      <td>0.517615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'n_components': None, 'priors': None, 'shrink...</td>\n",
       "      <td>0.835579</td>\n",
       "      <td>0.827142</td>\n",
       "      <td>0.0838288</td>\n",
       "      <td>0.00558491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'cols...</td>\n",
       "      <td>0.862515</td>\n",
       "      <td>0.826062</td>\n",
       "      <td>0.102924</td>\n",
       "      <td>0.0696249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>0.874578</td>\n",
       "      <td>0.826056</td>\n",
       "      <td>0.0979529</td>\n",
       "      <td>0.113901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n",
       "      <td>0.835298</td>\n",
       "      <td>0.824895</td>\n",
       "      <td>0.0753055</td>\n",
       "      <td>0.00854425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
       "      <td>0.89422</td>\n",
       "      <td>0.820438</td>\n",
       "      <td>0.0608934</td>\n",
       "      <td>0.255209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.866442</td>\n",
       "      <td>0.818204</td>\n",
       "      <td>0.0916285</td>\n",
       "      <td>0.00458841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.832214</td>\n",
       "      <td>0.814833</td>\n",
       "      <td>0.0606862</td>\n",
       "      <td>0.0809761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.91807</td>\n",
       "      <td>0.806968</td>\n",
       "      <td>0.0834529</td>\n",
       "      <td>0.158078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.91807</td>\n",
       "      <td>0.803609</td>\n",
       "      <td>0.101338</td>\n",
       "      <td>0.137219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.912176</td>\n",
       "      <td>0.799127</td>\n",
       "      <td>0.0634939</td>\n",
       "      <td>0.0219402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
       "      <td>0.80528</td>\n",
       "      <td>0.790095</td>\n",
       "      <td>0.116487</td>\n",
       "      <td>0.00279284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>0.803589</td>\n",
       "      <td>0.789021</td>\n",
       "      <td>0.0629193</td>\n",
       "      <td>0.00219421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
       "      <td>0.792929</td>\n",
       "      <td>0.783391</td>\n",
       "      <td>0.0527954</td>\n",
       "      <td>0.00339112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.91807</td>\n",
       "      <td>0.782286</td>\n",
       "      <td>0.113146</td>\n",
       "      <td>0.00339079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.91807</td>\n",
       "      <td>0.782255</td>\n",
       "      <td>0.0915646</td>\n",
       "      <td>0.00279284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n",
       "      <td>0.764604</td>\n",
       "      <td>0.749714</td>\n",
       "      <td>0.198497</td>\n",
       "      <td>0.00358987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
       "      <td>0.76038</td>\n",
       "      <td>0.736275</td>\n",
       "      <td>0.179284</td>\n",
       "      <td>0.00458775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
       "      <td>0.673969</td>\n",
       "      <td>0.677898</td>\n",
       "      <td>0.126625</td>\n",
       "      <td>0.00339041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "14                            SVC   \n",
       "16                      LinearSVC   \n",
       "15                          NuSVC   \n",
       "6            LogisticRegressionCV   \n",
       "19     LinearDiscriminantAnalysis   \n",
       "21                  XGBClassifier   \n",
       "3      GradientBoostingClassifier   \n",
       "8               RidgeClassifierCV   \n",
       "5       GaussianProcessClassifier   \n",
       "13           KNeighborsClassifier   \n",
       "0              AdaBoostClassifier   \n",
       "4          RandomForestClassifier   \n",
       "2            ExtraTreesClassifier   \n",
       "1               BaggingClassifier   \n",
       "10                     Perceptron   \n",
       "12                     GaussianNB   \n",
       "11                    BernoulliNB   \n",
       "17         DecisionTreeClassifier   \n",
       "18            ExtraTreeClassifier   \n",
       "7     PassiveAggressiveClassifier   \n",
       "9                   SGDClassifier   \n",
       "20  QuadraticDiscriminantAnalysis   \n",
       "\n",
       "                                       MLA Parameters MLA Train Accuracy Mean  \\\n",
       "14  {'C': 1.0, 'break_ties': False, 'cache_size': ...                0.833893   \n",
       "16  {'C': 1.0, 'class_weight': None, 'dual': True,...                0.838385   \n",
       "15  {'break_ties': False, 'cache_size': 200, 'clas...                0.832491   \n",
       "6   {'Cs': 10, 'class_weight': None, 'cv': None, '...                0.841192   \n",
       "19  {'n_components': None, 'priors': None, 'shrink...                0.835579   \n",
       "21  {'base_score': 0.5, 'booster': 'gbtree', 'cols...                0.862515   \n",
       "3   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...                0.874578   \n",
       "8   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...                0.835298   \n",
       "5   {'copy_X_train': True, 'kernel': None, 'max_it...                 0.89422   \n",
       "13  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.866442   \n",
       "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...                0.832214   \n",
       "4   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...                 0.91807   \n",
       "2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...                 0.91807   \n",
       "1   {'base_estimator': None, 'bootstrap': True, 'b...                0.912176   \n",
       "10  {'alpha': 0.0001, 'class_weight': None, 'early...                 0.80528   \n",
       "12           {'priors': None, 'var_smoothing': 1e-09}                0.803589   \n",
       "11  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...                0.792929   \n",
       "17  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...                 0.91807   \n",
       "18  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...                 0.91807   \n",
       "7   {'C': 1.0, 'average': False, 'class_weight': N...                0.764604   \n",
       "9   {'alpha': 0.0001, 'average': False, 'class_wei...                 0.76038   \n",
       "20  {'priors': None, 'reg_param': 0.0, 'store_cova...                0.673969   \n",
       "\n",
       "   MLA Test Accuracy Mean MLA Test Accuracy 3*STD    MLA Time  \n",
       "14               0.830507               0.0714191   0.0748039  \n",
       "16               0.828278               0.0809773   0.0508637  \n",
       "15               0.828259               0.0622931    0.147605  \n",
       "6                0.827173               0.0825726    0.517615  \n",
       "19               0.827142               0.0838288  0.00558491  \n",
       "21               0.826062                0.102924   0.0696249  \n",
       "3                0.826056               0.0979529    0.113901  \n",
       "8                0.824895               0.0753055  0.00854425  \n",
       "5                0.820438               0.0608934    0.255209  \n",
       "13               0.818204               0.0916285  0.00458841  \n",
       "0                0.814833               0.0606862   0.0809761  \n",
       "4                0.806968               0.0834529    0.158078  \n",
       "2                0.803609                0.101338    0.137219  \n",
       "1                0.799127               0.0634939   0.0219402  \n",
       "10               0.790095                0.116487  0.00279284  \n",
       "12               0.789021               0.0629193  0.00219421  \n",
       "11               0.783391               0.0527954  0.00339112  \n",
       "17               0.782286                0.113146  0.00339079  \n",
       "18               0.782255               0.0915646  0.00279284  \n",
       "7                0.749714                0.198497  0.00358987  \n",
       "9                0.736275                0.179284  0.00458775  \n",
       "20               0.677898                0.126625  0.00339041  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Algorithm')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\n",
    "sns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = compare_df, color = 'm')\n",
    "\n",
    "#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\n",
    "plt.title('Machine Learning Algorithm Accuracy Score \\n')\n",
    "plt.xlabel('Accuracy Score (%)')\n",
    "plt.ylabel('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is borrowed from the Kaggle notebook https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "#the original idea was to take the top ten from our list above, but since the alg list below covers a large portion of our top ten, we will use it directly\n",
    "def hp_tunre():\n",
    "    \n",
    "    vote_est = [\n",
    "                #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n",
    "                ('ada', ensemble.AdaBoostClassifier()),\n",
    "                ('bc', ensemble.BaggingClassifier()),\n",
    "                ('etc',ensemble.ExtraTreesClassifier()),\n",
    "                ('gbc', ensemble.GradientBoostingClassifier()),\n",
    "                ('rfc', ensemble.RandomForestClassifier()),\n",
    "\n",
    "                #Gaussian Processes: http://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process-classification-gpc\n",
    "                ('gpc', gaussian_process.GaussianProcessClassifier()),\n",
    "\n",
    "                #GLM: http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "                ('lr', linear_model.LogisticRegressionCV()),\n",
    "\n",
    "                #Navies Bayes: http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "                ('bnb', naive_bayes.BernoulliNB()),\n",
    "                ('gnb', naive_bayes.GaussianNB()),\n",
    "\n",
    "                #Nearest Neighbor: http://scikit-learn.org/stable/modules/neighbors.html\n",
    "                ('knn', neighbors.KNeighborsClassifier()),\n",
    "\n",
    "                #SVM: http://scikit-learn.org/stable/modules/svm.html\n",
    "                ('svc', svm.SVC(probability=True)),\n",
    "\n",
    "                #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "               ('xgb', XGBClassifier())\n",
    "\n",
    "                ]\n",
    "    \n",
    "    #Hyperparameter Tune with GridSearchCV: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "    grid_n_estimator = [10, 50, 100, 300, 500]\n",
    "    grid_ratio = [.1, .25, .5, .75, 1.0]\n",
    "    grid_learn = [.01, .03, .05, .1, .25]\n",
    "    grid_max_depth = [2, 4, 6, 8, 10, None]\n",
    "    grid_min_samples = [5, 10, .03, .05, .10]\n",
    "    grid_criterion = ['gini', 'entropy']\n",
    "    grid_bool = [True, False]\n",
    "    grid_seed = [0]\n",
    "\n",
    "\n",
    "    grid_param = [\n",
    "                [{\n",
    "                #AdaBoostClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "                'n_estimators': grid_n_estimator, #default=50\n",
    "                'learning_rate': grid_learn, #default=1\n",
    "                #'algorithm': ['SAMME', 'SAMME.R'], #default=SAMME.R\n",
    "                'random_state': grid_seed\n",
    "                }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #BaggingClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier\n",
    "                'n_estimators': grid_n_estimator, #default=10\n",
    "                'max_samples': grid_ratio, #default=1.0\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #ExtraTreesClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier\n",
    "                'n_estimators': grid_n_estimator, #default=10\n",
    "                'criterion': grid_criterion, #default=gini\n",
    "                'max_depth': grid_max_depth, #default=None\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #GradientBoostingClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n",
    "                #'loss': ['deviance', 'exponential'], #default=deviance\n",
    "                'learning_rate': [.05], #default=0.1 -- 12/31/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.\n",
    "                'n_estimators': [300], #default=100 -- 12/31/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.\n",
    "                #'criterion': ['friedman_mse', 'mse', 'mae'], #default=friedman_mse\n",
    "                'max_depth': grid_max_depth, #default=3   \n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #RandomForestClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "                'n_estimators': grid_n_estimator, #default=10\n",
    "                'criterion': grid_criterion, #default=gini\n",
    "                'max_depth': grid_max_depth, #default=None\n",
    "                'oob_score': [True], #default=False -- 12/31/17 set to reduce runtime -- The best parameter for RandomForestClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'oob_score': True, 'random_state': 0} with a runtime of 146.35 seconds.\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "                [{    \n",
    "                #GaussianProcessClassifier\n",
    "                'max_iter_predict': grid_n_estimator, #default: 100\n",
    "                'random_state': grid_seed\n",
    "                }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #LogisticRegressionCV - http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV\n",
    "                'fit_intercept': grid_bool, #default: True\n",
    "                #'penalty': ['l1','l2'],\n",
    "                'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], #default: lbfgs\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #BernoulliNB - http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB\n",
    "                'alpha': grid_ratio, #default: 1.0\n",
    "                 }],\n",
    "\n",
    "\n",
    "                #GaussianNB - \n",
    "                [{}],\n",
    "\n",
    "                [{\n",
    "                #KNeighborsClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "                'n_neighbors': [1,2,3,4,5,6,7], #default: 5\n",
    "                'weights': ['uniform', 'distance'], #default = uniform\n",
    "                'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "                }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #SVC - http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "                #http://blog.hackerearth.com/simple-tutorial-svm-parameter-tuning-python-r\n",
    "                #'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                'C': [1,2,3,4,5], #default=1.0\n",
    "                'gamma': grid_ratio, #edfault: auto\n",
    "                'decision_function_shape': ['ovo', 'ovr'], #default:ovr\n",
    "                'probability': [True],\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #XGBClassifier - http://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "                'learning_rate': grid_learn, #default: .3\n",
    "                'max_depth': [1,2,4,6,8,10], #default 2\n",
    "                'n_estimators': grid_n_estimator, \n",
    "                'seed': grid_seed  \n",
    "                 }]   \n",
    "            ]\n",
    "\n",
    "    \n",
    "    #create a table to display key metrics\n",
    "    hp_columns = ['Alg Name', 'Best Score', 'Score Before Tuning', 'Best Parameters']\n",
    "    hp_compare = pd.DataFrame(columns = hp_columns)\n",
    "\n",
    "    #index through MLA and save performance to table\n",
    "    row_index = 0\n",
    "\n",
    "    for clf, param in zip (vote_est, grid_param): #https://docs.python.org/3/library/functions.html#zip\n",
    "\n",
    "     \n",
    "        best_search = model_selection.GridSearchCV(estimator = clf[1], param_grid = param, cv = 5, scoring = 'accuracy')\n",
    "        best_search.fit(X_train, y_train)\n",
    "\n",
    "        best_param = best_search.best_params_\n",
    "        best_score = best_search.best_score_\n",
    "        alg_name = clf[1].__class__.__name__\n",
    "        #print('The best parameter for {} is {} with a runtime of {:.2f} seconds.'.format(clf[1].__class__.__name__, best_param, run))\n",
    "        clf[1].set_params(**best_param) \n",
    "        \n",
    "        hp_compare.loc[row_index, 'Alg Name'] = alg_name\n",
    "        hp_compare.loc[row_index, 'Best Parameters'] = str(best_param)\n",
    "        hp_compare.loc[row_index, 'Best Score'] = best_score\n",
    "        hp_compare.loc[row_index, 'Score Before Tuning'] = compare_df.loc[compare_df['MLA Name'] == alg_name]['MLA Test Accuracy Mean'].tolist()[0]\n",
    "        row_index+=1\n",
    "\n",
    "\n",
    "    print('Done')\n",
    "    print('-'*10)\n",
    "    \n",
    "    return vote_est, hp_compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "tuned_algs, hp_compare = hp_tunre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alg Name</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Score Before Tuning</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.827161</td>\n",
       "      <td>0.814833</td>\n",
       "      <td>{'learning_rate': 0.03, 'n_estimators': 500, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.82718</td>\n",
       "      <td>0.799127</td>\n",
       "      <td>{'max_samples': 0.5, 'n_estimators': 500, 'ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.828253</td>\n",
       "      <td>0.803609</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'n_estim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.826044</td>\n",
       "      <td>0.826056</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 2, 'n_est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.828278</td>\n",
       "      <td>0.806968</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'n_estim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>0.820438</td>\n",
       "      <td>0.820438</td>\n",
       "      <td>{'max_iter_predict': 10, 'random_state': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.827173</td>\n",
       "      <td>0.827173</td>\n",
       "      <td>{'fit_intercept': True, 'random_state': 0, 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.783391</td>\n",
       "      <td>0.783391</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.789021</td>\n",
       "      <td>0.789021</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.819333</td>\n",
       "      <td>0.818204</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 5, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.830507</td>\n",
       "      <td>0.830507</td>\n",
       "      <td>{'C': 3, 'decision_function_shape': 'ovo', 'ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.838378</td>\n",
       "      <td>0.826062</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 6, 'n_est...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Alg Name Best Score Score Before Tuning  \\\n",
       "0           AdaBoostClassifier   0.827161            0.814833   \n",
       "1            BaggingClassifier    0.82718            0.799127   \n",
       "2         ExtraTreesClassifier   0.828253            0.803609   \n",
       "3   GradientBoostingClassifier   0.826044            0.826056   \n",
       "4       RandomForestClassifier   0.828278            0.806968   \n",
       "5    GaussianProcessClassifier   0.820438            0.820438   \n",
       "6         LogisticRegressionCV   0.827173            0.827173   \n",
       "7                  BernoulliNB   0.783391            0.783391   \n",
       "8                   GaussianNB   0.789021            0.789021   \n",
       "9         KNeighborsClassifier   0.819333            0.818204   \n",
       "10                         SVC   0.830507            0.830507   \n",
       "11               XGBClassifier   0.838378            0.826062   \n",
       "\n",
       "                                      Best Parameters  \n",
       "0   {'learning_rate': 0.03, 'n_estimators': 500, '...  \n",
       "1   {'max_samples': 0.5, 'n_estimators': 500, 'ran...  \n",
       "2   {'criterion': 'gini', 'max_depth': 6, 'n_estim...  \n",
       "3   {'learning_rate': 0.05, 'max_depth': 2, 'n_est...  \n",
       "4   {'criterion': 'gini', 'max_depth': 6, 'n_estim...  \n",
       "5         {'max_iter_predict': 10, 'random_state': 0}  \n",
       "6   {'fit_intercept': True, 'random_state': 0, 'so...  \n",
       "7                                      {'alpha': 0.1}  \n",
       "8                                                  {}  \n",
       "9   {'algorithm': 'ball_tree', 'n_neighbors': 5, '...  \n",
       "10  {'C': 3, 'decision_function_shape': 'ovo', 'ga...  \n",
       "11  {'learning_rate': 0.05, 'max_depth': 6, 'n_est...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7991274872889336"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_df.loc[compare_df['MLA Name'] == 'BaggingClassifier']['MLA Test Accuracy Mean'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-a5154581fdf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhp_compare\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Score Before Tune'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcompare_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MLA Name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mhp_compare\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Alg Name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MLA Test Accuracy Mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indexed_same\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can only compare identically-labeled Series objects\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    "hp_compare['Score Before Tune'] = compare_df.loc[compare_df['MLA Name'] == hp_compare['Alg Name']]['MLA Test Accuracy Mean'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
