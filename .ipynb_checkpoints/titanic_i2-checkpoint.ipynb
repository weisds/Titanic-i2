{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of Attack\n",
    "- Understand the data, size of the data (column/row), size of missing data, columns to drop\n",
    "- Data Cleaning\n",
    "    - data outliers\n",
    "    - correct the data\n",
    "    - fillna()\n",
    "- EDA, look at numarical and object(string) data seperatly, to determine\n",
    "    - normalization/scale the data\n",
    "    - determine potential feature engineering approaches\n",
    "- Feature Engineering according to the findings\n",
    "- Def function for data preprocessing\n",
    "- Run Models\n",
    "- Voting\n",
    "- Output the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 2.7.18 |Anaconda, Inc.| (default, Apr 23 2020, 17:26:54) [MSC v.1500 64 bit (AMD64)]\n",
      "pandas version: 0.24.2\n",
      "matplotlib version: 2.2.3\n",
      "NumPy version: 1.16.6\n",
      "SciPy version: 1.2.1\n",
      "IPython version: 5.8.0\n",
      "scikit-learn version: 0.20.3\n",
      "seaborn version: 0.9.0\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# This block is from https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "#load packages\n",
    "import sys #access to system parameters https://docs.python.org/3/library/sys.html\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "import pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import matplotlib #collection of functions for scientific and publication-ready visualization\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np #foundational package for scientific computing\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "import scipy as sp #collection of functions for scientific computing and advance mathematics\n",
    "print(\"SciPy version: {}\". format(sp.__version__)) \n",
    "\n",
    "import IPython\n",
    "from IPython import display #pretty printing of dataframes in Jupyter notebook\n",
    "print(\"IPython version: {}\". format(IPython.__version__)) \n",
    "\n",
    "import sklearn #collection of machine learning algorithms\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "import seaborn as sns #collection of functions for data visualization\n",
    "print(\"seaborn version: {}\". format(sns.__version__))\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder #OneHot Encoder\n",
    "\n",
    "\n",
    "#misc libraries\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is from https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "\n",
    "#Common Model Algorithms\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "#from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "#Configure Visualization Defaults\n",
    "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
    "%matplotlib inline\n",
    "#mpl.style.use('ggplot')\n",
    "#sns.set_style('white')\n",
    "#pylab.rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train_raw = pd.read_csv('data/train.csv')\n",
    "test_raw = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the data\n",
    "\n",
    "In this stage, we take a bird's eye view of the data, to understand\n",
    "- size of the data\n",
    "- obvious errors, e.g. data outliers\n",
    "- holes in the data\n",
    "- what type of data, string, int, cat, date?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.info()\n",
    "train_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- This data consist of numaric, string (object), and the Ticket column contains a combination of string and numarical values\n",
    "- We have a total 12 columns\n",
    "- Age has some missing data, marjority of Cabin data are missing, two missing values in Embarked\n",
    "- judging from std, min and max, we can conclude that data in PassengerId are pretty evenly distributed\n",
    "\n",
    "#### Plan of action\n",
    "- Split the data by dtype (string vs numeric) for targeted actions\n",
    "- Need to handle missing data in Age, Cabin (drop, due to the large amount), and Embarked\n",
    "- Consider dropping PassengerId due to the lack of trend in the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "In this stage, we want to fill in the holes in the data to lay the foundation for later imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let split the data for more targeted handling\n",
    "txt_cols = [cname for cname in train_raw.columns if train_raw[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "num_cols = [cname for cname in train_raw.columns if train_raw[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "txt_data = train_raw[txt_cols].copy()\n",
    "num_data = train_raw[num_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to make sure we didn't accidentally drop any cols\n",
    "txt_data.shape[1] + num_data.shape[1] == train_raw.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Cols\n",
    "Let's first look at num data to see what needs to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Age          714 non-null    float64\n",
      " 4   SibSp        891 non-null    int64  \n",
      " 5   Parch        891 non-null    int64  \n",
      " 6   Fare         891 non-null    float64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 48.9 KB\n"
     ]
    }
   ],
   "source": [
    "#now let us look at the numaric cols\n",
    "num_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.87%\n"
     ]
    }
   ],
   "source": [
    "age_missing_per = num_data.Age.isnull().sum()/len(num_data.Age)\n",
    "print(\"{:.2%}\".format(age_missing_per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "We have close to 20% of Age data that are missing from the dataset, let's think of a cleverer way to fill in the gaps\n",
    "#### Action\n",
    "The idea is to find corrolating features with Age, create a lookup table to impute missing Age values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e1c0ed3bc8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to find corrolating features\n",
    "sns.heatmap(train_raw.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-0-0    324\n",
       "1-0-0    109\n",
       "2-0-0    104\n",
       "1-1-0     51\n",
       "3-1-0     46\n",
       "2-1-0     26\n",
       "3-1-1     25\n",
       "2-1-1     20\n",
       "1-0-1     19\n",
       "1-1-1     12\n",
       "3-0-2     12\n",
       "3-0-1     11\n",
       "3-2-0     10\n",
       "1-0-2      9\n",
       "3-4-2      9\n",
       "3-4-1      9\n",
       "2-1-2      8\n",
       "2-0-2      8\n",
       "2-0-1      8\n",
       "3-3-1      7\n",
       "3-8-2      7\n",
       "1-1-2      7\n",
       "3-5-2      5\n",
       "3-1-2      4\n",
       "3-3-2      4\n",
       "2-2-1      4\n",
       "1-3-2      3\n",
       "3-2-1      3\n",
       "2-2-0      3\n",
       "1-2-0      3\n",
       "3-1-5      3\n",
       "3-0-5      2\n",
       "3-2-2      2\n",
       "1-2-2      2\n",
       "3-1-4      2\n",
       "3-1-3      2\n",
       "3-0-3      1\n",
       "2-2-3      1\n",
       "2-1-3      1\n",
       "3-1-6      1\n",
       "3-0-4      1\n",
       "1-1-4      1\n",
       "2-3-0      1\n",
       "3-3-0      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we see that Pclass, Sibsp, Parch are highly corrolated with Age\n",
    "Pclass_Sibsp_Parch = train_raw['Pclass'].apply(str)+'-'+train_raw['SibSp'].apply(str)+'-'+train_raw['Parch'].apply(str)\n",
    "Pclass_Sibsp_Parch.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "It is clear that majority of the data can categorized into 3-0-0, 1-0-0 and 2-0-0\n",
    "#### Action\n",
    "Let's create a look up table with 3-0-0, 1-0-0 and 2-0-0 as the three major classes, and put the rest into the 'other' bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = { 'Pclass_Sibsp_Parch': Pclass_Sibsp_Parch, 'Age': train_raw.Age } \n",
    "age_psp = pd.DataFrame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_classes = ['3-0-0', '1-0-0', '2-0-0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other    354\n",
       "3-0-0    324\n",
       "1-0-0    109\n",
       "2-0-0    104\n",
       "Name: Pclass_Sibsp_Parch, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_psp['Pclass_Sibsp_Parch'] = age_psp['Pclass_Sibsp_Parch'].apply(lambda x: x if x in age_classes else 'other')\n",
    "age_psp['Pclass_Sibsp_Parch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_lookup= age_psp.groupby(\"Pclass_Sibsp_Parch\", as_index=False).mean()\n",
    "age_lookup = age_lookup.set_index('Pclass_Sibsp_Parch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data['temp_psp'] = age_psp['Pclass_Sibsp_Parch']\n",
    "num_data['temp_age_cat_mean'] = num_data['temp_psp']\n",
    "num_data['temp_age_cat_mean'] = num_data['temp_age_cat_mean'].apply(lambda x: age_lookup['Age'][x])\n",
    "num_data['Age'] = num_data['Age'].fillna(num_data['temp_age_cat_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to see if there is still null values in the data\n",
    "num_data['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = num_data.drop('temp_psp', axis=1)\n",
    "num_data = num_data.drop('temp_age_cat_mean', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at 'PassengerId' to decide if we should drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e1c13580c8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_data['PassengerId'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there is no observable trend the data, let's drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = num_data.drop('PassengerId', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name          0\n",
       "Sex           0\n",
       "Ticket        0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- large number of missing value in Cabin, let's drop it\n",
    "- only two missing value in Embarked, fill with most freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_data = txt_data.drop('Cabin', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_data['Embarked'] = txt_data['Embarked'].fillna(txt_data['Embarked'].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        0\n",
       "Sex         0\n",
       "Ticket      0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's def the data_cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean (df):\n",
    "    #create lookup table for Age\n",
    "    psp = df['Pclass'].apply(str)+'-'+df['SibSp'].apply(str)+'-'+df['Parch'].apply(str)\n",
    "    frame = { 'Pclass_Sibsp_Parch': psp, 'Age': df.Age } \n",
    "    psp_age = pd.DataFrame(frame)\n",
    "    #define age classes, other not yet included\n",
    "    age_classes = ['3-0-0', '1-0-0', '2-0-0']\n",
    "    #convert excluding items to 'other'\n",
    "    psp_age['Pclass_Sibsp_Parch'] = psp_age['Pclass_Sibsp_Parch'].apply(lambda x: x if x in age_classes else 'other')\n",
    "    #transform to a lookup table\n",
    "    am_lookup= psp_age.groupby('Pclass_Sibsp_Parch').mean()\n",
    "    #using the lookup table\n",
    "    df['temp_psp'] = psp_age['Pclass_Sibsp_Parch'] #setup a temp col with psp lables\n",
    "    df['temp_age_cat_mean'] = df['temp_psp'] #create a col for age means conversions\n",
    "    df['temp_age_cat_mean'] = df['temp_age_cat_mean'].apply(lambda x: am_lookup['Age'][x]) #convert values in this col to age means according to the psp lable\n",
    "    df['Age'] = df['Age'].fillna(df['temp_age_cat_mean']) #fill na according to the tempt mean col\n",
    "    #drop the temp cols\n",
    "    df = df.drop('temp_psp', axis=1)\n",
    "    df = df.drop('temp_age_cat_mean', axis=1)\n",
    "    \n",
    "    #found that there are missing valuse in Fare in the test dataset\n",
    "    df['Fare'] = df['Fare'].fillna(method='ffill')\n",
    "    \n",
    "    #for reasons stated above we don't want PassengerId, Cabin cols\n",
    "    df = df.drop('PassengerId', axis=1)\n",
    "    df = df.drop('Cabin', axis=1)\n",
    "    \n",
    "    #fill na for Embarked, only two \n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].value_counts().index[0])\n",
    "    \n",
    "    #do a final check\n",
    "    print(df.isnull().sum())\n",
    "    print(df.shape)\n",
    "\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "In this stage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.715957</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.165460</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.235556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.715957    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   13.165460    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.235556    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   36.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "We have Age and Fare containing continouse valuse\n",
    "#### Action\n",
    "For classification problem, we hypothesize that discrete values will be better fit for the algorithms, let's proceed with the conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.413452</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass        Age  SibSp  Parch     Fare  FareBin  AgeBin\n",
       "0           0       3  22.000000      1      0   7.2500        1       2\n",
       "1           1       1  38.000000      1      0  71.2833        5       3\n",
       "2           1       3  26.000000      0      0   7.9250        2       2\n",
       "3           1       1  35.000000      1      0  53.1000        5       3\n",
       "4           0       3  35.000000      0      0   8.0500        2       3\n",
       "..        ...     ...        ...    ...    ...      ...      ...     ...\n",
       "886         0       2  27.000000      0      0  13.0000        3       2\n",
       "887         1       1  19.000000      0      0  30.0000        4       2\n",
       "888         0       3  26.413452      1      2  23.4500        4       2\n",
       "889         1       1  26.000000      0      0  30.0000        4       2\n",
       "890         0       3  32.000000      0      0   7.7500        1       2\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data['FareBin'] = pd.qcut(num_data['Fare'], 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "num_data['AgeBin'] = pd.cut(num_data['Age'].astype(int), 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.069834</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.049771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.379096</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>-0.408902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.069834</td>\n",
       "      <td>-0.379096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.255773</td>\n",
       "      <td>-0.188705</td>\n",
       "      <td>0.101817</td>\n",
       "      <td>0.129939</td>\n",
       "      <td>0.940683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.255773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>-0.238513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.188705</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>-0.154571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.101817</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600883</td>\n",
       "      <td>0.128427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FareBin</th>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>0.129939</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>0.600883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBin</th>\n",
       "      <td>-0.049771</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>0.940683</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.128427</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived    Pclass       Age     SibSp     Parch      Fare  \\\n",
       "Survived  1.000000 -0.338481 -0.069834 -0.035322  0.081629  0.257307   \n",
       "Pclass   -0.338481  1.000000 -0.379096  0.083081  0.018443 -0.549500   \n",
       "Age      -0.069834 -0.379096  1.000000 -0.255773 -0.188705  0.101817   \n",
       "SibSp    -0.035322  0.083081 -0.255773  1.000000  0.414838  0.159651   \n",
       "Parch     0.081629  0.018443 -0.188705  0.414838  1.000000  0.216225   \n",
       "Fare      0.257307 -0.549500  0.101817  0.159651  0.216225  1.000000   \n",
       "FareBin   0.317783 -0.705206  0.129939  0.354974  0.351317  0.600883   \n",
       "AgeBin   -0.049771 -0.408902  0.940683 -0.238513 -0.154571  0.128427   \n",
       "\n",
       "           FareBin    AgeBin  \n",
       "Survived  0.317783 -0.049771  \n",
       "Pclass   -0.705206 -0.408902  \n",
       "Age       0.129939  0.940683  \n",
       "SibSp     0.354974 -0.238513  \n",
       "Parch     0.351317 -0.154571  \n",
       "Fare      0.600883  0.128427  \n",
       "FareBin   1.000000  0.148150  \n",
       "AgeBin    0.148150  1.000000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at if the new features are actually useful\n",
    "num_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "We see that FareBin has a better corrolation with Survived, whereas AgeBin has a lower correlation coefficient than raw Age\n",
    "#### Action\n",
    "- We will keep FareBin drop Fare\n",
    "- For Age vs Agebin, since the difference is small, and both Age and AgeBin are not tightly corrolated with Survived, for the sake of consistency we will keep AgeBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we drop the original features\n",
    "num_data = num_data.drop(['Fare', 'Age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  SibSp  Parch  FareBin  AgeBin\n",
       "0           0       3      1      0        1       2\n",
       "1           1       1      1      0        5       3\n",
       "2           1       3      0      0        2       2\n",
       "3           1       1      1      0        5       3\n",
       "4           0       3      0      0        2       3\n",
       "..        ...     ...    ...    ...      ...     ...\n",
       "886         0       2      0      0        3       2\n",
       "887         1       1      0      0        4       2\n",
       "888         0       3      1      2        4       2\n",
       "889         1       1      0      0        4       2\n",
       "890         0       3      0      0        1       2\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IsAlone and FamilySize\n",
    "Inspired by the approach taken in the follow Kaggle notebooks, we would like to engineer two new feature IsAlone and FamilySize\n",
    "- [https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy](https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy)\n",
    "- https://www.notion.so/Titanic-Data-Science-Solutions-Kaggle-a5a4aa2d5e024be88263390a26db3c6d#81f0bc93036e4f4ab87c1ac22e2d0e2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "FamilySize = num_data['SibSp']+num_data['Parch']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsAlone = FamilySize>1\n",
    "IsAlone = IsAlone.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.049771</td>\n",
       "      <td>0.203367</td>\n",
       "      <td>0.016639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>-0.135207</td>\n",
       "      <td>0.065997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>0.584471</td>\n",
       "      <td>0.890712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.583398</td>\n",
       "      <td>0.783111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FareBin</th>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>0.418125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBin</th>\n",
       "      <td>-0.049771</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161040</td>\n",
       "      <td>-0.240237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsAlone</th>\n",
       "      <td>0.203367</td>\n",
       "      <td>-0.135207</td>\n",
       "      <td>0.584471</td>\n",
       "      <td>0.583398</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>-0.161040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FamilySize</th>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>0.890712</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>0.418125</td>\n",
       "      <td>-0.240237</td>\n",
       "      <td>0.690922</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Survived    Pclass     SibSp     Parch   FareBin    AgeBin  \\\n",
       "Survived    1.000000 -0.338481 -0.035322  0.081629  0.317783 -0.049771   \n",
       "Pclass     -0.338481  1.000000  0.083081  0.018443 -0.705206 -0.408902   \n",
       "SibSp      -0.035322  0.083081  1.000000  0.414838  0.354974 -0.238513   \n",
       "Parch       0.081629  0.018443  0.414838  1.000000  0.351317 -0.154571   \n",
       "FareBin     0.317783 -0.705206  0.354974  0.351317  1.000000  0.148150   \n",
       "AgeBin     -0.049771 -0.408902 -0.238513 -0.154571  0.148150  1.000000   \n",
       "IsAlone     0.203367 -0.135207  0.584471  0.583398  0.520277 -0.161040   \n",
       "FamilySize  0.016639  0.065997  0.890712  0.783111  0.418125 -0.240237   \n",
       "\n",
       "             IsAlone  FamilySize  \n",
       "Survived    0.203367    0.016639  \n",
       "Pclass     -0.135207    0.065997  \n",
       "SibSp       0.584471    0.890712  \n",
       "Parch       0.583398    0.783111  \n",
       "FareBin     0.520277    0.418125  \n",
       "AgeBin     -0.161040   -0.240237  \n",
       "IsAlone     1.000000    0.690922  \n",
       "FamilySize  0.690922    1.000000  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data['IsAlone'] = IsAlone\n",
    "num_data['FamilySize'] = FamilySize\n",
    "num_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IsAlone has pretty good corrolation with the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>113803</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>373450</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>211536</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>112053</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>111369</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>370376</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name     Sex  \\\n",
       "0                              Braund, Mr. Owen Harris    male   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female   \n",
       "2                               Heikkinen, Miss. Laina  female   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   \n",
       "4                             Allen, Mr. William Henry    male   \n",
       "..                                                 ...     ...   \n",
       "886                              Montvila, Rev. Juozas    male   \n",
       "887                       Graham, Miss. Margaret Edith  female   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   \n",
       "889                              Behr, Mr. Karl Howell    male   \n",
       "890                                Dooley, Mr. Patrick    male   \n",
       "\n",
       "               Ticket Embarked  \n",
       "0           A/5 21171        S  \n",
       "1            PC 17599        C  \n",
       "2    STON/O2. 3101282        S  \n",
       "3              113803        S  \n",
       "4              373450        S  \n",
       "..                ...      ...  \n",
       "886            211536        S  \n",
       "887            112053        S  \n",
       "888        W./C. 6607        S  \n",
       "889            111369        C  \n",
       "890            370376        Q  \n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "Sex and Embarked are ready for labling\n",
    "Need to work on Name and Ticket\n",
    "\n",
    "#### Action\n",
    "- Analysis Name and Ticket\n",
    "- Impute Sex and Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and transform the Name col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "Name values are pretty uniformly formatted\n",
    "\n",
    "#### Action\n",
    "We could use simple split() to extract the Title values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              517\n",
       "Miss            182\n",
       "Mrs             125\n",
       "Master           40\n",
       "Dr                7\n",
       "Rev               6\n",
       "Col               2\n",
       "Major             2\n",
       "Mlle              2\n",
       "Lady              1\n",
       "Mme               1\n",
       "Sir               1\n",
       "Capt              1\n",
       "Jonkheer          1\n",
       "Ms                1\n",
       "Don               1\n",
       "the Countess      1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#borrowed from https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy notebook\n",
    "#quick and dirty code split title from name: http://www.pythonforbeginners.com/dictionary/python-split\n",
    "txt_data['Title'] = txt_data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "\n",
    "txt_data.Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr        517\n",
      "Miss      182\n",
      "Mrs       125\n",
      "Master     40\n",
      "Misc       27\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "title_names = (txt_data['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n",
    "\n",
    "#apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n",
    "txt_data['Title'] = txt_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "print(txt_data['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and transform the Ticket col\n",
    "\n",
    "#### Observation\n",
    "no obvious observable patterns in the data\n",
    "\n",
    "#### Action\n",
    "look at value len to see if we could extract some patterns out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ticket_len = txt_data.Ticket.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     419\n",
       "5     131\n",
       "4     101\n",
       "8      76\n",
       "10     41\n",
       "7      27\n",
       "9      26\n",
       "17     14\n",
       "16     11\n",
       "13     10\n",
       "12     10\n",
       "15      9\n",
       "11      8\n",
       "18      6\n",
       "3       2\n",
       "Name: Ticket, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ticket_len.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is much more workable than the raw data, let's apply the same cat approach we did for Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     419\n",
       "5     131\n",
       "30    123\n",
       "4     101\n",
       "8      76\n",
       "10     41\n",
       "Name: Ticket, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_min_ti = 30\n",
    "Ticket_len_ls = (Ticket_len.value_counts() < stat_min_ti)\n",
    "Ticket_len = Ticket_len.apply(lambda x: '30' if Ticket_len_ls.loc[x] == True else x)\n",
    "Ticket_len.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_data['Ticket_len'] = Ticket_len\n",
    "txt_data = txt_data.drop(['Name', 'Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Ticket_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Misc</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "      <td>Mr</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>male</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex Embarked Title Ticket_len\n",
       "0      male        S    Mr         30\n",
       "1    female        C   Mrs          8\n",
       "2    female        S  Miss         30\n",
       "3    female        S   Mrs          6\n",
       "4      male        S    Mr          6\n",
       "..      ...      ...   ...        ...\n",
       "886    male        S  Misc          6\n",
       "887  female        S  Miss          6\n",
       "888  female        S  Miss         10\n",
       "889    male        C    Mr          6\n",
       "890    male        Q    Mr          6\n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputer only works on str or numbers\n",
    "txt_data['Ticket_len'] = txt_data['Ticket_len'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we perform data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "imp_txt_cols = OH_en.fit_transform(txt_data[['Sex','Embarked', 'Title', 'Ticket_len']])\n",
    "imp_txt_cols = pd.DataFrame(imp_txt_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <th>Ticket_len_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  \\\n",
       "0           0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "1           1.0       0.0         1.0         0.0         0.0           0.0   \n",
       "2           1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "3           1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "4           0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "..          ...       ...         ...         ...         ...           ...   \n",
       "886         0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "887         1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "888         1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "889         0.0       1.0         1.0         0.0         0.0           0.0   \n",
       "890         0.0       1.0         0.0         1.0         0.0           0.0   \n",
       "\n",
       "     Title_Misc  Title_Miss  Title_Mr  Title_Mrs  Ticket_len_10  \\\n",
       "0           0.0         0.0       1.0        0.0            0.0   \n",
       "1           0.0         0.0       0.0        1.0            0.0   \n",
       "2           0.0         1.0       0.0        0.0            0.0   \n",
       "3           0.0         0.0       0.0        1.0            0.0   \n",
       "4           0.0         0.0       1.0        0.0            0.0   \n",
       "..          ...         ...       ...        ...            ...   \n",
       "886         1.0         0.0       0.0        0.0            0.0   \n",
       "887         0.0         1.0       0.0        0.0            0.0   \n",
       "888         0.0         1.0       0.0        0.0            1.0   \n",
       "889         0.0         0.0       1.0        0.0            0.0   \n",
       "890         0.0         0.0       1.0        0.0            0.0   \n",
       "\n",
       "     Ticket_len_30  Ticket_len_4  Ticket_len_5  Ticket_len_6  Ticket_len_8  \n",
       "0              1.0           0.0           0.0           0.0           0.0  \n",
       "1              0.0           0.0           0.0           0.0           1.0  \n",
       "2              1.0           0.0           0.0           0.0           0.0  \n",
       "3              0.0           0.0           0.0           1.0           0.0  \n",
       "4              0.0           0.0           0.0           1.0           0.0  \n",
       "..             ...           ...           ...           ...           ...  \n",
       "886            0.0           0.0           0.0           1.0           0.0  \n",
       "887            0.0           0.0           0.0           1.0           0.0  \n",
       "888            0.0           0.0           0.0           0.0           0.0  \n",
       "889            0.0           0.0           0.0           1.0           0.0  \n",
       "890            0.0           0.0           0.0           1.0           0.0  \n",
       "\n",
       "[891 rows x 16 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we align the index and col names\n",
    "imp_txt_cols.index = txt_data[['Sex','Embarked', 'Title', 'Ticket_len']].index\n",
    "imp_txt_cols.columns = OH_en.get_feature_names(['Sex','Embarked', 'Title', 'Ticket_len'])\n",
    "imp_txt_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Sex' 'Embarked' 'Title' 'Ticket_len'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-251f5ea4f80a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#now we complete the txt df with the imputed cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtxt_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtxt_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Embarked'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Title'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Ticket_len'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimp_txt_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtxt_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3995\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3996\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3997\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3998\u001b[0m         )\n\u001b[0;32m   3999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3936\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Sex' 'Embarked' 'Title' 'Ticket_len'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#now we complete the txt df with the imputed cols\n",
    "txt_data = txt_data.drop(['Sex','Embarked', 'Title', 'Ticket_len'], axis=1).join(imp_txt_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <th>Ticket_len_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  \\\n",
       "0           0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "1           1.0       0.0         1.0         0.0         0.0           0.0   \n",
       "2           1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "3           1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "4           0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "..          ...       ...         ...         ...         ...           ...   \n",
       "886         0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "887         1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "888         1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "889         0.0       1.0         1.0         0.0         0.0           0.0   \n",
       "890         0.0       1.0         0.0         1.0         0.0           0.0   \n",
       "\n",
       "     Title_Misc  Title_Miss  Title_Mr  Title_Mrs  Ticket_len_10  \\\n",
       "0           0.0         0.0       1.0        0.0            0.0   \n",
       "1           0.0         0.0       0.0        1.0            0.0   \n",
       "2           0.0         1.0       0.0        0.0            0.0   \n",
       "3           0.0         0.0       0.0        1.0            0.0   \n",
       "4           0.0         0.0       1.0        0.0            0.0   \n",
       "..          ...         ...       ...        ...            ...   \n",
       "886         1.0         0.0       0.0        0.0            0.0   \n",
       "887         0.0         1.0       0.0        0.0            0.0   \n",
       "888         0.0         1.0       0.0        0.0            1.0   \n",
       "889         0.0         0.0       1.0        0.0            0.0   \n",
       "890         0.0         0.0       1.0        0.0            0.0   \n",
       "\n",
       "     Ticket_len_30  Ticket_len_4  Ticket_len_5  Ticket_len_6  Ticket_len_8  \n",
       "0              1.0           0.0           0.0           0.0           0.0  \n",
       "1              0.0           0.0           0.0           0.0           1.0  \n",
       "2              1.0           0.0           0.0           0.0           0.0  \n",
       "3              0.0           0.0           0.0           1.0           0.0  \n",
       "4              0.0           0.0           0.0           1.0           0.0  \n",
       "..             ...           ...           ...           ...           ...  \n",
       "886            0.0           0.0           0.0           1.0           0.0  \n",
       "887            0.0           0.0           0.0           1.0           0.0  \n",
       "888            0.0           0.0           0.0           0.0           0.0  \n",
       "889            0.0           0.0           0.0           1.0           0.0  \n",
       "890            0.0           0.0           0.0           1.0           0.0  \n",
       "\n",
       "[891 rows x 16 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <th>Ticket_len_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex_female</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.119224</td>\n",
       "      <td>-0.159934</td>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.686808</td>\n",
       "      <td>-0.867334</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.084090</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>0.091776</td>\n",
       "      <td>-0.045475</td>\n",
       "      <td>0.052287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_male</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.082853</td>\n",
       "      <td>-0.074115</td>\n",
       "      <td>0.119224</td>\n",
       "      <td>0.159934</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>-0.686808</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>-0.547600</td>\n",
       "      <td>-0.006179</td>\n",
       "      <td>0.084090</td>\n",
       "      <td>-0.010421</td>\n",
       "      <td>-0.091776</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>-0.052287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>0.082853</td>\n",
       "      <td>-0.082853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>-0.782742</td>\n",
       "      <td>-0.035225</td>\n",
       "      <td>0.065432</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>-0.072567</td>\n",
       "      <td>0.061395</td>\n",
       "      <td>-0.105869</td>\n",
       "      <td>-0.068141</td>\n",
       "      <td>0.361630</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>-0.339198</td>\n",
       "      <td>0.325325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.074115</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.499421</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>-0.007767</td>\n",
       "      <td>0.171117</td>\n",
       "      <td>-0.078338</td>\n",
       "      <td>-0.089739</td>\n",
       "      <td>-0.048484</td>\n",
       "      <td>-0.123085</td>\n",
       "      <td>-0.097372</td>\n",
       "      <td>0.018938</td>\n",
       "      <td>0.206393</td>\n",
       "      <td>-0.093921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>-0.119224</td>\n",
       "      <td>0.119224</td>\n",
       "      <td>-0.782742</td>\n",
       "      <td>-0.499421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024264</td>\n",
       "      <td>-0.052433</td>\n",
       "      <td>-0.130650</td>\n",
       "      <td>0.112870</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.123257</td>\n",
       "      <td>0.137152</td>\n",
       "      <td>-0.255526</td>\n",
       "      <td>-0.035339</td>\n",
       "      <td>0.167268</td>\n",
       "      <td>-0.225893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Master</th>\n",
       "      <td>-0.159934</td>\n",
       "      <td>0.159934</td>\n",
       "      <td>-0.035225</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.024264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.038326</td>\n",
       "      <td>-0.109844</td>\n",
       "      <td>-0.254903</td>\n",
       "      <td>-0.087580</td>\n",
       "      <td>0.029992</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>-0.044095</td>\n",
       "      <td>0.012919</td>\n",
       "      <td>-0.046801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Misc</th>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>0.065432</td>\n",
       "      <td>-0.007767</td>\n",
       "      <td>-0.052433</td>\n",
       "      <td>-0.038326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.089565</td>\n",
       "      <td>-0.207843</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>-0.038825</td>\n",
       "      <td>-0.032784</td>\n",
       "      <td>-0.063208</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>0.086656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Miss</th>\n",
       "      <td>0.686808</td>\n",
       "      <td>-0.686808</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>0.171117</td>\n",
       "      <td>-0.130650</td>\n",
       "      <td>-0.109844</td>\n",
       "      <td>-0.089565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.595692</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.057497</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>0.024675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mr</th>\n",
       "      <td>-0.867334</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>-0.072567</td>\n",
       "      <td>-0.078338</td>\n",
       "      <td>0.112870</td>\n",
       "      <td>-0.254903</td>\n",
       "      <td>-0.207843</td>\n",
       "      <td>-0.595692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.474952</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.083562</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>-0.041512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mrs</th>\n",
       "      <td>0.547600</td>\n",
       "      <td>-0.547600</td>\n",
       "      <td>0.061395</td>\n",
       "      <td>-0.089739</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>-0.087580</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>-0.474952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>-0.039872</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>-0.043914</td>\n",
       "      <td>0.015478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.006179</td>\n",
       "      <td>-0.105869</td>\n",
       "      <td>-0.048484</td>\n",
       "      <td>0.123257</td>\n",
       "      <td>0.029992</td>\n",
       "      <td>-0.038825</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087893</td>\n",
       "      <td>-0.078529</td>\n",
       "      <td>-0.091182</td>\n",
       "      <td>-0.206928</td>\n",
       "      <td>-0.067067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <td>-0.084090</td>\n",
       "      <td>0.084090</td>\n",
       "      <td>-0.068141</td>\n",
       "      <td>-0.123085</td>\n",
       "      <td>0.137152</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>-0.032784</td>\n",
       "      <td>-0.057497</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>-0.039872</td>\n",
       "      <td>-0.087893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.143093</td>\n",
       "      <td>-0.166150</td>\n",
       "      <td>-0.377058</td>\n",
       "      <td>-0.122208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <td>0.010421</td>\n",
       "      <td>-0.010421</td>\n",
       "      <td>0.361630</td>\n",
       "      <td>-0.097372</td>\n",
       "      <td>-0.255526</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>-0.063208</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>-0.078529</td>\n",
       "      <td>-0.143093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148449</td>\n",
       "      <td>-0.336886</td>\n",
       "      <td>-0.109188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <td>0.091776</td>\n",
       "      <td>-0.091776</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.018938</td>\n",
       "      <td>-0.035339</td>\n",
       "      <td>-0.044095</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>-0.083562</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>-0.091182</td>\n",
       "      <td>-0.166150</td>\n",
       "      <td>-0.148449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.391169</td>\n",
       "      <td>-0.126782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <td>-0.045475</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>-0.339198</td>\n",
       "      <td>0.206393</td>\n",
       "      <td>0.167268</td>\n",
       "      <td>0.012919</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>-0.043914</td>\n",
       "      <td>-0.206928</td>\n",
       "      <td>-0.377058</td>\n",
       "      <td>-0.336886</td>\n",
       "      <td>-0.391169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.287716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_8</th>\n",
       "      <td>0.052287</td>\n",
       "      <td>-0.052287</td>\n",
       "      <td>0.325325</td>\n",
       "      <td>-0.093921</td>\n",
       "      <td>-0.225893</td>\n",
       "      <td>-0.046801</td>\n",
       "      <td>0.086656</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>-0.041512</td>\n",
       "      <td>0.015478</td>\n",
       "      <td>-0.067067</td>\n",
       "      <td>-0.122208</td>\n",
       "      <td>-0.109188</td>\n",
       "      <td>-0.126782</td>\n",
       "      <td>-0.287716</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \\\n",
       "Sex_female       1.000000 -1.000000    0.082853    0.074115   -0.119224   \n",
       "Sex_male        -1.000000  1.000000   -0.082853   -0.074115    0.119224   \n",
       "Embarked_C       0.082853 -0.082853    1.000000   -0.148258   -0.782742   \n",
       "Embarked_Q       0.074115 -0.074115   -0.148258    1.000000   -0.499421   \n",
       "Embarked_S      -0.119224  0.119224   -0.782742   -0.499421    1.000000   \n",
       "Title_Master    -0.159934  0.159934   -0.035225    0.010478    0.024264   \n",
       "Title_Misc      -0.034471  0.034471    0.065432   -0.007767   -0.052433   \n",
       "Title_Miss       0.686808 -0.686808    0.026215    0.171117   -0.130650   \n",
       "Title_Mr        -0.867334  0.867334   -0.072567   -0.078338    0.112870   \n",
       "Title_Mrs        0.547600 -0.547600    0.061395   -0.089739    0.002689   \n",
       "Ticket_len_10    0.006179 -0.006179   -0.105869   -0.048484    0.123257   \n",
       "Ticket_len_30   -0.084090  0.084090   -0.068141   -0.123085    0.137152   \n",
       "Ticket_len_4     0.010421 -0.010421    0.361630   -0.097372   -0.255526   \n",
       "Ticket_len_5     0.091776 -0.091776    0.026735    0.018938   -0.035339   \n",
       "Ticket_len_6    -0.045475  0.045475   -0.339198    0.206393    0.167268   \n",
       "Ticket_len_8     0.052287 -0.052287    0.325325   -0.093921   -0.225893   \n",
       "\n",
       "               Title_Master  Title_Misc  Title_Miss  Title_Mr  Title_Mrs  \\\n",
       "Sex_female        -0.159934   -0.034471    0.686808 -0.867334   0.547600   \n",
       "Sex_male           0.159934    0.034471   -0.686808  0.867334  -0.547600   \n",
       "Embarked_C        -0.035225    0.065432    0.026215 -0.072567   0.061395   \n",
       "Embarked_Q         0.010478   -0.007767    0.171117 -0.078338  -0.089739   \n",
       "Embarked_S         0.024264   -0.052433   -0.130650  0.112870   0.002689   \n",
       "Title_Master       1.000000   -0.038326   -0.109844 -0.254903  -0.087580   \n",
       "Title_Misc        -0.038326    1.000000   -0.089565 -0.207843  -0.071411   \n",
       "Title_Miss        -0.109844   -0.089565    1.000000 -0.595692  -0.204670   \n",
       "Title_Mr          -0.254903   -0.207843   -0.595692  1.000000  -0.474952   \n",
       "Title_Mrs         -0.087580   -0.071411   -0.204670 -0.474952   1.000000   \n",
       "Ticket_len_10      0.029992   -0.038825   -0.004981 -0.008576   0.019250   \n",
       "Ticket_len_30      0.038938   -0.032784   -0.057497  0.070078  -0.039872   \n",
       "Ticket_len_4       0.007963   -0.063208    0.020804  0.002834  -0.001728   \n",
       "Ticket_len_5      -0.044095    0.056025    0.033341 -0.083562   0.078680   \n",
       "Ticket_len_6       0.012919   -0.009143   -0.008851  0.035888  -0.043914   \n",
       "Ticket_len_8      -0.046801    0.086656    0.024675 -0.041512   0.015478   \n",
       "\n",
       "               Ticket_len_10  Ticket_len_30  Ticket_len_4  Ticket_len_5  \\\n",
       "Sex_female          0.006179      -0.084090      0.010421      0.091776   \n",
       "Sex_male           -0.006179       0.084090     -0.010421     -0.091776   \n",
       "Embarked_C         -0.105869      -0.068141      0.361630      0.026735   \n",
       "Embarked_Q         -0.048484      -0.123085     -0.097372      0.018938   \n",
       "Embarked_S          0.123257       0.137152     -0.255526     -0.035339   \n",
       "Title_Master        0.029992       0.038938      0.007963     -0.044095   \n",
       "Title_Misc         -0.038825      -0.032784     -0.063208      0.056025   \n",
       "Title_Miss         -0.004981      -0.057497      0.020804      0.033341   \n",
       "Title_Mr           -0.008576       0.070078      0.002834     -0.083562   \n",
       "Title_Mrs           0.019250      -0.039872     -0.001728      0.078680   \n",
       "Ticket_len_10       1.000000      -0.087893     -0.078529     -0.091182   \n",
       "Ticket_len_30      -0.087893       1.000000     -0.143093     -0.166150   \n",
       "Ticket_len_4       -0.078529      -0.143093      1.000000     -0.148449   \n",
       "Ticket_len_5       -0.091182      -0.166150     -0.148449      1.000000   \n",
       "Ticket_len_6       -0.206928      -0.377058     -0.336886     -0.391169   \n",
       "Ticket_len_8       -0.067067      -0.122208     -0.109188     -0.126782   \n",
       "\n",
       "               Ticket_len_6  Ticket_len_8  \n",
       "Sex_female        -0.045475      0.052287  \n",
       "Sex_male           0.045475     -0.052287  \n",
       "Embarked_C        -0.339198      0.325325  \n",
       "Embarked_Q         0.206393     -0.093921  \n",
       "Embarked_S         0.167268     -0.225893  \n",
       "Title_Master       0.012919     -0.046801  \n",
       "Title_Misc        -0.009143      0.086656  \n",
       "Title_Miss        -0.008851      0.024675  \n",
       "Title_Mr           0.035888     -0.041512  \n",
       "Title_Mrs         -0.043914      0.015478  \n",
       "Ticket_len_10     -0.206928     -0.067067  \n",
       "Ticket_len_30     -0.377058     -0.122208  \n",
       "Ticket_len_4      -0.336886     -0.109188  \n",
       "Ticket_len_5      -0.391169     -0.126782  \n",
       "Ticket_len_6       1.000000     -0.287716  \n",
       "Ticket_len_8      -0.287716      1.000000  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converge to a function\n",
    "Next, let's converge what we have just done to a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_eng (clean_data):\n",
    "    #let's start with num cols\n",
    "    #create value bins for continuouse values\n",
    "    clean_data['FareBin'] = pd.qcut(clean_data['Fare'], 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    clean_data['AgeBin'] = pd.cut(clean_data['Age'].astype(int), 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    #now we drop the original features\n",
    "    clean_data = clean_data.drop(['Fare', 'Age'], axis=1)\n",
    "    \n",
    "    #create new features\n",
    "    FamilySize = clean_data['SibSp']+clean_data['Parch']+1\n",
    "    IsAlone = FamilySize>1\n",
    "    IsAlone = IsAlone.apply(int)\n",
    "    clean_data['IsAlone'] = IsAlone\n",
    "    clean_data['FamilySize'] = FamilySize\n",
    "    \n",
    "    #next we work on text data\n",
    "    #extrat title from Name\n",
    "    clean_data['Title'] = clean_data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    \n",
    "    stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "    title_names = (clean_data['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n",
    "    #apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n",
    "    clean_data['Title'] = clean_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "    \n",
    "    #cat tickets by length\n",
    "    Ticket_len = clean_data.Ticket.apply(len)\n",
    "    stat_min_ti = 30\n",
    "    Ticket_len_ls = (Ticket_len.value_counts() < stat_min_ti)\n",
    "    Ticket_len = Ticket_len.apply(lambda x: '30' if Ticket_len_ls.loc[x] == True else x)\n",
    "    Ticket_len.value_counts()\n",
    "    clean_data['Ticket_len'] = Ticket_len\n",
    "    #imputer only works on str or numbers\n",
    "    clean_data['Ticket_len'] = clean_data['Ticket_len'].astype(str)\n",
    "    clean_data = clean_data.drop(['Name', 'Ticket'], axis=1)\n",
    "    \n",
    "    #do imputation on txt data\n",
    "    OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    imp_cols = OH_en.fit_transform(clean_data[['Sex','Embarked', 'Title', 'Ticket_len']])\n",
    "    imp_cols = pd.DataFrame(imp_cols)\n",
    "    #now we align the index and col names\n",
    "    imp_cols.index = clean_data[['Sex','Embarked', 'Title', 'Ticket_len']].index\n",
    "    imp_cols.columns = OH_en.get_feature_names(['Sex','Embarked', 'Title', 'Ticket_len'])\n",
    "    clean_data = clean_data.drop(['Sex','Embarked', 'Title', 'Ticket_len'], axis=1).join(imp_cols)\n",
    "\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Ticket      0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "(891, 10)\n",
      "   Survived  Pclass                                               Name  \\\n",
      "0         0       3                            Braund, Mr. Owen Harris   \n",
      "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "2         1       3                             Heikkinen, Miss. Laina   \n",
      "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "4         0       3                           Allen, Mr. William Henry   \n",
      "\n",
      "      Sex   Age  SibSp  Parch            Ticket     Fare Embarked  \n",
      "0    male  22.0      1      0         A/5 21171   7.2500        S  \n",
      "1  female  38.0      1      0          PC 17599  71.2833        C  \n",
      "2  female  26.0      0      0  STON/O2. 3101282   7.9250        S  \n",
      "3  female  35.0      1      0            113803  53.1000        S  \n",
      "4    male  35.0      0      0            373450   8.0500        S  \n"
     ]
    }
   ],
   "source": [
    "test_data = train_raw.copy()\n",
    "test_clean = data_clean(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = f_eng(test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <th>Ticket_len_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.049771</td>\n",
       "      <td>0.203367</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.543351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022030</td>\n",
       "      <td>0.327093</td>\n",
       "      <td>-0.549199</td>\n",
       "      <td>0.339040</td>\n",
       "      <td>-0.019137</td>\n",
       "      <td>-0.081703</td>\n",
       "      <td>-0.012868</td>\n",
       "      <td>0.200178</td>\n",
       "      <td>-0.124049</td>\n",
       "      <td>0.097727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>-0.135207</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206333</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>0.142698</td>\n",
       "      <td>-0.149209</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>0.155894</td>\n",
       "      <td>0.270416</td>\n",
       "      <td>-0.377124</td>\n",
       "      <td>0.157908</td>\n",
       "      <td>-0.324370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>0.584471</td>\n",
       "      <td>0.890712</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036364</td>\n",
       "      <td>0.087932</td>\n",
       "      <td>-0.250489</td>\n",
       "      <td>0.063407</td>\n",
       "      <td>-0.011875</td>\n",
       "      <td>0.084638</td>\n",
       "      <td>-0.031555</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>-0.112502</td>\n",
       "      <td>0.132163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.583398</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067480</td>\n",
       "      <td>0.105567</td>\n",
       "      <td>-0.333905</td>\n",
       "      <td>0.225852</td>\n",
       "      <td>0.082150</td>\n",
       "      <td>0.028529</td>\n",
       "      <td>-0.041927</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>-0.033182</td>\n",
       "      <td>0.004982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FareBin</th>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>0.418125</td>\n",
       "      <td>0.244943</td>\n",
       "      <td>-0.244943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112454</td>\n",
       "      <td>0.059106</td>\n",
       "      <td>-0.312117</td>\n",
       "      <td>0.245302</td>\n",
       "      <td>-0.024758</td>\n",
       "      <td>-0.079605</td>\n",
       "      <td>-0.162293</td>\n",
       "      <td>0.263112</td>\n",
       "      <td>-0.194354</td>\n",
       "      <td>0.314787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBin</th>\n",
       "      <td>-0.049771</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161040</td>\n",
       "      <td>-0.240237</td>\n",
       "      <td>-0.093198</td>\n",
       "      <td>0.093198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176985</td>\n",
       "      <td>-0.242363</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.146407</td>\n",
       "      <td>-0.035189</td>\n",
       "      <td>-0.072051</td>\n",
       "      <td>-0.142312</td>\n",
       "      <td>0.182356</td>\n",
       "      <td>-0.062603</td>\n",
       "      <td>0.157564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsAlone</th>\n",
       "      <td>0.203367</td>\n",
       "      <td>-0.135207</td>\n",
       "      <td>0.584471</td>\n",
       "      <td>0.583398</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>-0.161040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690922</td>\n",
       "      <td>0.303646</td>\n",
       "      <td>-0.303646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>0.055127</td>\n",
       "      <td>-0.396920</td>\n",
       "      <td>0.365454</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>-0.000926</td>\n",
       "      <td>0.122750</td>\n",
       "      <td>-0.130834</td>\n",
       "      <td>0.031241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FamilySize</th>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>0.890712</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>0.418125</td>\n",
       "      <td>-0.240237</td>\n",
       "      <td>0.690922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200988</td>\n",
       "      <td>-0.200988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058565</td>\n",
       "      <td>0.112838</td>\n",
       "      <td>-0.338014</td>\n",
       "      <td>0.156168</td>\n",
       "      <td>0.032924</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>-0.042513</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>-0.093468</td>\n",
       "      <td>0.092818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_female</th>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.244943</td>\n",
       "      <td>-0.093198</td>\n",
       "      <td>0.303646</td>\n",
       "      <td>0.200988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.686808</td>\n",
       "      <td>-0.867334</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.084090</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>0.091776</td>\n",
       "      <td>-0.045475</td>\n",
       "      <td>0.052287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_male</th>\n",
       "      <td>-0.543351</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>-0.244943</td>\n",
       "      <td>0.093198</td>\n",
       "      <td>-0.303646</td>\n",
       "      <td>-0.200988</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>-0.686808</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>-0.547600</td>\n",
       "      <td>-0.006179</td>\n",
       "      <td>0.084090</td>\n",
       "      <td>-0.010421</td>\n",
       "      <td>-0.091776</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>-0.052287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>0.168240</td>\n",
       "      <td>-0.243292</td>\n",
       "      <td>-0.059528</td>\n",
       "      <td>-0.011069</td>\n",
       "      <td>0.204579</td>\n",
       "      <td>0.042419</td>\n",
       "      <td>0.095298</td>\n",
       "      <td>-0.046215</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>-0.082853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065432</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>-0.072567</td>\n",
       "      <td>0.061395</td>\n",
       "      <td>-0.105869</td>\n",
       "      <td>-0.068141</td>\n",
       "      <td>0.361630</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>-0.339198</td>\n",
       "      <td>0.325325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.221009</td>\n",
       "      <td>-0.026354</td>\n",
       "      <td>-0.081228</td>\n",
       "      <td>-0.243154</td>\n",
       "      <td>-0.088339</td>\n",
       "      <td>-0.086464</td>\n",
       "      <td>-0.058592</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.074115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007767</td>\n",
       "      <td>0.171117</td>\n",
       "      <td>-0.078338</td>\n",
       "      <td>-0.089739</td>\n",
       "      <td>-0.048484</td>\n",
       "      <td>-0.123085</td>\n",
       "      <td>-0.097372</td>\n",
       "      <td>0.018938</td>\n",
       "      <td>0.206393</td>\n",
       "      <td>-0.093921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>-0.149683</td>\n",
       "      <td>0.074053</td>\n",
       "      <td>0.068734</td>\n",
       "      <td>0.060814</td>\n",
       "      <td>-0.026202</td>\n",
       "      <td>0.018431</td>\n",
       "      <td>-0.029074</td>\n",
       "      <td>0.077359</td>\n",
       "      <td>-0.119224</td>\n",
       "      <td>0.119224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052433</td>\n",
       "      <td>-0.130650</td>\n",
       "      <td>0.112870</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.123257</td>\n",
       "      <td>0.137152</td>\n",
       "      <td>-0.255526</td>\n",
       "      <td>-0.035339</td>\n",
       "      <td>0.167268</td>\n",
       "      <td>-0.225893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Master</th>\n",
       "      <td>0.085221</td>\n",
       "      <td>0.082081</td>\n",
       "      <td>0.349559</td>\n",
       "      <td>0.267344</td>\n",
       "      <td>0.124297</td>\n",
       "      <td>-0.324075</td>\n",
       "      <td>0.267024</td>\n",
       "      <td>0.372472</td>\n",
       "      <td>-0.159934</td>\n",
       "      <td>0.159934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038326</td>\n",
       "      <td>-0.109844</td>\n",
       "      <td>-0.254903</td>\n",
       "      <td>-0.087580</td>\n",
       "      <td>0.029992</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>-0.044095</td>\n",
       "      <td>0.012919</td>\n",
       "      <td>-0.046801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Misc</th>\n",
       "      <td>0.022030</td>\n",
       "      <td>-0.206333</td>\n",
       "      <td>-0.036364</td>\n",
       "      <td>-0.067480</td>\n",
       "      <td>0.112454</td>\n",
       "      <td>0.176985</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>-0.058565</td>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.089565</td>\n",
       "      <td>-0.207843</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>-0.038825</td>\n",
       "      <td>-0.032784</td>\n",
       "      <td>-0.063208</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>0.086656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Miss</th>\n",
       "      <td>0.327093</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>0.087932</td>\n",
       "      <td>0.105567</td>\n",
       "      <td>0.059106</td>\n",
       "      <td>-0.242363</td>\n",
       "      <td>0.055127</td>\n",
       "      <td>0.112838</td>\n",
       "      <td>0.686808</td>\n",
       "      <td>-0.686808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.595692</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.057497</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>0.024675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mr</th>\n",
       "      <td>-0.549199</td>\n",
       "      <td>0.142698</td>\n",
       "      <td>-0.250489</td>\n",
       "      <td>-0.333905</td>\n",
       "      <td>-0.312117</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>-0.396920</td>\n",
       "      <td>-0.338014</td>\n",
       "      <td>-0.867334</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207843</td>\n",
       "      <td>-0.595692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.474952</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.083562</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>-0.041512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mrs</th>\n",
       "      <td>0.339040</td>\n",
       "      <td>-0.149209</td>\n",
       "      <td>0.063407</td>\n",
       "      <td>0.225852</td>\n",
       "      <td>0.245302</td>\n",
       "      <td>0.146407</td>\n",
       "      <td>0.365454</td>\n",
       "      <td>0.156168</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>-0.547600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>-0.474952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>-0.039872</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>-0.043914</td>\n",
       "      <td>0.015478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <td>-0.019137</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>-0.011875</td>\n",
       "      <td>0.082150</td>\n",
       "      <td>-0.024758</td>\n",
       "      <td>-0.035189</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.032924</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.006179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038825</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087893</td>\n",
       "      <td>-0.078529</td>\n",
       "      <td>-0.091182</td>\n",
       "      <td>-0.206928</td>\n",
       "      <td>-0.067067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <td>-0.081703</td>\n",
       "      <td>0.155894</td>\n",
       "      <td>0.084638</td>\n",
       "      <td>0.028529</td>\n",
       "      <td>-0.079605</td>\n",
       "      <td>-0.072051</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>-0.084090</td>\n",
       "      <td>0.084090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032784</td>\n",
       "      <td>-0.057497</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>-0.039872</td>\n",
       "      <td>-0.087893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.143093</td>\n",
       "      <td>-0.166150</td>\n",
       "      <td>-0.377058</td>\n",
       "      <td>-0.122208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <td>-0.012868</td>\n",
       "      <td>0.270416</td>\n",
       "      <td>-0.031555</td>\n",
       "      <td>-0.041927</td>\n",
       "      <td>-0.162293</td>\n",
       "      <td>-0.142312</td>\n",
       "      <td>-0.000926</td>\n",
       "      <td>-0.042513</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>-0.010421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063208</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>-0.078529</td>\n",
       "      <td>-0.143093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148449</td>\n",
       "      <td>-0.336886</td>\n",
       "      <td>-0.109188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <td>0.200178</td>\n",
       "      <td>-0.377124</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.263112</td>\n",
       "      <td>0.182356</td>\n",
       "      <td>0.122750</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.091776</td>\n",
       "      <td>-0.091776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>-0.083562</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>-0.091182</td>\n",
       "      <td>-0.166150</td>\n",
       "      <td>-0.148449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.391169</td>\n",
       "      <td>-0.126782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <td>-0.124049</td>\n",
       "      <td>0.157908</td>\n",
       "      <td>-0.112502</td>\n",
       "      <td>-0.033182</td>\n",
       "      <td>-0.194354</td>\n",
       "      <td>-0.062603</td>\n",
       "      <td>-0.130834</td>\n",
       "      <td>-0.093468</td>\n",
       "      <td>-0.045475</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>-0.043914</td>\n",
       "      <td>-0.206928</td>\n",
       "      <td>-0.377058</td>\n",
       "      <td>-0.336886</td>\n",
       "      <td>-0.391169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.287716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_8</th>\n",
       "      <td>0.097727</td>\n",
       "      <td>-0.324370</td>\n",
       "      <td>0.132163</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>0.314787</td>\n",
       "      <td>0.157564</td>\n",
       "      <td>0.031241</td>\n",
       "      <td>0.092818</td>\n",
       "      <td>0.052287</td>\n",
       "      <td>-0.052287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086656</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>-0.041512</td>\n",
       "      <td>0.015478</td>\n",
       "      <td>-0.067067</td>\n",
       "      <td>-0.122208</td>\n",
       "      <td>-0.109188</td>\n",
       "      <td>-0.126782</td>\n",
       "      <td>-0.287716</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Survived    Pclass     SibSp     Parch   FareBin    AgeBin  \\\n",
       "Survived       1.000000 -0.338481 -0.035322  0.081629  0.317783 -0.049771   \n",
       "Pclass        -0.338481  1.000000  0.083081  0.018443 -0.705206 -0.408902   \n",
       "SibSp         -0.035322  0.083081  1.000000  0.414838  0.354974 -0.238513   \n",
       "Parch          0.081629  0.018443  0.414838  1.000000  0.351317 -0.154571   \n",
       "FareBin        0.317783 -0.705206  0.354974  0.351317  1.000000  0.148150   \n",
       "AgeBin        -0.049771 -0.408902 -0.238513 -0.154571  0.148150  1.000000   \n",
       "IsAlone        0.203367 -0.135207  0.584471  0.583398  0.520277 -0.161040   \n",
       "FamilySize     0.016639  0.065997  0.890712  0.783111  0.418125 -0.240237   \n",
       "Sex_female     0.543351 -0.131900  0.114631  0.245489  0.244943 -0.093198   \n",
       "Sex_male      -0.543351  0.131900 -0.114631 -0.245489 -0.244943  0.093198   \n",
       "Embarked_C     0.168240 -0.243292 -0.059528 -0.011069  0.204579  0.042419   \n",
       "Embarked_Q     0.003650  0.221009 -0.026354 -0.081228 -0.243154 -0.088339   \n",
       "Embarked_S    -0.149683  0.074053  0.068734  0.060814 -0.026202  0.018431   \n",
       "Title_Master   0.085221  0.082081  0.349559  0.267344  0.124297 -0.324075   \n",
       "Title_Misc     0.022030 -0.206333 -0.036364 -0.067480  0.112454  0.176985   \n",
       "Title_Miss     0.327093 -0.000576  0.087932  0.105567  0.059106 -0.242363   \n",
       "Title_Mr      -0.549199  0.142698 -0.250489 -0.333905 -0.312117  0.169465   \n",
       "Title_Mrs      0.339040 -0.149209  0.063407  0.225852  0.245302  0.146407   \n",
       "Ticket_len_10 -0.019137  0.027858 -0.011875  0.082150 -0.024758 -0.035189   \n",
       "Ticket_len_30 -0.081703  0.155894  0.084638  0.028529 -0.079605 -0.072051   \n",
       "Ticket_len_4  -0.012868  0.270416 -0.031555 -0.041927 -0.162293 -0.142312   \n",
       "Ticket_len_5   0.200178 -0.377124  0.007149  0.003978  0.263112  0.182356   \n",
       "Ticket_len_6  -0.124049  0.157908 -0.112502 -0.033182 -0.194354 -0.062603   \n",
       "Ticket_len_8   0.097727 -0.324370  0.132163  0.004982  0.314787  0.157564   \n",
       "\n",
       "                IsAlone  FamilySize  Sex_female  Sex_male  ...  Title_Misc  \\\n",
       "Survived       0.203367    0.016639    0.543351 -0.543351  ...    0.022030   \n",
       "Pclass        -0.135207    0.065997   -0.131900  0.131900  ...   -0.206333   \n",
       "SibSp          0.584471    0.890712    0.114631 -0.114631  ...   -0.036364   \n",
       "Parch          0.583398    0.783111    0.245489 -0.245489  ...   -0.067480   \n",
       "FareBin        0.520277    0.418125    0.244943 -0.244943  ...    0.112454   \n",
       "AgeBin        -0.161040   -0.240237   -0.093198  0.093198  ...    0.176985   \n",
       "IsAlone        1.000000    0.690922    0.303646 -0.303646  ...   -0.049870   \n",
       "FamilySize     0.690922    1.000000    0.200988 -0.200988  ...   -0.058565   \n",
       "Sex_female     0.303646    0.200988    1.000000 -1.000000  ...   -0.034471   \n",
       "Sex_male      -0.303646   -0.200988   -1.000000  1.000000  ...    0.034471   \n",
       "Embarked_C     0.095298   -0.046215    0.082853 -0.082853  ...    0.065432   \n",
       "Embarked_Q    -0.086464   -0.058592    0.074115 -0.074115  ...   -0.007767   \n",
       "Embarked_S    -0.029074    0.077359   -0.119224  0.119224  ...   -0.052433   \n",
       "Title_Master   0.267024    0.372472   -0.159934  0.159934  ...   -0.038326   \n",
       "Title_Misc    -0.049870   -0.058565   -0.034471  0.034471  ...    1.000000   \n",
       "Title_Miss     0.055127    0.112838    0.686808 -0.686808  ...   -0.089565   \n",
       "Title_Mr      -0.396920   -0.338014   -0.867334  0.867334  ...   -0.207843   \n",
       "Title_Mrs      0.365454    0.156168    0.547600 -0.547600  ...   -0.071411   \n",
       "Ticket_len_10  0.018724    0.032924    0.006179 -0.006179  ...   -0.038825   \n",
       "Ticket_len_30  0.027469    0.072100   -0.084090  0.084090  ...   -0.032784   \n",
       "Ticket_len_4  -0.000926   -0.042513    0.010421 -0.010421  ...   -0.063208   \n",
       "Ticket_len_5   0.122750    0.006873    0.091776 -0.091776  ...    0.056025   \n",
       "Ticket_len_6  -0.130834   -0.093468   -0.045475  0.045475  ...   -0.009143   \n",
       "Ticket_len_8   0.031241    0.092818    0.052287 -0.052287  ...    0.086656   \n",
       "\n",
       "               Title_Miss  Title_Mr  Title_Mrs  Ticket_len_10  Ticket_len_30  \\\n",
       "Survived         0.327093 -0.549199   0.339040      -0.019137      -0.081703   \n",
       "Pclass          -0.000576  0.142698  -0.149209       0.027858       0.155894   \n",
       "SibSp            0.087932 -0.250489   0.063407      -0.011875       0.084638   \n",
       "Parch            0.105567 -0.333905   0.225852       0.082150       0.028529   \n",
       "FareBin          0.059106 -0.312117   0.245302      -0.024758      -0.079605   \n",
       "AgeBin          -0.242363  0.169465   0.146407      -0.035189      -0.072051   \n",
       "IsAlone          0.055127 -0.396920   0.365454       0.018724       0.027469   \n",
       "FamilySize       0.112838 -0.338014   0.156168       0.032924       0.072100   \n",
       "Sex_female       0.686808 -0.867334   0.547600       0.006179      -0.084090   \n",
       "Sex_male        -0.686808  0.867334  -0.547600      -0.006179       0.084090   \n",
       "Embarked_C       0.026215 -0.072567   0.061395      -0.105869      -0.068141   \n",
       "Embarked_Q       0.171117 -0.078338  -0.089739      -0.048484      -0.123085   \n",
       "Embarked_S      -0.130650  0.112870   0.002689       0.123257       0.137152   \n",
       "Title_Master    -0.109844 -0.254903  -0.087580       0.029992       0.038938   \n",
       "Title_Misc      -0.089565 -0.207843  -0.071411      -0.038825      -0.032784   \n",
       "Title_Miss       1.000000 -0.595692  -0.204670      -0.004981      -0.057497   \n",
       "Title_Mr        -0.595692  1.000000  -0.474952      -0.008576       0.070078   \n",
       "Title_Mrs       -0.204670 -0.474952   1.000000       0.019250      -0.039872   \n",
       "Ticket_len_10   -0.004981 -0.008576   0.019250       1.000000      -0.087893   \n",
       "Ticket_len_30   -0.057497  0.070078  -0.039872      -0.087893       1.000000   \n",
       "Ticket_len_4     0.020804  0.002834  -0.001728      -0.078529      -0.143093   \n",
       "Ticket_len_5     0.033341 -0.083562   0.078680      -0.091182      -0.166150   \n",
       "Ticket_len_6    -0.008851  0.035888  -0.043914      -0.206928      -0.377058   \n",
       "Ticket_len_8     0.024675 -0.041512   0.015478      -0.067067      -0.122208   \n",
       "\n",
       "               Ticket_len_4  Ticket_len_5  Ticket_len_6  Ticket_len_8  \n",
       "Survived          -0.012868      0.200178     -0.124049      0.097727  \n",
       "Pclass             0.270416     -0.377124      0.157908     -0.324370  \n",
       "SibSp             -0.031555      0.007149     -0.112502      0.132163  \n",
       "Parch             -0.041927      0.003978     -0.033182      0.004982  \n",
       "FareBin           -0.162293      0.263112     -0.194354      0.314787  \n",
       "AgeBin            -0.142312      0.182356     -0.062603      0.157564  \n",
       "IsAlone           -0.000926      0.122750     -0.130834      0.031241  \n",
       "FamilySize        -0.042513      0.006873     -0.093468      0.092818  \n",
       "Sex_female         0.010421      0.091776     -0.045475      0.052287  \n",
       "Sex_male          -0.010421     -0.091776      0.045475     -0.052287  \n",
       "Embarked_C         0.361630      0.026735     -0.339198      0.325325  \n",
       "Embarked_Q        -0.097372      0.018938      0.206393     -0.093921  \n",
       "Embarked_S        -0.255526     -0.035339      0.167268     -0.225893  \n",
       "Title_Master       0.007963     -0.044095      0.012919     -0.046801  \n",
       "Title_Misc        -0.063208      0.056025     -0.009143      0.086656  \n",
       "Title_Miss         0.020804      0.033341     -0.008851      0.024675  \n",
       "Title_Mr           0.002834     -0.083562      0.035888     -0.041512  \n",
       "Title_Mrs         -0.001728      0.078680     -0.043914      0.015478  \n",
       "Ticket_len_10     -0.078529     -0.091182     -0.206928     -0.067067  \n",
       "Ticket_len_30     -0.143093     -0.166150     -0.377058     -0.122208  \n",
       "Ticket_len_4       1.000000     -0.148449     -0.336886     -0.109188  \n",
       "Ticket_len_5      -0.148449      1.000000     -0.391169     -0.126782  \n",
       "Ticket_len_6      -0.336886     -0.391169      1.000000     -0.287716  \n",
       "Ticket_len_8      -0.109188     -0.126782     -0.287716      1.000000  \n",
       "\n",
       "[24 rows x 24 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap all preprocesses to a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_p (train, test):\n",
    "    train_c = data_clean(train)\n",
    "    train_f = f_eng(train_c)\n",
    "    y_train = train_f.Survived\n",
    "    X_train = train_f.drop('Survived', axis=1)\n",
    "    \n",
    "    test_c = data_clean(test)\n",
    "    test_f = f_eng(test_c)\n",
    "    X_test = test_f\n",
    "    \n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Ticket      0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "(891, 10)\n",
      "   Survived  Pclass                                               Name  \\\n",
      "0         0       3                            Braund, Mr. Owen Harris   \n",
      "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "2         1       3                             Heikkinen, Miss. Laina   \n",
      "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "4         0       3                           Allen, Mr. William Henry   \n",
      "\n",
      "      Sex   Age  SibSp  Parch            Ticket     Fare Embarked  \n",
      "0    male  22.0      1      0         A/5 21171   7.2500        S  \n",
      "1  female  38.0      1      0          PC 17599  71.2833        C  \n",
      "2  female  26.0      0      0  STON/O2. 3101282   7.9250        S  \n",
      "3  female  35.0      1      0            113803  53.1000        S  \n",
      "4    male  35.0      0      0            373450   8.0500        S  \n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Ticket      0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "(418, 9)\n",
      "   Pclass                                          Name     Sex   Age  SibSp  \\\n",
      "0       3                              Kelly, Mr. James    male  34.5      0   \n",
      "1       3              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1   \n",
      "2       2                     Myles, Mr. Thomas Francis    male  62.0      0   \n",
      "3       3                              Wirz, Mr. Albert    male  27.0      0   \n",
      "4       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1   \n",
      "\n",
      "   Parch   Ticket     Fare Embarked  \n",
      "0      0   330911   7.8292        Q  \n",
      "1      0   363272   7.0000        S  \n",
      "2      0   240276   9.6875        Q  \n",
      "3      0   315154   8.6625        S  \n",
      "4      1  3101298  12.2875        S  \n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test = pre_p (train_raw, test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <th>Ticket_len_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  SibSp  Parch  FareBin  AgeBin  IsAlone  FamilySize  Sex_female  \\\n",
       "0         3      1      0        1       2        1           2         0.0   \n",
       "1         1      1      0        5       3        1           2         1.0   \n",
       "2         3      0      0        2       2        0           1         1.0   \n",
       "3         1      1      0        5       3        1           2         1.0   \n",
       "4         3      0      0        2       3        0           1         0.0   \n",
       "5         3      0      0        2       2        0           1         0.0   \n",
       "6         1      0      0        5       4        0           1         0.0   \n",
       "7         3      3      1        3       1        1           5         0.0   \n",
       "8         3      0      2        3       2        1           3         1.0   \n",
       "9         2      1      0        4       1        1           2         1.0   \n",
       "10        3      1      1        3       1        1           3         1.0   \n",
       "11        1      0      0        4       4        0           1         1.0   \n",
       "12        3      0      0        2       2        0           1         0.0   \n",
       "13        3      1      5        4       3        1           7         0.0   \n",
       "14        3      0      0        1       1        0           1         1.0   \n",
       "15        2      0      0        3       4        0           1         1.0   \n",
       "16        3      4      1        4       1        1           6         0.0   \n",
       "17        2      0      0        3       3        0           1         0.0   \n",
       "18        3      1      0        3       2        1           2         1.0   \n",
       "19        3      0      0        1       2        0           1         1.0   \n",
       "20        2      0      0        4       3        0           1         0.0   \n",
       "21        2      0      0        3       3        0           1         0.0   \n",
       "22        3      0      0        2       1        0           1         1.0   \n",
       "23        1      0      0        4       2        0           1         0.0   \n",
       "24        3      3      1        3       1        1           5         1.0   \n",
       "25        3      1      5        4       3        1           7         1.0   \n",
       "26        3      0      0        1       2        0           1         0.0   \n",
       "27        1      3      2        5       2        1           6         0.0   \n",
       "28        3      0      0        2       2        0           1         1.0   \n",
       "29        3      0      0        2       2        0           1         0.0   \n",
       "..      ...    ...    ...      ...     ...      ...         ...         ...   \n",
       "861       2      1      0        3       2        1           2         0.0   \n",
       "862       1      0      0        4       3        0           1         1.0   \n",
       "863       3      8      2        5       2        1          11         1.0   \n",
       "864       2      0      0        3       2        0           1         0.0   \n",
       "865       2      0      0        3       3        0           1         1.0   \n",
       "866       2      1      0        3       2        1           2         1.0   \n",
       "867       1      0      0        5       2        0           1         0.0   \n",
       "868       3      0      0        2       2        0           1         0.0   \n",
       "869       3      1      1        3       1        1           3         0.0   \n",
       "870       3      0      0        2       2        0           1         0.0   \n",
       "871       1      1      1        5       3        1           3         1.0   \n",
       "872       1      0      0        1       3        0           1         0.0   \n",
       "873       3      0      0        2       3        0           1         0.0   \n",
       "874       2      1      0        4       2        1           2         1.0   \n",
       "875       3      0      0        1       1        0           1         1.0   \n",
       "876       3      0      0        2       2        0           1         0.0   \n",
       "877       3      0      0        2       2        0           1         0.0   \n",
       "878       3      0      0        2       2        0           1         0.0   \n",
       "879       1      0      1        5       4        1           2         1.0   \n",
       "880       2      0      1        4       2        1           2         1.0   \n",
       "881       3      0      0        2       3        0           1         0.0   \n",
       "882       3      0      0        3       2        0           1         1.0   \n",
       "883       2      0      0        2       2        0           1         0.0   \n",
       "884       3      0      0        1       2        0           1         0.0   \n",
       "885       3      0      5        4       3        1           6         1.0   \n",
       "886       2      0      0        3       2        0           1         0.0   \n",
       "887       1      0      0        4       2        0           1         1.0   \n",
       "888       3      1      2        4       2        1           4         1.0   \n",
       "889       1      0      0        4       2        0           1         0.0   \n",
       "890       3      0      0        1       2        0           1         0.0   \n",
       "\n",
       "     Sex_male  Embarked_C  ...  Title_Misc  Title_Miss  Title_Mr  Title_Mrs  \\\n",
       "0         1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "1         0.0         1.0  ...         0.0         0.0       0.0        1.0   \n",
       "2         0.0         0.0  ...         0.0         1.0       0.0        0.0   \n",
       "3         0.0         0.0  ...         0.0         0.0       0.0        1.0   \n",
       "4         1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "5         1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "6         1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "7         1.0         0.0  ...         0.0         0.0       0.0        0.0   \n",
       "8         0.0         0.0  ...         0.0         0.0       0.0        1.0   \n",
       "9         0.0         1.0  ...         0.0         0.0       0.0        1.0   \n",
       "10        0.0         0.0  ...         0.0         1.0       0.0        0.0   \n",
       "11        0.0         0.0  ...         0.0         1.0       0.0        0.0   \n",
       "12        1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "13        1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "14        0.0         0.0  ...         0.0         1.0       0.0        0.0   \n",
       "15        0.0         0.0  ...         0.0         0.0       0.0        1.0   \n",
       "16        1.0         0.0  ...         0.0         0.0       0.0        0.0   \n",
       "17        1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "18        0.0         0.0  ...         0.0         0.0       0.0        1.0   \n",
       "19        0.0         1.0  ...         0.0         0.0       0.0        1.0   \n",
       "20        1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "21        1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "22        0.0         0.0  ...         0.0         1.0       0.0        0.0   \n",
       "23        1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "24        0.0         0.0  ...         0.0         1.0       0.0        0.0   \n",
       "25        0.0         0.0  ...         0.0         0.0       0.0        1.0   \n",
       "26        1.0         1.0  ...         0.0         0.0       1.0        0.0   \n",
       "27        1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "28        0.0         0.0  ...         0.0         1.0       0.0        0.0   \n",
       "29        1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "..        ...         ...  ...         ...         ...       ...        ...   \n",
       "861       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "862       0.0         0.0  ...         0.0         0.0       0.0        1.0   \n",
       "863       0.0         0.0  ...         0.0         1.0       0.0        0.0   \n",
       "864       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "865       0.0         0.0  ...         0.0         0.0       0.0        1.0   \n",
       "866       0.0         1.0  ...         0.0         1.0       0.0        0.0   \n",
       "867       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "868       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "869       1.0         0.0  ...         0.0         0.0       0.0        0.0   \n",
       "870       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "871       0.0         0.0  ...         0.0         0.0       0.0        1.0   \n",
       "872       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "873       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "874       0.0         1.0  ...         0.0         0.0       0.0        1.0   \n",
       "875       0.0         1.0  ...         0.0         1.0       0.0        0.0   \n",
       "876       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "877       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "878       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "879       0.0         1.0  ...         0.0         0.0       0.0        1.0   \n",
       "880       0.0         0.0  ...         0.0         0.0       0.0        1.0   \n",
       "881       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "882       0.0         0.0  ...         0.0         1.0       0.0        0.0   \n",
       "883       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "884       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "885       0.0         0.0  ...         0.0         0.0       0.0        1.0   \n",
       "886       1.0         0.0  ...         1.0         0.0       0.0        0.0   \n",
       "887       0.0         0.0  ...         0.0         1.0       0.0        0.0   \n",
       "888       0.0         0.0  ...         0.0         1.0       0.0        0.0   \n",
       "889       1.0         1.0  ...         0.0         0.0       1.0        0.0   \n",
       "890       1.0         0.0  ...         0.0         0.0       1.0        0.0   \n",
       "\n",
       "     Ticket_len_10  Ticket_len_30  Ticket_len_4  Ticket_len_5  Ticket_len_6  \\\n",
       "0              0.0            1.0           0.0           0.0           0.0   \n",
       "1              0.0            0.0           0.0           0.0           0.0   \n",
       "2              0.0            1.0           0.0           0.0           0.0   \n",
       "3              0.0            0.0           0.0           0.0           1.0   \n",
       "4              0.0            0.0           0.0           0.0           1.0   \n",
       "5              0.0            0.0           0.0           0.0           1.0   \n",
       "6              0.0            0.0           0.0           1.0           0.0   \n",
       "7              0.0            0.0           0.0           0.0           1.0   \n",
       "8              0.0            0.0           0.0           0.0           1.0   \n",
       "9              0.0            0.0           0.0           0.0           1.0   \n",
       "10             0.0            1.0           0.0           0.0           0.0   \n",
       "11             0.0            0.0           0.0           0.0           1.0   \n",
       "12             0.0            1.0           0.0           0.0           0.0   \n",
       "13             0.0            0.0           0.0           0.0           1.0   \n",
       "14             0.0            0.0           0.0           0.0           1.0   \n",
       "15             0.0            0.0           0.0           0.0           1.0   \n",
       "16             0.0            0.0           0.0           0.0           1.0   \n",
       "17             0.0            0.0           0.0           0.0           1.0   \n",
       "18             0.0            0.0           0.0           0.0           1.0   \n",
       "19             0.0            0.0           1.0           0.0           0.0   \n",
       "20             0.0            0.0           0.0           0.0           1.0   \n",
       "21             0.0            0.0           0.0           0.0           1.0   \n",
       "22             0.0            0.0           0.0           0.0           1.0   \n",
       "23             0.0            0.0           0.0           0.0           1.0   \n",
       "24             0.0            0.0           0.0           0.0           1.0   \n",
       "25             0.0            0.0           0.0           0.0           1.0   \n",
       "26             0.0            0.0           1.0           0.0           0.0   \n",
       "27             0.0            0.0           0.0           1.0           0.0   \n",
       "28             0.0            0.0           0.0           0.0           1.0   \n",
       "29             0.0            0.0           0.0           0.0           1.0   \n",
       "..             ...            ...           ...           ...           ...   \n",
       "861            0.0            0.0           0.0           1.0           0.0   \n",
       "862            0.0            0.0           0.0           1.0           0.0   \n",
       "863            0.0            0.0           0.0           0.0           0.0   \n",
       "864            0.0            0.0           0.0           0.0           1.0   \n",
       "865            0.0            0.0           0.0           0.0           1.0   \n",
       "866            0.0            1.0           0.0           0.0           0.0   \n",
       "867            0.0            0.0           0.0           0.0           0.0   \n",
       "868            0.0            0.0           0.0           0.0           1.0   \n",
       "869            0.0            0.0           0.0           0.0           1.0   \n",
       "870            0.0            0.0           0.0           0.0           1.0   \n",
       "871            0.0            0.0           0.0           1.0           0.0   \n",
       "872            0.0            1.0           0.0           0.0           0.0   \n",
       "873            0.0            0.0           0.0           0.0           1.0   \n",
       "874            0.0            1.0           0.0           0.0           0.0   \n",
       "875            0.0            0.0           1.0           0.0           0.0   \n",
       "876            0.0            0.0           1.0           0.0           0.0   \n",
       "877            0.0            0.0           0.0           0.0           1.0   \n",
       "878            0.0            0.0           0.0           0.0           1.0   \n",
       "879            0.0            0.0           0.0           1.0           0.0   \n",
       "880            0.0            0.0           0.0           0.0           1.0   \n",
       "881            0.0            0.0           0.0           0.0           1.0   \n",
       "882            0.0            0.0           1.0           0.0           0.0   \n",
       "883            0.0            1.0           0.0           0.0           0.0   \n",
       "884            0.0            1.0           0.0           0.0           0.0   \n",
       "885            0.0            0.0           0.0           0.0           1.0   \n",
       "886            0.0            0.0           0.0           0.0           1.0   \n",
       "887            0.0            0.0           0.0           0.0           1.0   \n",
       "888            1.0            0.0           0.0           0.0           0.0   \n",
       "889            0.0            0.0           0.0           0.0           1.0   \n",
       "890            0.0            0.0           0.0           0.0           1.0   \n",
       "\n",
       "     Ticket_len_8  \n",
       "0             0.0  \n",
       "1             1.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "5             0.0  \n",
       "6             0.0  \n",
       "7             0.0  \n",
       "8             0.0  \n",
       "9             0.0  \n",
       "10            0.0  \n",
       "11            0.0  \n",
       "12            0.0  \n",
       "13            0.0  \n",
       "14            0.0  \n",
       "15            0.0  \n",
       "16            0.0  \n",
       "17            0.0  \n",
       "18            0.0  \n",
       "19            0.0  \n",
       "20            0.0  \n",
       "21            0.0  \n",
       "22            0.0  \n",
       "23            0.0  \n",
       "24            0.0  \n",
       "25            0.0  \n",
       "26            0.0  \n",
       "27            0.0  \n",
       "28            0.0  \n",
       "29            0.0  \n",
       "..            ...  \n",
       "861           0.0  \n",
       "862           0.0  \n",
       "863           1.0  \n",
       "864           0.0  \n",
       "865           0.0  \n",
       "866           0.0  \n",
       "867           1.0  \n",
       "868           0.0  \n",
       "869           0.0  \n",
       "870           0.0  \n",
       "871           0.0  \n",
       "872           0.0  \n",
       "873           0.0  \n",
       "874           0.0  \n",
       "875           0.0  \n",
       "876           0.0  \n",
       "877           0.0  \n",
       "878           0.0  \n",
       "879           0.0  \n",
       "880           0.0  \n",
       "881           0.0  \n",
       "882           0.0  \n",
       "883           0.0  \n",
       "884           0.0  \n",
       "885           0.0  \n",
       "886           0.0  \n",
       "887           0.0  \n",
       "888           0.0  \n",
       "889           0.0  \n",
       "890           0.0  \n",
       "\n",
       "[891 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model (X_tr, y_tr):\n",
    "    #this is from https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "    #Machine Learning Algorithm (MLA) Selection and Initialization\n",
    "    MLA = [\n",
    "        #Ensemble Methods\n",
    "        ensemble.AdaBoostClassifier(),\n",
    "        ensemble.BaggingClassifier(),\n",
    "        ensemble.ExtraTreesClassifier(),\n",
    "        ensemble.GradientBoostingClassifier(),\n",
    "        ensemble.RandomForestClassifier(),\n",
    "\n",
    "        #Gaussian Processes\n",
    "        gaussian_process.GaussianProcessClassifier(),\n",
    "\n",
    "        #GLM\n",
    "        linear_model.LogisticRegressionCV(),\n",
    "        linear_model.PassiveAggressiveClassifier(),\n",
    "        linear_model.RidgeClassifierCV(),\n",
    "        linear_model.SGDClassifier(),\n",
    "        linear_model.Perceptron(),\n",
    "\n",
    "        #Navies Bayes\n",
    "        naive_bayes.BernoulliNB(),\n",
    "        naive_bayes.GaussianNB(),\n",
    "\n",
    "        #Nearest Neighbor\n",
    "        neighbors.KNeighborsClassifier(),\n",
    "\n",
    "        #SVM\n",
    "        svm.SVC(probability=True),\n",
    "        svm.NuSVC(probability=True),\n",
    "        svm.LinearSVC(),\n",
    "\n",
    "        #Trees    \n",
    "        tree.DecisionTreeClassifier(),\n",
    "        tree.ExtraTreeClassifier(),\n",
    "\n",
    "        #Discriminant Analysis\n",
    "        discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "        discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "\n",
    "        #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "        XGBClassifier()    \n",
    "        ]\n",
    "    \n",
    "    #split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
    "    #note: this is an alternative to train_test_split\n",
    "    #cv_split = model_selection.ShuffleSplit(test_size = .2, train_size = .8, random_state = 0 ) # run model 10x with 80/20 split intentionally leaving out 10%\n",
    "\n",
    "    #create table to compare MLA metrics\n",
    "    MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
    "    MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "    #create table to compare MLA predictions\n",
    "    MLA_predict = y_tr\n",
    "\n",
    "    #index through MLA and save performance to table\n",
    "    row_index = 0\n",
    "    for alg in MLA:\n",
    "\n",
    "        #set name and parameters\n",
    "        MLA_name = alg.__class__.__name__\n",
    "        #print(MLA_name)\n",
    "        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "        MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "        #print(y_tr.shape)\n",
    "\n",
    "        #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "        cv_results = model_selection.cross_validate(alg, X_tr, y_tr, cv = 5, scoring='accuracy', return_train_score=True)\n",
    "        \n",
    "\n",
    "        MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
    "        MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "        MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
    "        #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "        MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "\n",
    "\n",
    "        #save MLA predictions - see section 6 for usage\n",
    "        #alg.fit(X_tr, y_tr)\n",
    "        #MLA_predict[MLA_name] = alg.predict(X_tr)\n",
    "\n",
    "        row_index+=1\n",
    "\n",
    "\n",
    "    #print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "    MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "    return MLA_compare\n",
    "    #MLA_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_alg = base_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'verbose': False, ...</td>\n",
       "      <td>0.833335</td>\n",
       "      <td>0.830549</td>\n",
       "      <td>0.0611035</td>\n",
       "      <td>0.0991999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'presort': 'auto', 'loss': 'deviance', 'min_i...</td>\n",
       "      <td>0.874864</td>\n",
       "      <td>0.829488</td>\n",
       "      <td>0.0951147</td>\n",
       "      <td>0.0880001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'loss': 'squared_hinge', 'C': 1.0, 'verbose':...</td>\n",
       "      <td>0.838387</td>\n",
       "      <td>0.828333</td>\n",
       "      <td>0.0801202</td>\n",
       "      <td>0.0536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>{'scoring': None, 'n_jobs': None, 'verbose': 0...</td>\n",
       "      <td>0.841753</td>\n",
       "      <td>0.827203</td>\n",
       "      <td>0.0862662</td>\n",
       "      <td>0.2896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'solver': 'svd', 'priors': None, 'n_component...</td>\n",
       "      <td>0.835302</td>\n",
       "      <td>0.827184</td>\n",
       "      <td>0.0831936</td>\n",
       "      <td>0.00700002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>{'kernel': 'rbf', 'verbose': False, 'probabili...</td>\n",
       "      <td>0.831933</td>\n",
       "      <td>0.827165</td>\n",
       "      <td>0.0576147</td>\n",
       "      <td>0.1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'reg_alpha': 0, 'colsample_bytree': 1, 'silen...</td>\n",
       "      <td>0.861957</td>\n",
       "      <td>0.824981</td>\n",
       "      <td>0.0958777</td>\n",
       "      <td>0.0405999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>{'normalize': False, 'alphas': array([ 0.1,  1...</td>\n",
       "      <td>0.834741</td>\n",
       "      <td>0.824924</td>\n",
       "      <td>0.0747722</td>\n",
       "      <td>0.00800004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>{'warm_start': False, 'kernel': None, 'n_jobs'...</td>\n",
       "      <td>0.894507</td>\n",
       "      <td>0.820468</td>\n",
       "      <td>0.0602524</td>\n",
       "      <td>0.3644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'n_estimators': 50, 'base_estimator': None, '...</td>\n",
       "      <td>0.832777</td>\n",
       "      <td>0.815998</td>\n",
       "      <td>0.0581527</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'n_neighbors': 5, 'n_jobs': None, 'algorithm'...</td>\n",
       "      <td>0.866168</td>\n",
       "      <td>0.811554</td>\n",
       "      <td>0.0807268</td>\n",
       "      <td>0.00599999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'warm_start': False, 'oob_score': False, 'n_j...</td>\n",
       "      <td>0.918073</td>\n",
       "      <td>0.798064</td>\n",
       "      <td>0.0898239</td>\n",
       "      <td>0.0290001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'warm_start': False, 'max_samples': 1.0, 'bas...</td>\n",
       "      <td>0.911901</td>\n",
       "      <td>0.796884</td>\n",
       "      <td>0.0787063</td>\n",
       "      <td>0.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>0.803593</td>\n",
       "      <td>0.789069</td>\n",
       "      <td>0.0616201</td>\n",
       "      <td>0.00379996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'binarize': 0.0, 'alpha': 1.0, 'fit_prior': T...</td>\n",
       "      <td>0.79377</td>\n",
       "      <td>0.784543</td>\n",
       "      <td>0.0559523</td>\n",
       "      <td>0.00279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'warm_start': False, 'oob_score': False, 'n_j...</td>\n",
       "      <td>0.913021</td>\n",
       "      <td>0.782334</td>\n",
       "      <td>0.0510728</td>\n",
       "      <td>0.0218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'splitter': 'random', 'min_impurity_decrease'...</td>\n",
       "      <td>0.918073</td>\n",
       "      <td>0.77563</td>\n",
       "      <td>0.0894311</td>\n",
       "      <td>0.00400004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'presort': False, 'splitter': 'best', 'min_im...</td>\n",
       "      <td>0.918073</td>\n",
       "      <td>0.77337</td>\n",
       "      <td>0.0909213</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>{'warm_start': False, 'n_iter': None, 'n_jobs'...</td>\n",
       "      <td>0.777776</td>\n",
       "      <td>0.764356</td>\n",
       "      <td>0.118068</td>\n",
       "      <td>0.00439997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>{'warm_start': False, 'loss': 'hinge', 'C': 1....</td>\n",
       "      <td>0.716074</td>\n",
       "      <td>0.726092</td>\n",
       "      <td>0.51888</td>\n",
       "      <td>0.00679989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'n_jobs': None, 'shuffle': True, 'verbose': 0...</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.703996</td>\n",
       "      <td>0.33642</td>\n",
       "      <td>0.00419998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>{'priors': None, 'store_covariances': None, 'r...</td>\n",
       "      <td>0.684626</td>\n",
       "      <td>0.68475</td>\n",
       "      <td>0.0960356</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "14                            SVC   \n",
       "3      GradientBoostingClassifier   \n",
       "16                      LinearSVC   \n",
       "6            LogisticRegressionCV   \n",
       "19     LinearDiscriminantAnalysis   \n",
       "15                          NuSVC   \n",
       "21                  XGBClassifier   \n",
       "8               RidgeClassifierCV   \n",
       "5       GaussianProcessClassifier   \n",
       "0              AdaBoostClassifier   \n",
       "13           KNeighborsClassifier   \n",
       "2            ExtraTreesClassifier   \n",
       "1               BaggingClassifier   \n",
       "12                     GaussianNB   \n",
       "11                    BernoulliNB   \n",
       "4          RandomForestClassifier   \n",
       "18            ExtraTreeClassifier   \n",
       "17         DecisionTreeClassifier   \n",
       "10                     Perceptron   \n",
       "7     PassiveAggressiveClassifier   \n",
       "9                   SGDClassifier   \n",
       "20  QuadraticDiscriminantAnalysis   \n",
       "\n",
       "                                       MLA Parameters MLA Train Accuracy Mean  \\\n",
       "14  {'kernel': 'rbf', 'C': 1.0, 'verbose': False, ...                0.833335   \n",
       "3   {'presort': 'auto', 'loss': 'deviance', 'min_i...                0.874864   \n",
       "16  {'loss': 'squared_hinge', 'C': 1.0, 'verbose':...                0.838387   \n",
       "6   {'scoring': None, 'n_jobs': None, 'verbose': 0...                0.841753   \n",
       "19  {'solver': 'svd', 'priors': None, 'n_component...                0.835302   \n",
       "15  {'kernel': 'rbf', 'verbose': False, 'probabili...                0.831933   \n",
       "21  {'reg_alpha': 0, 'colsample_bytree': 1, 'silen...                0.861957   \n",
       "8   {'normalize': False, 'alphas': array([ 0.1,  1...                0.834741   \n",
       "5   {'warm_start': False, 'kernel': None, 'n_jobs'...                0.894507   \n",
       "0   {'n_estimators': 50, 'base_estimator': None, '...                0.832777   \n",
       "13  {'n_neighbors': 5, 'n_jobs': None, 'algorithm'...                0.866168   \n",
       "2   {'warm_start': False, 'oob_score': False, 'n_j...                0.918073   \n",
       "1   {'warm_start': False, 'max_samples': 1.0, 'bas...                0.911901   \n",
       "12           {'priors': None, 'var_smoothing': 1e-09}                0.803593   \n",
       "11  {'binarize': 0.0, 'alpha': 1.0, 'fit_prior': T...                 0.79377   \n",
       "4   {'warm_start': False, 'oob_score': False, 'n_j...                0.913021   \n",
       "18  {'splitter': 'random', 'min_impurity_decrease'...                0.918073   \n",
       "17  {'presort': False, 'splitter': 'best', 'min_im...                0.918073   \n",
       "10  {'warm_start': False, 'n_iter': None, 'n_jobs'...                0.777776   \n",
       "7   {'warm_start': False, 'loss': 'hinge', 'C': 1....                0.716074   \n",
       "9   {'n_jobs': None, 'shuffle': True, 'verbose': 0...                0.723577   \n",
       "20  {'priors': None, 'store_covariances': None, 'r...                0.684626   \n",
       "\n",
       "   MLA Test Accuracy Mean MLA Test Accuracy 3*STD    MLA Time  \n",
       "14               0.830549               0.0611035   0.0991999  \n",
       "3                0.829488               0.0951147   0.0880001  \n",
       "16               0.828333               0.0801202      0.0536  \n",
       "6                0.827203               0.0862662      0.2896  \n",
       "19               0.827184               0.0831936  0.00700002  \n",
       "15               0.827165               0.0576147      0.1146  \n",
       "21               0.824981               0.0958777   0.0405999  \n",
       "8                0.824924               0.0747722  0.00800004  \n",
       "5                0.820468               0.0602524      0.3644  \n",
       "0                0.815998               0.0581527       0.125  \n",
       "13               0.811554               0.0807268  0.00599999  \n",
       "2                0.798064               0.0898239   0.0290001  \n",
       "1                0.796884               0.0787063      0.0282  \n",
       "12               0.789069               0.0616201  0.00379996  \n",
       "11               0.784543               0.0559523  0.00279999  \n",
       "4                0.782334               0.0510728      0.0218  \n",
       "18                0.77563               0.0894311  0.00400004  \n",
       "17                0.77337               0.0909213      0.0046  \n",
       "10               0.764356                0.118068  0.00439997  \n",
       "7                0.726092                 0.51888  0.00679989  \n",
       "9                0.703996                 0.33642  0.00419998  \n",
       "20                0.68475               0.0960356      0.0026  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Algorithm')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\n",
    "sns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = base_alg, color = 'm')\n",
    "\n",
    "#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\n",
    "plt.title('Machine Learning Algorithm Accuracy Score \\n')\n",
    "plt.xlabel('Accuracy Score (%)')\n",
    "plt.ylabel('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is borrowed from the Kaggle notebook https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "#the original idea was to take the top ten from our list above, but since the alg list below covers a large portion of our top ten, we will use it directly\n",
    "def hp_tune(X_tr, y_tr):\n",
    "    \n",
    "    vote_est = [\n",
    "                #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n",
    "                ('ada', ensemble.AdaBoostClassifier()),\n",
    "                ('bc', ensemble.BaggingClassifier()),\n",
    "                ('etc',ensemble.ExtraTreesClassifier()),\n",
    "                ('gbc', ensemble.GradientBoostingClassifier()),\n",
    "                ('rfc', ensemble.RandomForestClassifier()),\n",
    "\n",
    "                #Gaussian Processes: http://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process-classification-gpc\n",
    "                ('gpc', gaussian_process.GaussianProcessClassifier()),\n",
    "\n",
    "                #GLM: http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "                ('lr', linear_model.LogisticRegressionCV()),\n",
    "\n",
    "                #Navies Bayes: http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "                ('bnb', naive_bayes.BernoulliNB()),\n",
    "                ('gnb', naive_bayes.GaussianNB()),\n",
    "\n",
    "                #Nearest Neighbor: http://scikit-learn.org/stable/modules/neighbors.html\n",
    "                ('knn', neighbors.KNeighborsClassifier()),\n",
    "\n",
    "                #SVM: http://scikit-learn.org/stable/modules/svm.html\n",
    "                ('svc', svm.SVC(probability=True)),\n",
    "\n",
    "                #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "               ('xgb', XGBClassifier())\n",
    "\n",
    "                ]\n",
    "    \n",
    "    #Hyperparameter Tune with GridSearchCV: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "    grid_n_estimator = [10, 50, 100, 300, 500]\n",
    "    grid_ratio = [.1, .25, .5, .75, 1.0]\n",
    "    grid_learn = [.01, .03, .05, .1, .25]\n",
    "    grid_max_depth = [2, 4, 6, 8, 10, None]\n",
    "    grid_min_samples = [5, 10, .03, .05, .10]\n",
    "    grid_criterion = ['gini', 'entropy']\n",
    "    grid_bool = [True, False]\n",
    "    grid_seed = [0]\n",
    "\n",
    "\n",
    "    grid_param = [\n",
    "                [{\n",
    "                #AdaBoostClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "                'n_estimators': grid_n_estimator, #default=50\n",
    "                'learning_rate': grid_learn, #default=1\n",
    "                #'algorithm': ['SAMME', 'SAMME.R'], #default=’SAMME.R\n",
    "                'random_state': grid_seed\n",
    "                }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #BaggingClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier\n",
    "                'n_estimators': grid_n_estimator, #default=10\n",
    "                'max_samples': grid_ratio, #default=1.0\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #ExtraTreesClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier\n",
    "                'n_estimators': grid_n_estimator, #default=10\n",
    "                'criterion': grid_criterion, #default=”gini”\n",
    "                'max_depth': grid_max_depth, #default=None\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #GradientBoostingClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n",
    "                #'loss': ['deviance', 'exponential'], #default=’deviance’\n",
    "                'learning_rate': [.05], #default=0.1 -- 12/31/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.\n",
    "                'n_estimators': [300], #default=100 -- 12/31/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.\n",
    "                #'criterion': ['friedman_mse', 'mse', 'mae'], #default=”friedman_mse”\n",
    "                'max_depth': grid_max_depth, #default=3   \n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #RandomForestClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "                'n_estimators': grid_n_estimator, #default=10\n",
    "                'criterion': grid_criterion, #default=”gini”\n",
    "                'max_depth': grid_max_depth, #default=None\n",
    "                'oob_score': [True], #default=False -- 12/31/17 set to reduce runtime -- The best parameter for RandomForestClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'oob_score': True, 'random_state': 0} with a runtime of 146.35 seconds.\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "                [{    \n",
    "                #GaussianProcessClassifier\n",
    "                'max_iter_predict': grid_n_estimator, #default: 100\n",
    "                'random_state': grid_seed\n",
    "                }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #LogisticRegressionCV - http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV\n",
    "                'fit_intercept': grid_bool, #default: True\n",
    "                #'penalty': ['l1','l2'],\n",
    "                'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], #default: lbfgs\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #BernoulliNB - http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB\n",
    "                'alpha': grid_ratio, #default: 1.0\n",
    "                 }],\n",
    "\n",
    "\n",
    "                #GaussianNB - \n",
    "                [{}],\n",
    "\n",
    "                [{\n",
    "                #KNeighborsClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "                'n_neighbors': [1,2,3,4,5,6,7], #default: 5\n",
    "                'weights': ['uniform', 'distance'], #default = ‘uniform’\n",
    "                'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "                }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #SVC - http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "                #http://blog.hackerearth.com/simple-tutorial-svm-parameter-tuning-python-r\n",
    "                #'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                'C': [1,2,3,4,5], #default=1.0\n",
    "                'gamma': grid_ratio, #edfault: auto\n",
    "                'decision_function_shape': ['ovo', 'ovr'], #default:ovr\n",
    "                'probability': [True],\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #XGBClassifier - http://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "                'learning_rate': grid_learn, #default: .3\n",
    "                'max_depth': [1,2,4,6,8,10], #default 2\n",
    "                'n_estimators': grid_n_estimator, \n",
    "                'seed': grid_seed  \n",
    "                 }]   \n",
    "            ]\n",
    "\n",
    "    \n",
    "    #create a table to display key metrics\n",
    "    hp_columns = ['Alg Name', 'Best Score', 'Score Before Tuning', 'Best Parameters']\n",
    "    hp_compare = pd.DataFrame(columns = hp_columns)\n",
    "\n",
    "    #index through MLA and save performance to table\n",
    "    row_index = 0\n",
    "\n",
    "    for clf, param in zip (vote_est, grid_param): #https://docs.python.org/3/library/functions.html#zip\n",
    "\n",
    "     \n",
    "        best_search = model_selection.GridSearchCV(estimator = clf[1], param_grid = param, cv = 5, scoring = 'accuracy')\n",
    "        best_search.fit(X_tr, y_tr)\n",
    "\n",
    "        best_param = best_search.best_params_\n",
    "        best_score = best_search.best_score_\n",
    "        alg_name = clf[1].__class__.__name__\n",
    "        #print('The best parameter for {} is {} with a runtime of {:.2f} seconds.'.format(clf[1].__class__.__name__, best_param, run))\n",
    "        clf[1].set_params(**best_param) \n",
    "        \n",
    "        hp_compare.loc[row_index, 'Alg Name'] = alg_name\n",
    "        hp_compare.loc[row_index, 'Best Parameters'] = str(best_param)\n",
    "        hp_compare.loc[row_index, 'Best Score'] = best_score\n",
    "        hp_compare.loc[row_index, 'Score Before Tuning'] = base_alg.loc[base_alg['MLA Name'] == alg_name]['MLA Test Accuracy Mean'].tolist()[0]\n",
    "        row_index+=1\n",
    "\n",
    "\n",
    "    print('Done')\n",
    "    print('-'*10)\n",
    "    \n",
    "    return vote_est, hp_compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "tuned_algs, hp_compare = hp_tune(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alg Name</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Score Before Tuning</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.824981</td>\n",
       "      <td>{'n_estimators': 50, 'learning_rate': 0.05, 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.830549</td>\n",
       "      <td>{'C': 3, 'random_state': 0, 'decision_function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.829405</td>\n",
       "      <td>0.796884</td>\n",
       "      <td>{'n_estimators': 500, 'max_samples': 0.5, 'ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.829405</td>\n",
       "      <td>0.782334</td>\n",
       "      <td>{'n_estimators': 100, 'oob_score': True, 'rand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.815998</td>\n",
       "      <td>{'n_estimators': 300, 'learning_rate': 0.03, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.798064</td>\n",
       "      <td>{'n_estimators': 100, 'random_state': 0, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.82716</td>\n",
       "      <td>0.827203</td>\n",
       "      <td>{'solver': 'newton-cg', 'random_state': 0, 'fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.824916</td>\n",
       "      <td>0.829488</td>\n",
       "      <td>{'n_estimators': 300, 'learning_rate': 0.05, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.822671</td>\n",
       "      <td>0.811554</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'uniform', 'algo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.820468</td>\n",
       "      <td>{'max_iter_predict': 10, 'random_state': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.789001</td>\n",
       "      <td>0.789069</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.784512</td>\n",
       "      <td>0.784543</td>\n",
       "      <td>{'alpha': 0.25}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Alg Name Best Score Score Before Tuning  \\\n",
       "11               XGBClassifier   0.838384            0.824981   \n",
       "10                         SVC   0.830527            0.830549   \n",
       "1            BaggingClassifier   0.829405            0.796884   \n",
       "4       RandomForestClassifier   0.829405            0.782334   \n",
       "0           AdaBoostClassifier   0.828283            0.815998   \n",
       "2         ExtraTreesClassifier   0.828283            0.798064   \n",
       "6         LogisticRegressionCV    0.82716            0.827203   \n",
       "3   GradientBoostingClassifier   0.824916            0.829488   \n",
       "9         KNeighborsClassifier   0.822671            0.811554   \n",
       "5    GaussianProcessClassifier   0.820426            0.820468   \n",
       "8                   GaussianNB   0.789001            0.789069   \n",
       "7                  BernoulliNB   0.784512            0.784543   \n",
       "\n",
       "                                      Best Parameters  \n",
       "11  {'n_estimators': 50, 'learning_rate': 0.05, 's...  \n",
       "10  {'C': 3, 'random_state': 0, 'decision_function...  \n",
       "1   {'n_estimators': 500, 'max_samples': 0.5, 'ran...  \n",
       "4   {'n_estimators': 100, 'oob_score': True, 'rand...  \n",
       "0   {'n_estimators': 300, 'learning_rate': 0.03, '...  \n",
       "2   {'n_estimators': 100, 'random_state': 0, 'crit...  \n",
       "6   {'solver': 'newton-cg', 'random_state': 0, 'fi...  \n",
       "3   {'n_estimators': 300, 'learning_rate': 0.05, '...  \n",
       "9   {'n_neighbors': 5, 'weights': 'uniform', 'algo...  \n",
       "5         {'max_iter_predict': 10, 'random_state': 0}  \n",
       "8                                                  {}  \n",
       "7                                     {'alpha': 0.25}  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_compare.sort_values(by='Best Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alg Name                                                   XGBClassifier\n",
       "Best Score                                                      0.838384\n",
       "Score Before Tuning                                             0.824981\n",
       "Best Parameters        {'n_estimators': 50, 'learning_rate': 0.05, 's...\n",
       "Name: 11, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_compare.sort_values(by='Best Score', ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Ensemble Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_alg (algs, X_tr, y_tr):\n",
    "    \n",
    "    grid_hard = ensemble.VotingClassifier(estimators = algs , voting = 'hard')\n",
    "    grid_hard_cv = model_selection.cross_validate(grid_hard, X_tr, y_tr, cv  = 5)\n",
    "    grid_hard.fit(X_tr, y_tr)\n",
    "\n",
    "    print(\"Hard Voting w/Tuned Hyperparameters Training w/bin score mean: {:.2f}\". format(grid_hard_cv['train_score'].mean()*100)) \n",
    "    print(\"Hard Voting w/Tuned Hyperparameters Test w/bin score mean: {:.2f}\". format(grid_hard_cv['test_score'].mean()*100))\n",
    "    print(\"Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- {:.2f}\". format(grid_hard_cv['test_score'].std()*100*3))\n",
    "    print('-'*10)\n",
    "\n",
    "    #Soft Vote or weighted probabilities w/Tuned Hyperparameters\n",
    "    grid_soft = ensemble.VotingClassifier(estimators = algs , voting = 'soft')\n",
    "    grid_soft_cv = model_selection.cross_validate(grid_soft, X_tr, y_tr, cv  = 5)\n",
    "    grid_soft.fit(X_tr, y_tr)\n",
    "\n",
    "    print(\"Soft Voting w/Tuned Hyperparameters Training w/bin score mean: {:.2f}\". format(grid_soft_cv['train_score'].mean()*100)) \n",
    "    print(\"Soft Voting w/Tuned Hyperparameters Test w/bin score mean: {:.2f}\". format(grid_soft_cv['test_score'].mean()*100))\n",
    "    print(\"Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- {:.2f}\". format(grid_soft_cv['test_score'].std()*100*3))\n",
    "    print('-'*10)\n",
    "    \n",
    "    return grid_hard, grid_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting w/Tuned Hyperparameters Training w/bin score mean: 85.58\n",
      "Hard Voting w/Tuned Hyperparameters Test w/bin score mean: 82.94\n",
      "Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 5.82\n",
      "----------\n",
      "Soft Voting w/Tuned Hyperparameters Training w/bin score mean: 85.19\n",
      "Soft Voting w/Tuned Hyperparameters Test w/bin score mean: 83.17\n",
      "Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 8.00\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "vc_hard_all, vc_soft_all = en_alg(tuned_algs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11                 XGBClassifier\n",
       "10                           SVC\n",
       "1              BaggingClassifier\n",
       "4         RandomForestClassifier\n",
       "0             AdaBoostClassifier\n",
       "2           ExtraTreesClassifier\n",
       "6           LogisticRegressionCV\n",
       "3     GradientBoostingClassifier\n",
       "9           KNeighborsClassifier\n",
       "5      GaussianProcessClassifier\n",
       "8                     GaussianNB\n",
       "7                    BernoulliNB\n",
       "Name: Alg Name, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_compare.sort_values(by='Best Score', ascending=False)['Alg Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AdaBoostClassifier'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_algs[0][1].__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_algs (sorted_score_df, algs, num_algs):\n",
    "    top_alg_ls = []\n",
    "    \n",
    "    for alg_name in sorted_score_df:\n",
    "        for alg in algs:\n",
    "            if alg[1].__class__.__name__ == alg_name:\n",
    "                top_alg_ls.append(alg)\n",
    "        \n",
    "    return top_alg_ls[:num_algs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_alg_names = hp_compare.sort_values(by='Best Score', ascending=False)['Alg Name']\n",
    "top_five_algs = top_algs(sorted_alg_names, tuned_algs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting w/Tuned Hyperparameters Training w/bin score mean: 86.48\n",
      "Hard Voting w/Tuned Hyperparameters Test w/bin score mean: 82.94\n",
      "Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 6.01\n",
      "----------\n",
      "Soft Voting w/Tuned Hyperparameters Training w/bin score mean: 87.94\n",
      "Soft Voting w/Tuned Hyperparameters Test w/bin score mean: 82.61\n",
      "Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 7.70\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "vc_hard_tfive, vc_soft_tfive = en_alg(top_five_algs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xgb', XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "         gamma=0, learning_rate=0.05, max_delta_step=0, max_depth=6,\n",
       "         min_child_weight=1, missing=None, n_estimators=50, nthread=-1,\n",
       "         objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "         scale_pos_weight=1, seed=0, silent=True, subsample=1)),\n",
       " ('svc', SVC(C=3, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovo', degree=3, gamma=0.1, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=0, shrinking=True, tol=0.001,\n",
       "    verbose=False)),\n",
       " ('bc', BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "           bootstrap_features=False, max_features=1.0, max_samples=0.5,\n",
       "           n_estimators=500, n_jobs=None, oob_score=False, random_state=0,\n",
       "           verbose=0, warm_start=False)),\n",
       " ('rfc',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "              oob_score=True, random_state=0, verbose=0, warm_start=False)),\n",
       " ('ada', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "            learning_rate=0.03, n_estimators=300, random_state=0))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_five_algs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_submissions(top_five, b_vc_hard, b_vc_soft, X_tr, y_tr, X_test):\n",
    "    \n",
    "    #create submissions for each alg in the top_five list\n",
    "    for alg in top_five:\n",
    "        alg[1].fit(X_tr, y_tr)\n",
    "        y_pred = alg[1].predict(X_test).astype(int)\n",
    "        final_data = {'PassengerId': test_raw.PassengerId, 'Survived': y_pred}\n",
    "        submission = pd.DataFrame(data=final_data)\n",
    "        submission.to_csv('submissions/submission_'+alg[0]+'.csv', index =False)\n",
    "        \n",
    "    #create submissions best hard and soft vc\n",
    "    #they are already fitted in the evaluation steps\n",
    "    y_pred_b_vc_hard = b_vc_hard.predict(X_test).astype(int)\n",
    "    y_pred_b_vc_soft = b_vc_soft.predict(X_test) .astype(int)\n",
    "    vc_hard_sub_data = {'PassengerId': test_raw.PassengerId, 'Survived': y_pred_b_vc_hard}\n",
    "    vc_soft_sub_data = {'PassengerId': test_raw.PassengerId, 'Survived': y_pred_b_vc_soft}\n",
    "    vc_hard_sub = pd.DataFrame(data=vc_hard_sub_data)\n",
    "    vc_soft_sub = pd.DataFrame(data=vc_soft_sub_data)\n",
    "    vc_hard_sub.to_csv('submissions/submission_vc_hard.csv', index =False) \n",
    "    vc_soft_sub.to_csv('submissions/submission_vc_soft.csv', index =False) \n",
    "    \n",
    "    print('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after some debugging, we found that Ticket_len_10 is missing from the X_test, as it was auto generated in X_train, need to improve the process in the next project\n",
    "X_test.insert(17, \"Ticket_len_10\", 0, allow_duplicates = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "gen_submissions(top_five_algs, vc_hard_all, vc_soft_all, X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-submission Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0305\n",
       "                \n",
       "                    &plusmn; 0.0039\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                FamilySize\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0168\n",
       "                \n",
       "                    &plusmn; 0.0032\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Pclass\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0097\n",
       "                \n",
       "                    &plusmn; 0.0034\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Title_Master\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0085\n",
       "                \n",
       "                    &plusmn; 0.0052\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SibSp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0070\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                FareBin\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.38%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0063\n",
       "                \n",
       "                    &plusmn; 0.0137\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Title_Mr\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.96%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0043\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Ticket_len_5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.96%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0043\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Ticket_len_4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.56%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0025\n",
       "                \n",
       "                    &plusmn; 0.0046\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                AgeBin\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.78%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0022\n",
       "                \n",
       "                    &plusmn; 0.0014\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Parch\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0020\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Title_Misc\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0020\n",
       "                \n",
       "                    &plusmn; 0.0036\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Ticket_len_6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0018\n",
       "                \n",
       "                    &plusmn; 0.0034\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                IsAlone\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0018\n",
       "                \n",
       "                    &plusmn; 0.0042\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Title_Miss\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0011\n",
       "                \n",
       "                    &plusmn; 0.0020\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Ticket_len_30\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0011\n",
       "                \n",
       "                    &plusmn; 0.0028\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Embarked_C\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0009\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Embarked_Q\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.96%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0027\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Ticket_len_8\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Ticket_len_10\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.96%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0004\n",
       "                \n",
       "                    &plusmn; 0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Embarked_S\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.78%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0022\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Sex_female\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.78%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0022\n",
       "                \n",
       "                    &plusmn; 0.0032\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Title_Mrs\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 91.21%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0094\n",
       "                \n",
       "                    &plusmn; 0.0097\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Sex_male\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(vc_soft_all, random_state=1).fit(X_train, y_train)\n",
    "eli5.show_weights(perm, feature_names = X_train.columns.tolist(), top = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name _validate_lengths",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-9c79a43cc81b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mshap\u001b[0m  \u001b[1;31m# package used to calculate Shap values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Create object that can calculate shap values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTreeExplainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvc_soft_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\wesu\\Anaconda3\\envs\\myenv\\lib\\site-packages\\shap\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGradientExplainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearExplainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary_plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdependence\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdependence_plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforce\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforce_plot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitjs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_html\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\wesu\\Anaconda3\\envs\\myenv\\lib\\site-packages\\shap\\plots\\summary.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# TODO: remove unused title argument / use title argument\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\wesu\\Anaconda3\\envs\\myenv\\lib\\site-packages\\shap\\plots\\colors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\wesu\\Anaconda3\\envs\\myenv\\lib\\site-packages\\skimage\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0m_raise_build_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\wesu\\Anaconda3\\envs\\myenv\\lib\\site-packages\\skimage\\util\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mapply_parallel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapply_parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0marraycrop\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcrop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_regular_grid\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregular_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregular_seeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munique_rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\wesu\\Anaconda3\\envs\\myenv\\lib\\site-packages\\skimage\\util\\arraycrop.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marraypad\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_validate_lengths\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name _validate_lengths"
     ]
    }
   ],
   "source": [
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(vc_soft_all)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Make plot. Index of [1] is explained in text below.\n",
    "shap.summary_plot(shap_values[1], X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 2\n",
    "We are not satisfy with the results we got from the first attempt, we want to try some advance feature engineering techniques\n",
    "\n",
    "### Objective\n",
    "Evaluate the effect on model accuracy for each feature engineering step taken in our last attempt, and try new feature engineering techniques \n",
    "\n",
    "### Action Plan\n",
    "- create a base model\n",
    "- evaluate each new feature created in iteration 1\n",
    "    - Agebin\n",
    "    - Farebin\n",
    "    - FamilySize\n",
    "    - IsAlone\n",
    "- Try new techniques\n",
    "    - Interactions\n",
    "    - normalizing continouse features\n",
    "    - Target Encoding\n",
    "    - CatBoost Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a base model, the best result we got from single model approach was XGB, we will use it as our base model in this experiment\n",
    "xgb = XGBClassifier(n_estimators=500)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Ticket      0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "(891, 10)\n",
      "   Survived  Pclass                                               Name  \\\n",
      "0         0       3                            Braund, Mr. Owen Harris   \n",
      "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "2         1       3                             Heikkinen, Miss. Laina   \n",
      "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "4         0       3                           Allen, Mr. William Henry   \n",
      "\n",
      "      Sex   Age  SibSp  Parch            Ticket     Fare Embarked  \n",
      "0    male  22.0      1      0         A/5 21171   7.2500        S  \n",
      "1  female  38.0      1      0          PC 17599  71.2833        C  \n",
      "2  female  26.0      0      0  STON/O2. 3101282   7.9250        S  \n",
      "3  female  35.0      1      0            113803  53.1000        S  \n",
      "4    male  35.0      0      0            373450   8.0500        S  \n"
     ]
    }
   ],
   "source": [
    "#prepare data for baseline evaluation \n",
    "train_i2 = train_raw.copy()\n",
    "train_i2 = data_clean(train_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_f_eng (clean_data):\n",
    "    \n",
    "    #next we work on text data\n",
    "    #extrat title from Name\n",
    "    clean_data['Title'] = clean_data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    \n",
    "    stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "    title_names = (clean_data['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n",
    "    #apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n",
    "    clean_data['Title'] = clean_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "    \n",
    "    \n",
    "    #do imputation on txt data\n",
    "    OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    imp_cols = OH_en.fit_transform(clean_data[['Sex','Embarked', 'Title']])\n",
    "    imp_cols = pd.DataFrame(imp_cols)\n",
    "    #now we align the index and col names\n",
    "    imp_cols.index = clean_data[['Sex','Embarked', 'Title']].index\n",
    "    imp_cols.columns = OH_en.get_feature_names(['Sex','Embarked', 'Title'])\n",
    "    clean_data = clean_data.drop(['Sex','Embarked', 'Title'], axis=1).join(imp_cols)\n",
    "    \n",
    "    clean_data = clean_data.drop('Ticket', axis=1)\n",
    "    clean_data = clean_data.drop('Name', axis=1)\n",
    "\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score (X, y):\n",
    "    cv_agebin_results = model_selection.cross_validate(xgb, X, y, cv = 5, scoring='accuracy', return_train_score=True)\n",
    "    print(cv_agebin_results['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xysplit (df):\n",
    "    X = df.drop('Survived', axis=1)\n",
    "    y = df['Survived']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_i2_base = base_f_eng (train_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base = train_i2_base.drop('Survived', axis=1)\n",
    "y_base = train_i2_base['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8238130752429171\n"
     ]
    }
   ],
   "source": [
    "score (X_base, y_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_bin (clean_data):\n",
    "    AgeBin = pd.cut(clean_data['Age'].astype(int), 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    AgeBin.name = 'AgeBin'\n",
    "    train_i2_agebin = train_i2_base.join(AgeBin)\n",
    "    train_i2_agebin = train_i2_agebin.drop('Age', axis =1)\n",
    "    \n",
    "    X, y = xysplit(train_i2_agebin)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8305672024163527\n"
     ]
    }
   ],
   "source": [
    "X_agebin, y_agebin = age_bin (train_i2)\n",
    "score (X_agebin, y_agebin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "converting Age data to Agebin improve prediction result by roughtly, 0.07%. base score: 0.8238130752429171 vs imporved score 0.8305672024163527\n",
    "\n",
    "#### Action to take\n",
    "Add AgeBin and drop Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_bin (clean_data):\n",
    "    FareBin = pd.cut(clean_data['Fare'].astype(int), 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    FareBin.name = 'FareBin'\n",
    "    train_i2_agebin = train_i2_base.join(FareBin)\n",
    "    train_i2_agebin = train_i2_agebin.drop('Fare', axis =1)\n",
    "    \n",
    "    X, y = xysplit(train_i2_agebin)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8283140180446253\n"
     ]
    }
   ],
   "source": [
    "X_farebin, y_farebin = fare_bin (train_i2)\n",
    "score (X_farebin, y_farebin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "The FareBin feature imporve score by 0.05, base score: 0.8238130752429171 vs imporved score 0.8283140180446253\n",
    "\n",
    "#### Action\n",
    "Generate FareBin and drop Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have all Fare values plus one to remove zeros\n",
    "fare_po = train_i2['Fare']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_fare = stats.boxcox(fare_po)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xd7c9ec8>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_i2['Fare'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_fare = pd.Series(boxcox_fare[0], index=train_i2['Fare'].index, name='boxcox_fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10bf06c8>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxcox_fare.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_fare = np.sqrt(train_i2['Fare'])\n",
    "sqrt_fare.name = 'sqrt_fare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fare = np.log(train_i2['Fare'])\n",
    "log_fare.name = 'log_fare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x109c3888>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sqrt_fare.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x106ad548>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_fare.hist(range=(0, 8), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_val (base_df, nor_fare):\n",
    "    \n",
    "    train_i2_nor_fare = base_df.join(nor_fare)\n",
    "    train_i2_nor_fare_final = train_i2_nor_fare.drop('Fare', axis=1)\n",
    "    X, y = xysplit(train_i2_nor_fare_final)\n",
    "    score (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8249556438128127\n"
     ]
    }
   ],
   "source": [
    "fare_val(train_i2_base, log_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8238130752429171\n"
     ]
    }
   ],
   "source": [
    "fare_val(train_i2_base, sqrt_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8238130752429171\n"
     ]
    }
   ],
   "source": [
    "fare_val(train_i2_base, boxcox_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what if we include both Farebin and nor_fare in the data\n",
    "def fare_w_fbin_val (base_df, nor_fare):\n",
    "    \n",
    "    train_i2_nor_fare = base_df.join(nor_fare)\n",
    "    train_i2_nor_fare_final = train_i2_nor_fare.drop('Fare', axis=1)\n",
    "    train_i2_nor_fare_final['FareBin'] = X_farebin['FareBin']\n",
    "    X, y = xysplit(train_i2_nor_fare_final)\n",
    "    score (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8249556438128127\n"
     ]
    }
   ],
   "source": [
    "fare_w_fbin_val(train_i2_base, log_fare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obervation\n",
    "Only Boxcox showed improvement on the result, and including FareBin with Boxcox did not improve the result. Comparing having just the FareBin, the score decreased.\n",
    "\n",
    "#### Action to take\n",
    "Not to include the normalized Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
       "0         0       3  22.0      1      0   7.2500         0.0       1.0   \n",
       "1         1       1  38.0      1      0  71.2833         1.0       0.0   \n",
       "2         1       3  26.0      0      0   7.9250         1.0       0.0   \n",
       "3         1       1  35.0      1      0  53.1000         1.0       0.0   \n",
       "4         0       3  35.0      0      0   8.0500         0.0       1.0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Misc  Title_Miss  \\\n",
       "0         0.0         0.0         1.0           0.0         0.0         0.0   \n",
       "1         1.0         0.0         0.0           0.0         0.0         0.0   \n",
       "2         0.0         0.0         1.0           0.0         0.0         1.0   \n",
       "3         0.0         0.0         1.0           0.0         0.0         0.0   \n",
       "4         0.0         0.0         1.0           0.0         0.0         0.0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  \n",
       "0       1.0        0.0  \n",
       "1       0.0        1.0  \n",
       "2       0.0        0.0  \n",
       "3       0.0        1.0  \n",
       "4       1.0        0.0  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_i2_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
       "0         0       3  22.0      1      0   7.2500         0.0       1.0   \n",
       "1         1       1  38.0      1      0  71.2833         1.0       0.0   \n",
       "2         1       3  26.0      0      0   7.9250         1.0       0.0   \n",
       "3         1       1  35.0      1      0  53.1000         1.0       0.0   \n",
       "4         0       3  35.0      0      0   8.0500         0.0       1.0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Misc  Title_Miss  \\\n",
       "0         0.0         0.0         1.0           0.0         0.0         0.0   \n",
       "1         1.0         0.0         0.0           0.0         0.0         0.0   \n",
       "2         0.0         0.0         1.0           0.0         0.0         1.0   \n",
       "3         0.0         0.0         1.0           0.0         0.0         0.0   \n",
       "4         0.0         0.0         1.0           0.0         0.0         0.0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  FamilySize  \n",
       "0       1.0        0.0           2  \n",
       "1       0.0        1.0           2  \n",
       "2       0.0        0.0           1  \n",
       "3       0.0        1.0           2  \n",
       "4       1.0        0.0           1  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FamilySize evaluation\n",
    "train_i2_fz = train_i2_base.copy()\n",
    "train_i2_fz['FamilySize'] = train_i2_fz['SibSp']+train_i2_fz['Parch']+1\n",
    "train_i2_fz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8361728385867444\n"
     ]
    }
   ],
   "source": [
    "X_fz, y_fz = xysplit(train_i2_fz)\n",
    "score (X_fz, y_fz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8384009856063596\n"
     ]
    }
   ],
   "source": [
    "train_i2_fz_noraw = train_i2_fz.drop(['SibSp', 'Parch'], axis=1)\n",
    "X_fz_nr, y_fz_nr = xysplit(train_i2_fz_noraw)\n",
    "score (X_fz_nr, y_fz_nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation \n",
    "Engineering the FamilySize feature improves the model, base score: 0.8238130752429171 vs imporved score 0.8361728385867444. And removing the original features further imporved the result by 0.002 \n",
    "\n",
    "#### Action\n",
    "Add the FamilySize feature in our final modeling, and remove the raw data ['SibSp', 'Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_i2_fz_isAlone = train_i2_fz_noraw.copy()\n",
    "train_i2_fz_isAlone['IsAlone'] = train_i2_fz_isAlone['FamilySize'] == 1\n",
    "train_i2_fz_isAlone['IsAlone'] = train_i2_fz_isAlone['IsAlone'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8384009856063596\n"
     ]
    }
   ],
   "source": [
    "X_fz_ia, y_fz_ia = xysplit(train_i2_fz_isAlone)\n",
    "score (X_fz_ia, y_fz_ia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "Adding the IsAlone does not improve the result\n",
    "\n",
    "#### Action\n",
    "Not to add this new feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try Ticketlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticket_len (df):\n",
    "    #making sure we are not massing with the raw data\n",
    "    clean_data = df.copy()\n",
    "    #cat tickets by length\n",
    "    Ticket_len = clean_data.Ticket.apply(len)\n",
    "    stat_min_ti = 30\n",
    "    Ticket_len_ls = (Ticket_len.value_counts() < stat_min_ti)\n",
    "    Ticket_len = Ticket_len.apply(lambda x: '30' if Ticket_len_ls.loc[x] == True else x)\n",
    "    Ticket_len = Ticket_len.astype(str)\n",
    "    \n",
    "    \n",
    "    #do imputation on txt data\n",
    "    OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    imp_cols = OH_en.fit_transform(pd.DataFrame(Ticket_len))\n",
    "    imp_cols = pd.DataFrame(imp_cols)\n",
    "    #now we align the index and col names\n",
    "    imp_cols.index = Ticket_len.index\n",
    "    imp_cols.columns = OH_en.get_feature_names(['Ticket_len'])\n",
    "        \n",
    "\n",
    "    return imp_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ticket_len = ticket_len (train_i2)\n",
    "train_i2_tl = train_i2_base.copy()\n",
    "train_i2_tl = train_i2_tl.join(Ticket_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8440442841959339\n"
     ]
    }
   ],
   "source": [
    "X_fz_tl, y_fz_tl = xysplit(train_i2_tl)\n",
    "score (X_fz_tl, y_fz_tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "Engineering the Ticket_len feature improves the result by 0.02, base score: 0.8238130752429171 vs imporved score 0.8440442841959339.\n",
    "\n",
    "#### Action\n",
    "Add Ticket_len feature to the final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Techniques\n",
    "\n",
    "### Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Embarked Title  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500        S    Mr  \n",
       "1  female  38.0      1      0          PC 17599  71.2833        C   Mrs  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250        S  Miss  \n",
       "3  female  35.0      1      0            113803  53.1000        S   Mrs  \n",
       "4    male  35.0      0      0            373450   8.0500        S    Mr  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_i2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactions (df):\n",
    "    \n",
    "    PSE = df.Pclass.astype(str) + df.Sex + df.Embarked\n",
    "    \n",
    "    #do imputation on txt data\n",
    "    OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    imp_cols = OH_en.fit_transform(pd.DataFrame(PSE))\n",
    "    imp_cols = pd.DataFrame(imp_cols)\n",
    "    #now we align the index and col names\n",
    "    imp_cols.index = PSE.index\n",
    "    imp_cols.columns = OH_en.get_feature_names(['Pclass_Sex_Embarked'])\n",
    "    \n",
    "    return imp_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "pse = interactions(train_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8451555383438537\n"
     ]
    }
   ],
   "source": [
    "train_i2_pse = train_i2_base.copy()\n",
    "train_i2_pse = train_i2_tl.join(pse)\n",
    "X_pse, y_pse = xysplit(train_i2_pse)\n",
    "score (X_pse, y_pse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8507419177405954\n"
     ]
    }
   ],
   "source": [
    "train_i2_pse_noraw = train_i2_pse.drop(['Pclass', 'Sex_male','Sex_female','Embarked_C','Embarked_Q','Embarked_S'], axis=1)\n",
    "X_pse_nr, y_pse_nr = xysplit(train_i2_pse_noraw)\n",
    "score (X_pse_nr, y_pse_nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "We get a ~0.02 improvement on the score by engineering the Pclass_Sex_Embarked feature in our data, with the raw features removed\n",
    "\n",
    "#### Action\n",
    "include Pclass_Sex_Embarked in our final data set and remove the raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_eng_i2 (clean_data):\n",
    "    #let's start with num cols\n",
    "    #create value bins for continuouse values\n",
    "    clean_data['FareBin'] = pd.qcut(clean_data['Fare'], 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    clean_data['AgeBin'] = pd.cut(clean_data['Age'].astype(int), 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    #now we drop the original features\n",
    "    clean_data = clean_data.drop(['Fare', 'Age'], axis=1)\n",
    "    \n",
    "    #create new features\n",
    "    FamilySize = clean_data['SibSp']+clean_data['Parch']+1\n",
    "    clean_data['FamilySize'] = FamilySize\n",
    "    \n",
    "    #next we work on text data\n",
    "    #extrat title from Name\n",
    "    clean_data['Title'] = clean_data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    \n",
    "    stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "    title_names = (clean_data['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n",
    "    #apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n",
    "    clean_data['Title'] = clean_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "    \n",
    "    #cat tickets by length\n",
    "    Ticket_len = clean_data.Ticket.apply(len)\n",
    "    stat_min_ti = 30\n",
    "    Ticket_len_ls = (Ticket_len.value_counts() < stat_min_ti)\n",
    "    Ticket_len = Ticket_len.apply(lambda x: '30' if Ticket_len_ls.loc[x] == True else x)\n",
    "    Ticket_len.value_counts()\n",
    "    clean_data['Ticket_len'] = Ticket_len\n",
    "    #imputer only works on str or numbers\n",
    "    clean_data['Ticket_len'] = clean_data['Ticket_len'].astype(str)\n",
    "    clean_data = clean_data.drop(['Name', 'Ticket'], axis=1)\n",
    "    \n",
    "    #adding Pclass_Sex_Embarked\n",
    "    PSE = clean_data.Pclass.astype(str) + clean_data.Sex + clean_data.Embarked\n",
    "    clean_data['Pclass_Sex_Embarked'] = PSE\n",
    "    \n",
    "    \n",
    "    #do imputation on txt data\n",
    "    OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    imp_cols = OH_en.fit_transform(clean_data[['Title', 'Ticket_len', 'Pclass_Sex_Embarked']])\n",
    "    imp_cols = pd.DataFrame(imp_cols)\n",
    "    #now we align the index and col names\n",
    "    imp_cols.index = clean_data[['Sex','Embarked','Title', 'Ticket_len', 'Pclass_Sex_Embarked']].index\n",
    "    imp_cols.columns = OH_en.get_feature_names(['Title', 'Ticket_len', 'Pclass_Sex_Embarked'])\n",
    "    clean_data = clean_data.drop(['Sex','Embarked', 'Title', 'Ticket_len', 'SibSp', 'Parch', 'Pclass', 'Pclass_Sex_Embarked'], axis=1).join(imp_cols)\n",
    "\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_i2_af = f_eng_i2(train_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                    u'Survived',                      u'FareBin',\n",
       "                             u'AgeBin',                   u'FamilySize',\n",
       "                       u'Title_Master',                   u'Title_Misc',\n",
       "                         u'Title_Miss',                     u'Title_Mr',\n",
       "                          u'Title_Mrs',                u'Ticket_len_10',\n",
       "                      u'Ticket_len_30',                 u'Ticket_len_4',\n",
       "                       u'Ticket_len_5',                 u'Ticket_len_6',\n",
       "                       u'Ticket_len_8', u'Pclass_Sex_Embarked_1femaleC',\n",
       "       u'Pclass_Sex_Embarked_1femaleQ', u'Pclass_Sex_Embarked_1femaleS',\n",
       "         u'Pclass_Sex_Embarked_1maleC',   u'Pclass_Sex_Embarked_1maleQ',\n",
       "         u'Pclass_Sex_Embarked_1maleS', u'Pclass_Sex_Embarked_2femaleC',\n",
       "       u'Pclass_Sex_Embarked_2femaleQ', u'Pclass_Sex_Embarked_2femaleS',\n",
       "         u'Pclass_Sex_Embarked_2maleC',   u'Pclass_Sex_Embarked_2maleQ',\n",
       "         u'Pclass_Sex_Embarked_2maleS', u'Pclass_Sex_Embarked_3femaleC',\n",
       "       u'Pclass_Sex_Embarked_3femaleQ', u'Pclass_Sex_Embarked_3femaleS',\n",
       "         u'Pclass_Sex_Embarked_3maleC',   u'Pclass_Sex_Embarked_3maleQ',\n",
       "         u'Pclass_Sex_Embarked_3maleS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_i2_af.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8126716308714098\n"
     ]
    }
   ],
   "source": [
    "X_af, y_af = xysplit(train_i2_af)\n",
    "score (X_af, y_af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
