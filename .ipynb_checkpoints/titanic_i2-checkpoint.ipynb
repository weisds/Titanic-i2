{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Prediction - A Comprehensive Analysis and Experiment for the Kaggle Titanic Competition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "This kernel was created for the purpose of defining the best features and models for the Kaggle Titanic dataset that together yeilds the best prediction score. This kernel contains details around the analysis and experiment undertaken in the effort to derive the best feature and model set. In addition, the causation effect on the predition result of each engineered feature as an individual addition to the original feature set, various combinations derived from feature selection technique, and finally all together as a batch to the set.\n",
    "\n",
    "## Introduction \n",
    "We are attempting create a ML model that provides a binary result indicating rather or not a passenger on the Titanic will surive the well-known desaster. (review this with the description of the competition). This kernel contains the detail breakdown of the analysis and experiments attempted in the effort to achieve the highest percision. \n",
    "\n",
    "The steps taken are grouped into two major iterations: iteration 1 where we conducted the EDA, Feature Engineering and the attempts to build the most accurate model with the findings; iteration 2, sought to build upon the effort from iteration 1 by validating the causation effect of each engineered feature on the predition result to determine best feature set for training the model. In addition, we also attempted a couple new feature engineering technique in iteration 2, namely, interation and normalization.\n",
    "\n",
    "\n",
    "## Conclusions\n",
    "Revealed by our post-submission analysis, we see that Sex, Title and Pclass_Sex_Embarked are the top three features which have the most positive effect on the surival rate, and we don't see any strong trend on features that have a negative impact on the result. Conculding from our Permutation Importance analysis and Shap analysis, we can predict with a level of certainty that a female passenger where PClass is 1 and is onborading from Southampton will have a better chance of suriving the accident. \n",
    "\n",
    "\n",
    "### Modeling and Data Preperation\n",
    "From our Iteration 1 effort, we can conclude that blindly creating new features based on corrolations and dropping or keeping the raw features without knowing the subsequent impacts will let to results that are difficult to interpret hard to improve on.\n",
    "\n",
    "On the other hands, from Iteration 2, we noticed that results from baseline model evalution on features do not always hold true in the final modeling. Specifically, we see that measures that resulted in positive impact on the model accuracy based on our baseline model evaluation, when aggregated did not lead to a stacked improve as anticipated. Instead, we observed a much lower accuracy score when combining these measures. As a result, we propose that when doing future modeling, all features should be kept, and use feature selection technique to generate the best dataset, and we should test different feature combinations for optimal result.\n",
    "\n",
    "\n",
    "## Techniques Used\n",
    "### Data Cleaning\n",
    "- Fillna ()\n",
    "- Filling missing data from lookup tables\n",
    "### Feature Engineering\n",
    "- Data evaluation to determine subsequent feature engineering approaches\n",
    "    - Distribution\n",
    "    - Corrolation\n",
    "    - Text data patterns\n",
    "    - Categorical data\n",
    "    - Data clustering\n",
    "- OneHot Encoding\n",
    "- Interations\n",
    "- Normalization\n",
    "- Text Data Manipulation\n",
    "- Converting Continuous Data to Discrete Data\n",
    "- Productionization\n",
    "### Modeling\n",
    "- Cross Validation\n",
    "- Hyperparameter Tuning\n",
    "- Voting (Ensemble)\n",
    "- Grid Search\n",
    "- Feature Evaluation (base model evaluation)\n",
    "- Post Modeling Evaluation (Permutation Importance and Shap analysis)\n",
    "\n",
    "\n",
    "\n",
    "## Credits\n",
    "\n",
    "Many techniques and feature engineering approach are inspired and borrowed from the sources listed below\n",
    "- https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "- https://www.kaggle.com/kenjee/titanic-project-example\n",
    "- https://www.kaggle.com/learn/overview\n",
    "\n",
    "===============================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 1\n",
    "In this iteration of the experiment, we are going to do EDA to understand the data in the aspects of outliers, holes, size of the data, continuous to discrete data, categorical data, numeric data vs string data, skewed data, etc. Next, based on the findings we will clean the data, then apply feature engineering techniques to convert string to numeric values, engineer new features and impute categorical data to prepare for the modeling.\n",
    "\n",
    "In the modeling stage, we still attempt multiple models and compare the results, for scoring we will use cross_val to determine the accuracy of the resulting models. After we have a set of model candidates, we will also attempt the ensemble approach to create models using the top five models resulting for the model evaluation effort.\n",
    "\n",
    "Lastly, we will productionize our effort by creating functions to streamline the data cleaning, feature engineering, and modeling process.\n",
    "\n",
    "\n",
    "### Plan of Attack\n",
    "- Understand the data, size of the data (column/row), size of missing data, columns to drop\n",
    "- Data Cleaning\n",
    "    - data outliers\n",
    "    - correct the data\n",
    "    - fillna()\n",
    "- EDA, look at numarical and object(string) data seperatly, to determine\n",
    "    - normalization/scale the data\n",
    "    - determine potential feature engineering approaches\n",
    "- Feature Engineering according to the findings\n",
    "- Def function for data preprocessing\n",
    "- Run Models\n",
    "- Voting\n",
    "- Output the result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas version: 1.0.1\n",
      "matplotlib version: 3.1.3\n",
      "NumPy version: 1.18.1\n",
      "SciPy version: 1.4.1\n",
      "IPython version: 7.12.0\n",
      "scikit-learn version: 0.22.1\n",
      "seaborn version: 0.10.0\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# This block is from https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "#load packages\n",
    "import sys #access to system parameters https://docs.python.org/3/library/sys.html\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "import pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import matplotlib #collection of functions for scientific and publication-ready visualization\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np #foundational package for scientific computing\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "import scipy as sp #collection of functions for scientific computing and advance mathematics\n",
    "print(\"SciPy version: {}\". format(sp.__version__)) \n",
    "\n",
    "import IPython\n",
    "from IPython import display #pretty printing of dataframes in Jupyter notebook\n",
    "print(\"IPython version: {}\". format(IPython.__version__)) \n",
    "\n",
    "import sklearn #collection of machine learning algorithms\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "import seaborn as sns #collection of functions for data visualization\n",
    "print(\"seaborn version: {}\". format(sns.__version__))\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder #OneHot Encoder\n",
    "\n",
    "\n",
    "#misc libraries\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is from https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "\n",
    "#Common Model Algorithms\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "#from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "#Configure Visualization Defaults\n",
    "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
    "%matplotlib inline\n",
    "#mpl.style.use('ggplot')\n",
    "#sns.set_style('white')\n",
    "#pylab.rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train_raw = pd.read_csv('data/train.csv')\n",
    "test_raw = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the data\n",
    "\n",
    "In this stage, we take a bird's eye view of the data, to understand\n",
    "- size of the data\n",
    "- obvious errors, e.g. data outliers\n",
    "- holes in the data\n",
    "- the types of data we are dealing with, string, int, cat, date?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.info()\n",
    "train_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- This data consists of numeric, string (object), and the Ticket column contains a combination of string and numarical values\n",
    "- We have a total 12 columns\n",
    "- Age has some missing data, marjority of Cabin data are missing, two missing values in Embarked\n",
    "- judging from std, min and max, we can conclude that data in PassengerId are pretty evenly distributed\n",
    "\n",
    "#### Action Plan\n",
    "- Split the data by dtype (string vs numeric) for targeted actions\n",
    "- Need to handle missing data in Age, Cabin (drop, due to the large amount), and Embarked\n",
    "- Consider dropping PassengerId due to the lack of trend in the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "In this stage, we want to fill in the holes in the data to lay the foundation for later imputations and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let split the data for more targeted handling\n",
    "txt_cols = [cname for cname in train_raw.columns if train_raw[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "num_cols = [cname for cname in train_raw.columns if train_raw[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "txt_data = train_raw[txt_cols].copy()\n",
    "num_data = train_raw[num_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to make sure we didn't accidentally drop any cols\n",
    "txt_data.shape[1] + num_data.shape[1] == train_raw.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Cols\n",
    "Let's first look at num data to see what needs to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Age          714 non-null    float64\n",
      " 4   SibSp        891 non-null    int64  \n",
      " 5   Parch        891 non-null    int64  \n",
      " 6   Fare         891 non-null    float64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 48.9 KB\n"
     ]
    }
   ],
   "source": [
    "#now let us look at the numaric cols\n",
    "num_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.87%\n"
     ]
    }
   ],
   "source": [
    "age_missing_per = num_data.Age.isnull().sum()/len(num_data.Age)\n",
    "print(\"{:.2%}\".format(age_missing_per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "We have close to 20% of Age data that are missing from the dataset, let's think of a cleverer way to fill in the gaps\n",
    "#### Action Plan\n",
    "The idea is to find features that corrolate with Age, create a lookup table to impute missing Age values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e1c0ed3bc8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to find corrolating features\n",
    "sns.heatmap(train_raw.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-0-0    324\n",
       "1-0-0    109\n",
       "2-0-0    104\n",
       "1-1-0     51\n",
       "3-1-0     46\n",
       "2-1-0     26\n",
       "3-1-1     25\n",
       "2-1-1     20\n",
       "1-0-1     19\n",
       "1-1-1     12\n",
       "3-0-2     12\n",
       "3-0-1     11\n",
       "3-2-0     10\n",
       "1-0-2      9\n",
       "3-4-2      9\n",
       "3-4-1      9\n",
       "2-1-2      8\n",
       "2-0-2      8\n",
       "2-0-1      8\n",
       "3-3-1      7\n",
       "3-8-2      7\n",
       "1-1-2      7\n",
       "3-5-2      5\n",
       "3-1-2      4\n",
       "3-3-2      4\n",
       "2-2-1      4\n",
       "1-3-2      3\n",
       "3-2-1      3\n",
       "2-2-0      3\n",
       "1-2-0      3\n",
       "3-1-5      3\n",
       "3-0-5      2\n",
       "3-2-2      2\n",
       "1-2-2      2\n",
       "3-1-4      2\n",
       "3-1-3      2\n",
       "3-0-3      1\n",
       "2-2-3      1\n",
       "2-1-3      1\n",
       "3-1-6      1\n",
       "3-0-4      1\n",
       "1-1-4      1\n",
       "2-3-0      1\n",
       "3-3-0      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we see that Pclass, Sibsp, Parch are highly corrolated with Age\n",
    "Pclass_Sibsp_Parch = train_raw['Pclass'].apply(str)+'-'+train_raw['SibSp'].apply(str)+'-'+train_raw['Parch'].apply(str)\n",
    "Pclass_Sibsp_Parch.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "It is clear that majority of the data can categorized into 3-0-0, 1-0-0 and 2-0-0\n",
    "#### Action Plan\n",
    "Let's create a lookup table with 3-0-0, 1-0-0 and 2-0-0 as the three major classes, and put the rest into the 'other' bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = { 'Pclass_Sibsp_Parch': Pclass_Sibsp_Parch, 'Age': train_raw.Age } \n",
    "age_psp = pd.DataFrame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_classes = ['3-0-0', '1-0-0', '2-0-0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other    354\n",
       "3-0-0    324\n",
       "1-0-0    109\n",
       "2-0-0    104\n",
       "Name: Pclass_Sibsp_Parch, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we have the data in the right state to be converted to the desired lookup table\n",
    "age_psp['Pclass_Sibsp_Parch'] = age_psp['Pclass_Sibsp_Parch'].apply(lambda x: x if x in age_classes else 'other')\n",
    "age_psp['Pclass_Sibsp_Parch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the lookup table with Pclass_Sibsp_Parch as index\n",
    "age_lookup= age_psp.groupby(\"Pclass_Sibsp_Parch\", as_index=False).mean()\n",
    "age_lookup = age_lookup.set_index('Pclass_Sibsp_Parch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create temp columns in the df to impute missing Age values\n",
    "num_data['temp_psp'] = age_psp['Pclass_Sibsp_Parch']\n",
    "num_data['temp_age_cat_mean'] = num_data['temp_psp']\n",
    "num_data['temp_age_cat_mean'] = num_data['temp_age_cat_mean'].apply(lambda x: age_lookup['Age'][x])\n",
    "num_data['Age'] = num_data['Age'].fillna(num_data['temp_age_cat_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to see if there is still null values in the data\n",
    "num_data['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up after the imputation\n",
    "num_data = num_data.drop('temp_psp', axis=1)\n",
    "num_data = num_data.drop('temp_age_cat_mean', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at 'PassengerId' to decide if we should drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e1c13580c8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_data['PassengerId'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there is no observable trend the data, let's drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = num_data.drop('PassengerId', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name          0\n",
       "Sex           0\n",
       "Ticket        0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- large number of missing value in Cabin, let's drop it\n",
    "- only two missing value in Embarked, fill with most freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_data = txt_data.drop('Cabin', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_data['Embarked'] = txt_data['Embarked'].fillna(txt_data['Embarked'].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        0\n",
       "Sex         0\n",
       "Ticket      0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's def the data_cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean (df):\n",
    "    #create lookup table for Age\n",
    "    psp = df['Pclass'].apply(str)+'-'+df['SibSp'].apply(str)+'-'+df['Parch'].apply(str)\n",
    "    frame = { 'Pclass_Sibsp_Parch': psp, 'Age': df.Age } \n",
    "    psp_age = pd.DataFrame(frame)\n",
    "    #define age classes, other not yet included\n",
    "    age_classes = ['3-0-0', '1-0-0', '2-0-0']\n",
    "    #convert excluding items to 'other'\n",
    "    psp_age['Pclass_Sibsp_Parch'] = psp_age['Pclass_Sibsp_Parch'].apply(lambda x: x if x in age_classes else 'other')\n",
    "    #transform to a lookup table\n",
    "    am_lookup= psp_age.groupby('Pclass_Sibsp_Parch').mean()\n",
    "    #using the lookup table\n",
    "    df['temp_psp'] = psp_age['Pclass_Sibsp_Parch'] #setup a temp col with psp lables\n",
    "    df['temp_age_cat_mean'] = df['temp_psp'] #create a col for age means conversions\n",
    "    df['temp_age_cat_mean'] = df['temp_age_cat_mean'].apply(lambda x: am_lookup['Age'][x]) #convert values in this col to age means according to the psp lable\n",
    "    df['Age'] = df['Age'].fillna(df['temp_age_cat_mean']) #fill na according to the tempt mean col\n",
    "    #drop the temp cols\n",
    "    df = df.drop('temp_psp', axis=1)\n",
    "    df = df.drop('temp_age_cat_mean', axis=1)\n",
    "    \n",
    "    #found that there are missing valuse in Fare in the test dataset\n",
    "    df['Fare'] = df['Fare'].fillna(method='ffill')\n",
    "    \n",
    "    #for reasons stated above we don't want PassengerId, Cabin cols\n",
    "    df = df.drop('PassengerId', axis=1)\n",
    "    df = df.drop('Cabin', axis=1)\n",
    "    \n",
    "    #fill na for Embarked, only two \n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].value_counts().index[0])\n",
    "    \n",
    "    #do a final check\n",
    "    print(df.isnull().sum())\n",
    "    print(df.shape)\n",
    "\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "In this stage, we are going to:\n",
    "- convert string values to numeric values\n",
    "- use onehot encoder to imputer categorical data\n",
    "- create new features from exsiting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Data\n",
    "\n",
    "Let's look at the numeric data first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.715957</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.165460</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.235556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.715957    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   13.165460    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.235556    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   36.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "We have Age and Fare containing continouse valuse\n",
    "#### Action\n",
    "For classification problem, we hypothesize that discrete values will be better fit for the algorithms, let's proceed with the conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.413452</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass        Age  SibSp  Parch     Fare  FareBin  AgeBin\n",
       "0           0       3  22.000000      1      0   7.2500        1       2\n",
       "1           1       1  38.000000      1      0  71.2833        5       3\n",
       "2           1       3  26.000000      0      0   7.9250        2       2\n",
       "3           1       1  35.000000      1      0  53.1000        5       3\n",
       "4           0       3  35.000000      0      0   8.0500        2       3\n",
       "..        ...     ...        ...    ...    ...      ...      ...     ...\n",
       "886         0       2  27.000000      0      0  13.0000        3       2\n",
       "887         1       1  19.000000      0      0  30.0000        4       2\n",
       "888         0       3  26.413452      1      2  23.4500        4       2\n",
       "889         1       1  26.000000      0      0  30.0000        4       2\n",
       "890         0       3  32.000000      0      0   7.7500        1       2\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data['FareBin'] = pd.qcut(num_data['Fare'], 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "num_data['AgeBin'] = pd.cut(num_data['Age'].astype(int), 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.069834</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.049771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.379096</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>-0.408902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.069834</td>\n",
       "      <td>-0.379096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.255773</td>\n",
       "      <td>-0.188705</td>\n",
       "      <td>0.101817</td>\n",
       "      <td>0.129939</td>\n",
       "      <td>0.940683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.255773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>-0.238513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.188705</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>-0.154571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.101817</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600883</td>\n",
       "      <td>0.128427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FareBin</th>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>0.129939</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>0.600883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBin</th>\n",
       "      <td>-0.049771</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>0.940683</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.128427</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived    Pclass       Age     SibSp     Parch      Fare  \\\n",
       "Survived  1.000000 -0.338481 -0.069834 -0.035322  0.081629  0.257307   \n",
       "Pclass   -0.338481  1.000000 -0.379096  0.083081  0.018443 -0.549500   \n",
       "Age      -0.069834 -0.379096  1.000000 -0.255773 -0.188705  0.101817   \n",
       "SibSp    -0.035322  0.083081 -0.255773  1.000000  0.414838  0.159651   \n",
       "Parch     0.081629  0.018443 -0.188705  0.414838  1.000000  0.216225   \n",
       "Fare      0.257307 -0.549500  0.101817  0.159651  0.216225  1.000000   \n",
       "FareBin   0.317783 -0.705206  0.129939  0.354974  0.351317  0.600883   \n",
       "AgeBin   -0.049771 -0.408902  0.940683 -0.238513 -0.154571  0.128427   \n",
       "\n",
       "           FareBin    AgeBin  \n",
       "Survived  0.317783 -0.049771  \n",
       "Pclass   -0.705206 -0.408902  \n",
       "Age       0.129939  0.940683  \n",
       "SibSp     0.354974 -0.238513  \n",
       "Parch     0.351317 -0.154571  \n",
       "Fare      0.600883  0.128427  \n",
       "FareBin   1.000000  0.148150  \n",
       "AgeBin    0.148150  1.000000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at if the new features are actually useful\n",
    "num_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "We see that FareBin has a better corrolation with Survived, whereas AgeBin has a lower correlation coefficient than raw Age with Survived\n",
    "\n",
    "#### Action Plan\n",
    "- We will keep FareBin drop Fare\n",
    "- For Age vs Agebin, since the difference is small, and both Age and AgeBin are not tightly corrolated with Survived, for the sake of consistency we will keep AgeBin and drop Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we drop the original features\n",
    "num_data = num_data.drop(['Fare', 'Age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  SibSp  Parch  FareBin  AgeBin\n",
       "0           0       3      1      0        1       2\n",
       "1           1       1      1      0        5       3\n",
       "2           1       3      0      0        2       2\n",
       "3           1       1      1      0        5       3\n",
       "4           0       3      0      0        2       3\n",
       "..        ...     ...    ...    ...      ...     ...\n",
       "886         0       2      0      0        3       2\n",
       "887         1       1      0      0        4       2\n",
       "888         0       3      1      2        4       2\n",
       "889         1       1      0      0        4       2\n",
       "890         0       3      0      0        1       2\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IsAlone and FamilySize\n",
    "Inspired by the approach taken in the follow Kaggle notebooks, we would like to engineer two new features, IsAlone and FamilySize\n",
    "- [https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy](https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy)\n",
    "- https://www.notion.so/Titanic-Data-Science-Solutions-Kaggle-a5a4aa2d5e024be88263390a26db3c6d#81f0bc93036e4f4ab87c1ac22e2d0e2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "FamilySize = num_data['SibSp']+num_data['Parch']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsAlone = FamilySize>1\n",
    "IsAlone = IsAlone.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.049771</td>\n",
       "      <td>0.203367</td>\n",
       "      <td>0.016639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>-0.135207</td>\n",
       "      <td>0.065997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>0.584471</td>\n",
       "      <td>0.890712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.583398</td>\n",
       "      <td>0.783111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FareBin</th>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>0.418125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBin</th>\n",
       "      <td>-0.049771</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161040</td>\n",
       "      <td>-0.240237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsAlone</th>\n",
       "      <td>0.203367</td>\n",
       "      <td>-0.135207</td>\n",
       "      <td>0.584471</td>\n",
       "      <td>0.583398</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>-0.161040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FamilySize</th>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>0.890712</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>0.418125</td>\n",
       "      <td>-0.240237</td>\n",
       "      <td>0.690922</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Survived    Pclass     SibSp     Parch   FareBin    AgeBin  \\\n",
       "Survived    1.000000 -0.338481 -0.035322  0.081629  0.317783 -0.049771   \n",
       "Pclass     -0.338481  1.000000  0.083081  0.018443 -0.705206 -0.408902   \n",
       "SibSp      -0.035322  0.083081  1.000000  0.414838  0.354974 -0.238513   \n",
       "Parch       0.081629  0.018443  0.414838  1.000000  0.351317 -0.154571   \n",
       "FareBin     0.317783 -0.705206  0.354974  0.351317  1.000000  0.148150   \n",
       "AgeBin     -0.049771 -0.408902 -0.238513 -0.154571  0.148150  1.000000   \n",
       "IsAlone     0.203367 -0.135207  0.584471  0.583398  0.520277 -0.161040   \n",
       "FamilySize  0.016639  0.065997  0.890712  0.783111  0.418125 -0.240237   \n",
       "\n",
       "             IsAlone  FamilySize  \n",
       "Survived    0.203367    0.016639  \n",
       "Pclass     -0.135207    0.065997  \n",
       "SibSp       0.584471    0.890712  \n",
       "Parch       0.583398    0.783111  \n",
       "FareBin     0.520277    0.418125  \n",
       "AgeBin     -0.161040   -0.240237  \n",
       "IsAlone     1.000000    0.690922  \n",
       "FamilySize  0.690922    1.000000  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data['IsAlone'] = IsAlone\n",
    "num_data['FamilySize'] = FamilySize\n",
    "num_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IsAlone has a pretty good corrolation with the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data\n",
    "\n",
    "Next, we look at text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>113803</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>373450</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>211536</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>112053</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>111369</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>370376</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name     Sex  \\\n",
       "0                              Braund, Mr. Owen Harris    male   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female   \n",
       "2                               Heikkinen, Miss. Laina  female   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   \n",
       "4                             Allen, Mr. William Henry    male   \n",
       "..                                                 ...     ...   \n",
       "886                              Montvila, Rev. Juozas    male   \n",
       "887                       Graham, Miss. Margaret Edith  female   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   \n",
       "889                              Behr, Mr. Karl Howell    male   \n",
       "890                                Dooley, Mr. Patrick    male   \n",
       "\n",
       "               Ticket Embarked  \n",
       "0           A/5 21171        S  \n",
       "1            PC 17599        C  \n",
       "2    STON/O2. 3101282        S  \n",
       "3              113803        S  \n",
       "4              373450        S  \n",
       "..                ...      ...  \n",
       "886            211536        S  \n",
       "887            112053        S  \n",
       "888        W./C. 6607        S  \n",
       "889            111369        C  \n",
       "890            370376        Q  \n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "- Sex and Embarked are ready for labling\n",
    "- Need to work on Name and Ticket\n",
    "\n",
    "#### Action\n",
    "- Analyze Name and Ticket\n",
    "- Impute Sex and Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze and transform the Name column \n",
    "\n",
    "Sepcifically, we want to look at the data to see if there was any observable trend, potential clustering, or possible extraction of common elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "Name values are pretty uniformly formatted\n",
    "\n",
    "#### Action Plan\n",
    "We could use simple split() to extract titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              517\n",
       "Miss            182\n",
       "Mrs             125\n",
       "Master           40\n",
       "Dr                7\n",
       "Rev               6\n",
       "Col               2\n",
       "Major             2\n",
       "Mlle              2\n",
       "Lady              1\n",
       "Mme               1\n",
       "Sir               1\n",
       "Capt              1\n",
       "Jonkheer          1\n",
       "Ms                1\n",
       "Don               1\n",
       "the Countess      1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#borrowed from https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy notebook\n",
    "#quick and dirty code split title from name: http://www.pythonforbeginners.com/dictionary/python-split\n",
    "txt_data['Title'] = txt_data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "\n",
    "txt_data.Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr        517\n",
      "Miss      182\n",
      "Mrs       125\n",
      "Master     40\n",
      "Misc       27\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "title_names = (txt_data['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n",
    "\n",
    "#apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n",
    "txt_data['Title'] = txt_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "print(txt_data['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze and transform the Ticket column \n",
    "\n",
    "#### Observation\n",
    "No obvious observable patterns in the data\n",
    "\n",
    "#### Action Plan\n",
    "Look at value len to see if we could extract some patterns out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ticket_len = txt_data.Ticket.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     419\n",
       "5     131\n",
       "4     101\n",
       "8      76\n",
       "10     41\n",
       "7      27\n",
       "9      26\n",
       "17     14\n",
       "16     11\n",
       "13     10\n",
       "12     10\n",
       "15      9\n",
       "11      8\n",
       "18      6\n",
       "3       2\n",
       "Name: Ticket, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ticket_len.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much more workable than the raw data, let's apply the same cat approach we did for Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     419\n",
       "5     131\n",
       "30    123\n",
       "4     101\n",
       "8      76\n",
       "10     41\n",
       "Name: Ticket, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_min_ti = 30\n",
    "Ticket_len_ls = (Ticket_len.value_counts() < stat_min_ti)\n",
    "Ticket_len = Ticket_len.apply(lambda x: '30' if Ticket_len_ls.loc[x] == True else x)\n",
    "Ticket_len.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_data['Ticket_len'] = Ticket_len\n",
    "txt_data = txt_data.drop(['Name', 'Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Ticket_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Misc</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "      <td>Mr</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>male</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex Embarked Title Ticket_len\n",
       "0      male        S    Mr         30\n",
       "1    female        C   Mrs          8\n",
       "2    female        S  Miss         30\n",
       "3    female        S   Mrs          6\n",
       "4      male        S    Mr          6\n",
       "..      ...      ...   ...        ...\n",
       "886    male        S  Misc          6\n",
       "887  female        S  Miss          6\n",
       "888  female        S  Miss         10\n",
       "889    male        C    Mr          6\n",
       "890    male        Q    Mr          6\n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputer only works on str or numbers\n",
    "txt_data['Ticket_len'] = txt_data['Ticket_len'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we perform data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "imp_txt_cols = OH_en.fit_transform(txt_data[['Sex','Embarked', 'Title', 'Ticket_len']])\n",
    "imp_txt_cols = pd.DataFrame(imp_txt_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <th>Ticket_len_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  \\\n",
       "0           0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "1           1.0       0.0         1.0         0.0         0.0           0.0   \n",
       "2           1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "3           1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "4           0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "..          ...       ...         ...         ...         ...           ...   \n",
       "886         0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "887         1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "888         1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "889         0.0       1.0         1.0         0.0         0.0           0.0   \n",
       "890         0.0       1.0         0.0         1.0         0.0           0.0   \n",
       "\n",
       "     Title_Misc  Title_Miss  Title_Mr  Title_Mrs  Ticket_len_10  \\\n",
       "0           0.0         0.0       1.0        0.0            0.0   \n",
       "1           0.0         0.0       0.0        1.0            0.0   \n",
       "2           0.0         1.0       0.0        0.0            0.0   \n",
       "3           0.0         0.0       0.0        1.0            0.0   \n",
       "4           0.0         0.0       1.0        0.0            0.0   \n",
       "..          ...         ...       ...        ...            ...   \n",
       "886         1.0         0.0       0.0        0.0            0.0   \n",
       "887         0.0         1.0       0.0        0.0            0.0   \n",
       "888         0.0         1.0       0.0        0.0            1.0   \n",
       "889         0.0         0.0       1.0        0.0            0.0   \n",
       "890         0.0         0.0       1.0        0.0            0.0   \n",
       "\n",
       "     Ticket_len_30  Ticket_len_4  Ticket_len_5  Ticket_len_6  Ticket_len_8  \n",
       "0              1.0           0.0           0.0           0.0           0.0  \n",
       "1              0.0           0.0           0.0           0.0           1.0  \n",
       "2              1.0           0.0           0.0           0.0           0.0  \n",
       "3              0.0           0.0           0.0           1.0           0.0  \n",
       "4              0.0           0.0           0.0           1.0           0.0  \n",
       "..             ...           ...           ...           ...           ...  \n",
       "886            0.0           0.0           0.0           1.0           0.0  \n",
       "887            0.0           0.0           0.0           1.0           0.0  \n",
       "888            0.0           0.0           0.0           0.0           0.0  \n",
       "889            0.0           0.0           0.0           1.0           0.0  \n",
       "890            0.0           0.0           0.0           1.0           0.0  \n",
       "\n",
       "[891 rows x 16 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we align the index and col names\n",
    "imp_txt_cols.index = txt_data[['Sex','Embarked', 'Title', 'Ticket_len']].index\n",
    "imp_txt_cols.columns = OH_en.get_feature_names(['Sex','Embarked', 'Title', 'Ticket_len'])\n",
    "imp_txt_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <th>Ticket_len_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  \\\n",
       "0           0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "1           1.0       0.0         1.0         0.0         0.0           0.0   \n",
       "2           1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "3           1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "4           0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "..          ...       ...         ...         ...         ...           ...   \n",
       "886         0.0       1.0         0.0         0.0         1.0           0.0   \n",
       "887         1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "888         1.0       0.0         0.0         0.0         1.0           0.0   \n",
       "889         0.0       1.0         1.0         0.0         0.0           0.0   \n",
       "890         0.0       1.0         0.0         1.0         0.0           0.0   \n",
       "\n",
       "     Title_Misc  Title_Miss  Title_Mr  Title_Mrs  Ticket_len_10  \\\n",
       "0           0.0         0.0       1.0        0.0            0.0   \n",
       "1           0.0         0.0       0.0        1.0            0.0   \n",
       "2           0.0         1.0       0.0        0.0            0.0   \n",
       "3           0.0         0.0       0.0        1.0            0.0   \n",
       "4           0.0         0.0       1.0        0.0            0.0   \n",
       "..          ...         ...       ...        ...            ...   \n",
       "886         1.0         0.0       0.0        0.0            0.0   \n",
       "887         0.0         1.0       0.0        0.0            0.0   \n",
       "888         0.0         1.0       0.0        0.0            1.0   \n",
       "889         0.0         0.0       1.0        0.0            0.0   \n",
       "890         0.0         0.0       1.0        0.0            0.0   \n",
       "\n",
       "     Ticket_len_30  Ticket_len_4  Ticket_len_5  Ticket_len_6  Ticket_len_8  \n",
       "0              1.0           0.0           0.0           0.0           0.0  \n",
       "1              0.0           0.0           0.0           0.0           1.0  \n",
       "2              1.0           0.0           0.0           0.0           0.0  \n",
       "3              0.0           0.0           0.0           1.0           0.0  \n",
       "4              0.0           0.0           0.0           1.0           0.0  \n",
       "..             ...           ...           ...           ...           ...  \n",
       "886            0.0           0.0           0.0           1.0           0.0  \n",
       "887            0.0           0.0           0.0           1.0           0.0  \n",
       "888            0.0           0.0           0.0           0.0           0.0  \n",
       "889            0.0           0.0           0.0           1.0           0.0  \n",
       "890            0.0           0.0           0.0           1.0           0.0  \n",
       "\n",
       "[891 rows x 16 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we complete the txt df with the imputed cols\n",
    "txt_data = txt_data.drop(['Sex','Embarked', 'Title', 'Ticket_len'], axis=1).join(imp_txt_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <th>Ticket_len_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex_female</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.119224</td>\n",
       "      <td>-0.159934</td>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.686808</td>\n",
       "      <td>-0.867334</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.084090</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>0.091776</td>\n",
       "      <td>-0.045475</td>\n",
       "      <td>0.052287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_male</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.082853</td>\n",
       "      <td>-0.074115</td>\n",
       "      <td>0.119224</td>\n",
       "      <td>0.159934</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>-0.686808</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>-0.547600</td>\n",
       "      <td>-0.006179</td>\n",
       "      <td>0.084090</td>\n",
       "      <td>-0.010421</td>\n",
       "      <td>-0.091776</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>-0.052287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>0.082853</td>\n",
       "      <td>-0.082853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>-0.782742</td>\n",
       "      <td>-0.035225</td>\n",
       "      <td>0.065432</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>-0.072567</td>\n",
       "      <td>0.061395</td>\n",
       "      <td>-0.105869</td>\n",
       "      <td>-0.068141</td>\n",
       "      <td>0.361630</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>-0.339198</td>\n",
       "      <td>0.325325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.074115</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.499421</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>-0.007767</td>\n",
       "      <td>0.171117</td>\n",
       "      <td>-0.078338</td>\n",
       "      <td>-0.089739</td>\n",
       "      <td>-0.048484</td>\n",
       "      <td>-0.123085</td>\n",
       "      <td>-0.097372</td>\n",
       "      <td>0.018938</td>\n",
       "      <td>0.206393</td>\n",
       "      <td>-0.093921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>-0.119224</td>\n",
       "      <td>0.119224</td>\n",
       "      <td>-0.782742</td>\n",
       "      <td>-0.499421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024264</td>\n",
       "      <td>-0.052433</td>\n",
       "      <td>-0.130650</td>\n",
       "      <td>0.112870</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.123257</td>\n",
       "      <td>0.137152</td>\n",
       "      <td>-0.255526</td>\n",
       "      <td>-0.035339</td>\n",
       "      <td>0.167268</td>\n",
       "      <td>-0.225893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Master</th>\n",
       "      <td>-0.159934</td>\n",
       "      <td>0.159934</td>\n",
       "      <td>-0.035225</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.024264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.038326</td>\n",
       "      <td>-0.109844</td>\n",
       "      <td>-0.254903</td>\n",
       "      <td>-0.087580</td>\n",
       "      <td>0.029992</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>-0.044095</td>\n",
       "      <td>0.012919</td>\n",
       "      <td>-0.046801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Misc</th>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>0.065432</td>\n",
       "      <td>-0.007767</td>\n",
       "      <td>-0.052433</td>\n",
       "      <td>-0.038326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.089565</td>\n",
       "      <td>-0.207843</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>-0.038825</td>\n",
       "      <td>-0.032784</td>\n",
       "      <td>-0.063208</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>0.086656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Miss</th>\n",
       "      <td>0.686808</td>\n",
       "      <td>-0.686808</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>0.171117</td>\n",
       "      <td>-0.130650</td>\n",
       "      <td>-0.109844</td>\n",
       "      <td>-0.089565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.595692</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.057497</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>0.024675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mr</th>\n",
       "      <td>-0.867334</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>-0.072567</td>\n",
       "      <td>-0.078338</td>\n",
       "      <td>0.112870</td>\n",
       "      <td>-0.254903</td>\n",
       "      <td>-0.207843</td>\n",
       "      <td>-0.595692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.474952</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.083562</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>-0.041512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mrs</th>\n",
       "      <td>0.547600</td>\n",
       "      <td>-0.547600</td>\n",
       "      <td>0.061395</td>\n",
       "      <td>-0.089739</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>-0.087580</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>-0.474952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>-0.039872</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>-0.043914</td>\n",
       "      <td>0.015478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.006179</td>\n",
       "      <td>-0.105869</td>\n",
       "      <td>-0.048484</td>\n",
       "      <td>0.123257</td>\n",
       "      <td>0.029992</td>\n",
       "      <td>-0.038825</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087893</td>\n",
       "      <td>-0.078529</td>\n",
       "      <td>-0.091182</td>\n",
       "      <td>-0.206928</td>\n",
       "      <td>-0.067067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <td>-0.084090</td>\n",
       "      <td>0.084090</td>\n",
       "      <td>-0.068141</td>\n",
       "      <td>-0.123085</td>\n",
       "      <td>0.137152</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>-0.032784</td>\n",
       "      <td>-0.057497</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>-0.039872</td>\n",
       "      <td>-0.087893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.143093</td>\n",
       "      <td>-0.166150</td>\n",
       "      <td>-0.377058</td>\n",
       "      <td>-0.122208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <td>0.010421</td>\n",
       "      <td>-0.010421</td>\n",
       "      <td>0.361630</td>\n",
       "      <td>-0.097372</td>\n",
       "      <td>-0.255526</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>-0.063208</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>-0.078529</td>\n",
       "      <td>-0.143093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148449</td>\n",
       "      <td>-0.336886</td>\n",
       "      <td>-0.109188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <td>0.091776</td>\n",
       "      <td>-0.091776</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.018938</td>\n",
       "      <td>-0.035339</td>\n",
       "      <td>-0.044095</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>-0.083562</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>-0.091182</td>\n",
       "      <td>-0.166150</td>\n",
       "      <td>-0.148449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.391169</td>\n",
       "      <td>-0.126782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <td>-0.045475</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>-0.339198</td>\n",
       "      <td>0.206393</td>\n",
       "      <td>0.167268</td>\n",
       "      <td>0.012919</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>-0.043914</td>\n",
       "      <td>-0.206928</td>\n",
       "      <td>-0.377058</td>\n",
       "      <td>-0.336886</td>\n",
       "      <td>-0.391169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.287716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_8</th>\n",
       "      <td>0.052287</td>\n",
       "      <td>-0.052287</td>\n",
       "      <td>0.325325</td>\n",
       "      <td>-0.093921</td>\n",
       "      <td>-0.225893</td>\n",
       "      <td>-0.046801</td>\n",
       "      <td>0.086656</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>-0.041512</td>\n",
       "      <td>0.015478</td>\n",
       "      <td>-0.067067</td>\n",
       "      <td>-0.122208</td>\n",
       "      <td>-0.109188</td>\n",
       "      <td>-0.126782</td>\n",
       "      <td>-0.287716</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \\\n",
       "Sex_female       1.000000 -1.000000    0.082853    0.074115   -0.119224   \n",
       "Sex_male        -1.000000  1.000000   -0.082853   -0.074115    0.119224   \n",
       "Embarked_C       0.082853 -0.082853    1.000000   -0.148258   -0.782742   \n",
       "Embarked_Q       0.074115 -0.074115   -0.148258    1.000000   -0.499421   \n",
       "Embarked_S      -0.119224  0.119224   -0.782742   -0.499421    1.000000   \n",
       "Title_Master    -0.159934  0.159934   -0.035225    0.010478    0.024264   \n",
       "Title_Misc      -0.034471  0.034471    0.065432   -0.007767   -0.052433   \n",
       "Title_Miss       0.686808 -0.686808    0.026215    0.171117   -0.130650   \n",
       "Title_Mr        -0.867334  0.867334   -0.072567   -0.078338    0.112870   \n",
       "Title_Mrs        0.547600 -0.547600    0.061395   -0.089739    0.002689   \n",
       "Ticket_len_10    0.006179 -0.006179   -0.105869   -0.048484    0.123257   \n",
       "Ticket_len_30   -0.084090  0.084090   -0.068141   -0.123085    0.137152   \n",
       "Ticket_len_4     0.010421 -0.010421    0.361630   -0.097372   -0.255526   \n",
       "Ticket_len_5     0.091776 -0.091776    0.026735    0.018938   -0.035339   \n",
       "Ticket_len_6    -0.045475  0.045475   -0.339198    0.206393    0.167268   \n",
       "Ticket_len_8     0.052287 -0.052287    0.325325   -0.093921   -0.225893   \n",
       "\n",
       "               Title_Master  Title_Misc  Title_Miss  Title_Mr  Title_Mrs  \\\n",
       "Sex_female        -0.159934   -0.034471    0.686808 -0.867334   0.547600   \n",
       "Sex_male           0.159934    0.034471   -0.686808  0.867334  -0.547600   \n",
       "Embarked_C        -0.035225    0.065432    0.026215 -0.072567   0.061395   \n",
       "Embarked_Q         0.010478   -0.007767    0.171117 -0.078338  -0.089739   \n",
       "Embarked_S         0.024264   -0.052433   -0.130650  0.112870   0.002689   \n",
       "Title_Master       1.000000   -0.038326   -0.109844 -0.254903  -0.087580   \n",
       "Title_Misc        -0.038326    1.000000   -0.089565 -0.207843  -0.071411   \n",
       "Title_Miss        -0.109844   -0.089565    1.000000 -0.595692  -0.204670   \n",
       "Title_Mr          -0.254903   -0.207843   -0.595692  1.000000  -0.474952   \n",
       "Title_Mrs         -0.087580   -0.071411   -0.204670 -0.474952   1.000000   \n",
       "Ticket_len_10      0.029992   -0.038825   -0.004981 -0.008576   0.019250   \n",
       "Ticket_len_30      0.038938   -0.032784   -0.057497  0.070078  -0.039872   \n",
       "Ticket_len_4       0.007963   -0.063208    0.020804  0.002834  -0.001728   \n",
       "Ticket_len_5      -0.044095    0.056025    0.033341 -0.083562   0.078680   \n",
       "Ticket_len_6       0.012919   -0.009143   -0.008851  0.035888  -0.043914   \n",
       "Ticket_len_8      -0.046801    0.086656    0.024675 -0.041512   0.015478   \n",
       "\n",
       "               Ticket_len_10  Ticket_len_30  Ticket_len_4  Ticket_len_5  \\\n",
       "Sex_female          0.006179      -0.084090      0.010421      0.091776   \n",
       "Sex_male           -0.006179       0.084090     -0.010421     -0.091776   \n",
       "Embarked_C         -0.105869      -0.068141      0.361630      0.026735   \n",
       "Embarked_Q         -0.048484      -0.123085     -0.097372      0.018938   \n",
       "Embarked_S          0.123257       0.137152     -0.255526     -0.035339   \n",
       "Title_Master        0.029992       0.038938      0.007963     -0.044095   \n",
       "Title_Misc         -0.038825      -0.032784     -0.063208      0.056025   \n",
       "Title_Miss         -0.004981      -0.057497      0.020804      0.033341   \n",
       "Title_Mr           -0.008576       0.070078      0.002834     -0.083562   \n",
       "Title_Mrs           0.019250      -0.039872     -0.001728      0.078680   \n",
       "Ticket_len_10       1.000000      -0.087893     -0.078529     -0.091182   \n",
       "Ticket_len_30      -0.087893       1.000000     -0.143093     -0.166150   \n",
       "Ticket_len_4       -0.078529      -0.143093      1.000000     -0.148449   \n",
       "Ticket_len_5       -0.091182      -0.166150     -0.148449      1.000000   \n",
       "Ticket_len_6       -0.206928      -0.377058     -0.336886     -0.391169   \n",
       "Ticket_len_8       -0.067067      -0.122208     -0.109188     -0.126782   \n",
       "\n",
       "               Ticket_len_6  Ticket_len_8  \n",
       "Sex_female        -0.045475      0.052287  \n",
       "Sex_male           0.045475     -0.052287  \n",
       "Embarked_C        -0.339198      0.325325  \n",
       "Embarked_Q         0.206393     -0.093921  \n",
       "Embarked_S         0.167268     -0.225893  \n",
       "Title_Master       0.012919     -0.046801  \n",
       "Title_Misc        -0.009143      0.086656  \n",
       "Title_Miss        -0.008851      0.024675  \n",
       "Title_Mr           0.035888     -0.041512  \n",
       "Title_Mrs         -0.043914      0.015478  \n",
       "Ticket_len_10     -0.206928     -0.067067  \n",
       "Ticket_len_30     -0.377058     -0.122208  \n",
       "Ticket_len_4      -0.336886     -0.109188  \n",
       "Ticket_len_5      -0.391169     -0.126782  \n",
       "Ticket_len_6       1.000000     -0.287716  \n",
       "Ticket_len_8      -0.287716      1.000000  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converge to a function\n",
    "Next, let's converge what we have just done to a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_eng (clean_data):\n",
    "    #let's start with num cols\n",
    "    #create value bins for continuouse values\n",
    "    clean_data['FareBin'] = pd.qcut(clean_data['Fare'], 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    clean_data['AgeBin'] = pd.cut(clean_data['Age'].astype(int), 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    #now we drop the original features\n",
    "    clean_data = clean_data.drop(['Fare', 'Age'], axis=1)\n",
    "    \n",
    "    #create new features\n",
    "    FamilySize = clean_data['SibSp']+clean_data['Parch']+1\n",
    "    IsAlone = FamilySize>1\n",
    "    IsAlone = IsAlone.apply(int)\n",
    "    clean_data['IsAlone'] = IsAlone\n",
    "    clean_data['FamilySize'] = FamilySize\n",
    "    \n",
    "    #next we work on text data\n",
    "    #extrat title from Name\n",
    "    clean_data['Title'] = clean_data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    \n",
    "    stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "    title_names = (clean_data['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n",
    "    #apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n",
    "    clean_data['Title'] = clean_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "    \n",
    "    #cat tickets by length\n",
    "    Ticket_len = clean_data.Ticket.apply(len)\n",
    "    stat_min_ti = 30\n",
    "    Ticket_len_ls = (Ticket_len.value_counts() < stat_min_ti)\n",
    "    Ticket_len = Ticket_len.apply(lambda x: '30' if Ticket_len_ls.loc[x] == True else x)\n",
    "    Ticket_len.value_counts()\n",
    "    clean_data['Ticket_len'] = Ticket_len\n",
    "    #imputer only works on str or numbers\n",
    "    clean_data['Ticket_len'] = clean_data['Ticket_len'].astype(str)\n",
    "    clean_data = clean_data.drop(['Name', 'Ticket'], axis=1)\n",
    "    \n",
    "    #do imputation on txt data\n",
    "    OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    imp_cols = OH_en.fit_transform(clean_data[['Sex','Embarked', 'Title', 'Ticket_len']])\n",
    "    imp_cols = pd.DataFrame(imp_cols)\n",
    "    #now we align the index and col names\n",
    "    imp_cols.index = clean_data[['Sex','Embarked', 'Title', 'Ticket_len']].index\n",
    "    imp_cols.columns = OH_en.get_feature_names(['Sex','Embarked', 'Title', 'Ticket_len'])\n",
    "    clean_data = clean_data.drop(['Sex','Embarked', 'Title', 'Ticket_len'], axis=1).join(imp_cols)\n",
    "\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our functions\n",
    "\n",
    "Testing our data cleaning and feature engineering functions for combining into a single wrapping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Ticket      0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "(891, 10)\n",
      "   Survived  Pclass                                               Name  \\\n",
      "0         0       3                            Braund, Mr. Owen Harris   \n",
      "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "2         1       3                             Heikkinen, Miss. Laina   \n",
      "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "4         0       3                           Allen, Mr. William Henry   \n",
      "\n",
      "      Sex   Age  SibSp  Parch            Ticket     Fare Embarked  \n",
      "0    male  22.0      1      0         A/5 21171   7.2500        S  \n",
      "1  female  38.0      1      0          PC 17599  71.2833        C  \n",
      "2  female  26.0      0      0  STON/O2. 3101282   7.9250        S  \n",
      "3  female  35.0      1      0            113803  53.1000        S  \n",
      "4    male  35.0      0      0            373450   8.0500        S  \n"
     ]
    }
   ],
   "source": [
    "test_data = train_raw.copy()\n",
    "test_clean = data_clean(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = f_eng(test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <th>Ticket_len_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.049771</td>\n",
       "      <td>0.203367</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.543351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022030</td>\n",
       "      <td>0.327093</td>\n",
       "      <td>-0.549199</td>\n",
       "      <td>0.339040</td>\n",
       "      <td>-0.019137</td>\n",
       "      <td>-0.081703</td>\n",
       "      <td>-0.012868</td>\n",
       "      <td>0.200178</td>\n",
       "      <td>-0.124049</td>\n",
       "      <td>0.097727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>-0.135207</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206333</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>0.142698</td>\n",
       "      <td>-0.149209</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>0.155894</td>\n",
       "      <td>0.270416</td>\n",
       "      <td>-0.377124</td>\n",
       "      <td>0.157908</td>\n",
       "      <td>-0.324370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>0.584471</td>\n",
       "      <td>0.890712</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036364</td>\n",
       "      <td>0.087932</td>\n",
       "      <td>-0.250489</td>\n",
       "      <td>0.063407</td>\n",
       "      <td>-0.011875</td>\n",
       "      <td>0.084638</td>\n",
       "      <td>-0.031555</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>-0.112502</td>\n",
       "      <td>0.132163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.583398</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067480</td>\n",
       "      <td>0.105567</td>\n",
       "      <td>-0.333905</td>\n",
       "      <td>0.225852</td>\n",
       "      <td>0.082150</td>\n",
       "      <td>0.028529</td>\n",
       "      <td>-0.041927</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>-0.033182</td>\n",
       "      <td>0.004982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FareBin</th>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.705206</td>\n",
       "      <td>0.354974</td>\n",
       "      <td>0.351317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>0.418125</td>\n",
       "      <td>0.244943</td>\n",
       "      <td>-0.244943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112454</td>\n",
       "      <td>0.059106</td>\n",
       "      <td>-0.312117</td>\n",
       "      <td>0.245302</td>\n",
       "      <td>-0.024758</td>\n",
       "      <td>-0.079605</td>\n",
       "      <td>-0.162293</td>\n",
       "      <td>0.263112</td>\n",
       "      <td>-0.194354</td>\n",
       "      <td>0.314787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBin</th>\n",
       "      <td>-0.049771</td>\n",
       "      <td>-0.408902</td>\n",
       "      <td>-0.238513</td>\n",
       "      <td>-0.154571</td>\n",
       "      <td>0.148150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161040</td>\n",
       "      <td>-0.240237</td>\n",
       "      <td>-0.093198</td>\n",
       "      <td>0.093198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176985</td>\n",
       "      <td>-0.242363</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.146407</td>\n",
       "      <td>-0.035189</td>\n",
       "      <td>-0.072051</td>\n",
       "      <td>-0.142312</td>\n",
       "      <td>0.182356</td>\n",
       "      <td>-0.062603</td>\n",
       "      <td>0.157564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsAlone</th>\n",
       "      <td>0.203367</td>\n",
       "      <td>-0.135207</td>\n",
       "      <td>0.584471</td>\n",
       "      <td>0.583398</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>-0.161040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690922</td>\n",
       "      <td>0.303646</td>\n",
       "      <td>-0.303646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>0.055127</td>\n",
       "      <td>-0.396920</td>\n",
       "      <td>0.365454</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>-0.000926</td>\n",
       "      <td>0.122750</td>\n",
       "      <td>-0.130834</td>\n",
       "      <td>0.031241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FamilySize</th>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>0.890712</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>0.418125</td>\n",
       "      <td>-0.240237</td>\n",
       "      <td>0.690922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200988</td>\n",
       "      <td>-0.200988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058565</td>\n",
       "      <td>0.112838</td>\n",
       "      <td>-0.338014</td>\n",
       "      <td>0.156168</td>\n",
       "      <td>0.032924</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>-0.042513</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>-0.093468</td>\n",
       "      <td>0.092818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_female</th>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.244943</td>\n",
       "      <td>-0.093198</td>\n",
       "      <td>0.303646</td>\n",
       "      <td>0.200988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.686808</td>\n",
       "      <td>-0.867334</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.084090</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>0.091776</td>\n",
       "      <td>-0.045475</td>\n",
       "      <td>0.052287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_male</th>\n",
       "      <td>-0.543351</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>-0.244943</td>\n",
       "      <td>0.093198</td>\n",
       "      <td>-0.303646</td>\n",
       "      <td>-0.200988</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>-0.686808</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>-0.547600</td>\n",
       "      <td>-0.006179</td>\n",
       "      <td>0.084090</td>\n",
       "      <td>-0.010421</td>\n",
       "      <td>-0.091776</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>-0.052287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>0.168240</td>\n",
       "      <td>-0.243292</td>\n",
       "      <td>-0.059528</td>\n",
       "      <td>-0.011069</td>\n",
       "      <td>0.204579</td>\n",
       "      <td>0.042419</td>\n",
       "      <td>0.095298</td>\n",
       "      <td>-0.046215</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>-0.082853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065432</td>\n",
       "      <td>0.026215</td>\n",
       "      <td>-0.072567</td>\n",
       "      <td>0.061395</td>\n",
       "      <td>-0.105869</td>\n",
       "      <td>-0.068141</td>\n",
       "      <td>0.361630</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>-0.339198</td>\n",
       "      <td>0.325325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.221009</td>\n",
       "      <td>-0.026354</td>\n",
       "      <td>-0.081228</td>\n",
       "      <td>-0.243154</td>\n",
       "      <td>-0.088339</td>\n",
       "      <td>-0.086464</td>\n",
       "      <td>-0.058592</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.074115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007767</td>\n",
       "      <td>0.171117</td>\n",
       "      <td>-0.078338</td>\n",
       "      <td>-0.089739</td>\n",
       "      <td>-0.048484</td>\n",
       "      <td>-0.123085</td>\n",
       "      <td>-0.097372</td>\n",
       "      <td>0.018938</td>\n",
       "      <td>0.206393</td>\n",
       "      <td>-0.093921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>-0.149683</td>\n",
       "      <td>0.074053</td>\n",
       "      <td>0.068734</td>\n",
       "      <td>0.060814</td>\n",
       "      <td>-0.026202</td>\n",
       "      <td>0.018431</td>\n",
       "      <td>-0.029074</td>\n",
       "      <td>0.077359</td>\n",
       "      <td>-0.119224</td>\n",
       "      <td>0.119224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052433</td>\n",
       "      <td>-0.130650</td>\n",
       "      <td>0.112870</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.123257</td>\n",
       "      <td>0.137152</td>\n",
       "      <td>-0.255526</td>\n",
       "      <td>-0.035339</td>\n",
       "      <td>0.167268</td>\n",
       "      <td>-0.225893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Master</th>\n",
       "      <td>0.085221</td>\n",
       "      <td>0.082081</td>\n",
       "      <td>0.349559</td>\n",
       "      <td>0.267344</td>\n",
       "      <td>0.124297</td>\n",
       "      <td>-0.324075</td>\n",
       "      <td>0.267024</td>\n",
       "      <td>0.372472</td>\n",
       "      <td>-0.159934</td>\n",
       "      <td>0.159934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038326</td>\n",
       "      <td>-0.109844</td>\n",
       "      <td>-0.254903</td>\n",
       "      <td>-0.087580</td>\n",
       "      <td>0.029992</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>-0.044095</td>\n",
       "      <td>0.012919</td>\n",
       "      <td>-0.046801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Misc</th>\n",
       "      <td>0.022030</td>\n",
       "      <td>-0.206333</td>\n",
       "      <td>-0.036364</td>\n",
       "      <td>-0.067480</td>\n",
       "      <td>0.112454</td>\n",
       "      <td>0.176985</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>-0.058565</td>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.089565</td>\n",
       "      <td>-0.207843</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>-0.038825</td>\n",
       "      <td>-0.032784</td>\n",
       "      <td>-0.063208</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>0.086656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Miss</th>\n",
       "      <td>0.327093</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>0.087932</td>\n",
       "      <td>0.105567</td>\n",
       "      <td>0.059106</td>\n",
       "      <td>-0.242363</td>\n",
       "      <td>0.055127</td>\n",
       "      <td>0.112838</td>\n",
       "      <td>0.686808</td>\n",
       "      <td>-0.686808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.595692</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.057497</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>0.024675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mr</th>\n",
       "      <td>-0.549199</td>\n",
       "      <td>0.142698</td>\n",
       "      <td>-0.250489</td>\n",
       "      <td>-0.333905</td>\n",
       "      <td>-0.312117</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>-0.396920</td>\n",
       "      <td>-0.338014</td>\n",
       "      <td>-0.867334</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207843</td>\n",
       "      <td>-0.595692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.474952</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.083562</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>-0.041512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_Mrs</th>\n",
       "      <td>0.339040</td>\n",
       "      <td>-0.149209</td>\n",
       "      <td>0.063407</td>\n",
       "      <td>0.225852</td>\n",
       "      <td>0.245302</td>\n",
       "      <td>0.146407</td>\n",
       "      <td>0.365454</td>\n",
       "      <td>0.156168</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>-0.547600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>-0.474952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>-0.039872</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>-0.043914</td>\n",
       "      <td>0.015478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_10</th>\n",
       "      <td>-0.019137</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>-0.011875</td>\n",
       "      <td>0.082150</td>\n",
       "      <td>-0.024758</td>\n",
       "      <td>-0.035189</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.032924</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>-0.006179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038825</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087893</td>\n",
       "      <td>-0.078529</td>\n",
       "      <td>-0.091182</td>\n",
       "      <td>-0.206928</td>\n",
       "      <td>-0.067067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_30</th>\n",
       "      <td>-0.081703</td>\n",
       "      <td>0.155894</td>\n",
       "      <td>0.084638</td>\n",
       "      <td>0.028529</td>\n",
       "      <td>-0.079605</td>\n",
       "      <td>-0.072051</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>-0.084090</td>\n",
       "      <td>0.084090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032784</td>\n",
       "      <td>-0.057497</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>-0.039872</td>\n",
       "      <td>-0.087893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.143093</td>\n",
       "      <td>-0.166150</td>\n",
       "      <td>-0.377058</td>\n",
       "      <td>-0.122208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_4</th>\n",
       "      <td>-0.012868</td>\n",
       "      <td>0.270416</td>\n",
       "      <td>-0.031555</td>\n",
       "      <td>-0.041927</td>\n",
       "      <td>-0.162293</td>\n",
       "      <td>-0.142312</td>\n",
       "      <td>-0.000926</td>\n",
       "      <td>-0.042513</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>-0.010421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063208</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>-0.078529</td>\n",
       "      <td>-0.143093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148449</td>\n",
       "      <td>-0.336886</td>\n",
       "      <td>-0.109188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_5</th>\n",
       "      <td>0.200178</td>\n",
       "      <td>-0.377124</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.263112</td>\n",
       "      <td>0.182356</td>\n",
       "      <td>0.122750</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.091776</td>\n",
       "      <td>-0.091776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>-0.083562</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>-0.091182</td>\n",
       "      <td>-0.166150</td>\n",
       "      <td>-0.148449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.391169</td>\n",
       "      <td>-0.126782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_6</th>\n",
       "      <td>-0.124049</td>\n",
       "      <td>0.157908</td>\n",
       "      <td>-0.112502</td>\n",
       "      <td>-0.033182</td>\n",
       "      <td>-0.194354</td>\n",
       "      <td>-0.062603</td>\n",
       "      <td>-0.130834</td>\n",
       "      <td>-0.093468</td>\n",
       "      <td>-0.045475</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>-0.043914</td>\n",
       "      <td>-0.206928</td>\n",
       "      <td>-0.377058</td>\n",
       "      <td>-0.336886</td>\n",
       "      <td>-0.391169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.287716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_len_8</th>\n",
       "      <td>0.097727</td>\n",
       "      <td>-0.324370</td>\n",
       "      <td>0.132163</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>0.314787</td>\n",
       "      <td>0.157564</td>\n",
       "      <td>0.031241</td>\n",
       "      <td>0.092818</td>\n",
       "      <td>0.052287</td>\n",
       "      <td>-0.052287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086656</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>-0.041512</td>\n",
       "      <td>0.015478</td>\n",
       "      <td>-0.067067</td>\n",
       "      <td>-0.122208</td>\n",
       "      <td>-0.109188</td>\n",
       "      <td>-0.126782</td>\n",
       "      <td>-0.287716</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Survived    Pclass     SibSp     Parch   FareBin    AgeBin  \\\n",
       "Survived       1.000000 -0.338481 -0.035322  0.081629  0.317783 -0.049771   \n",
       "Pclass        -0.338481  1.000000  0.083081  0.018443 -0.705206 -0.408902   \n",
       "SibSp         -0.035322  0.083081  1.000000  0.414838  0.354974 -0.238513   \n",
       "Parch          0.081629  0.018443  0.414838  1.000000  0.351317 -0.154571   \n",
       "FareBin        0.317783 -0.705206  0.354974  0.351317  1.000000  0.148150   \n",
       "AgeBin        -0.049771 -0.408902 -0.238513 -0.154571  0.148150  1.000000   \n",
       "IsAlone        0.203367 -0.135207  0.584471  0.583398  0.520277 -0.161040   \n",
       "FamilySize     0.016639  0.065997  0.890712  0.783111  0.418125 -0.240237   \n",
       "Sex_female     0.543351 -0.131900  0.114631  0.245489  0.244943 -0.093198   \n",
       "Sex_male      -0.543351  0.131900 -0.114631 -0.245489 -0.244943  0.093198   \n",
       "Embarked_C     0.168240 -0.243292 -0.059528 -0.011069  0.204579  0.042419   \n",
       "Embarked_Q     0.003650  0.221009 -0.026354 -0.081228 -0.243154 -0.088339   \n",
       "Embarked_S    -0.149683  0.074053  0.068734  0.060814 -0.026202  0.018431   \n",
       "Title_Master   0.085221  0.082081  0.349559  0.267344  0.124297 -0.324075   \n",
       "Title_Misc     0.022030 -0.206333 -0.036364 -0.067480  0.112454  0.176985   \n",
       "Title_Miss     0.327093 -0.000576  0.087932  0.105567  0.059106 -0.242363   \n",
       "Title_Mr      -0.549199  0.142698 -0.250489 -0.333905 -0.312117  0.169465   \n",
       "Title_Mrs      0.339040 -0.149209  0.063407  0.225852  0.245302  0.146407   \n",
       "Ticket_len_10 -0.019137  0.027858 -0.011875  0.082150 -0.024758 -0.035189   \n",
       "Ticket_len_30 -0.081703  0.155894  0.084638  0.028529 -0.079605 -0.072051   \n",
       "Ticket_len_4  -0.012868  0.270416 -0.031555 -0.041927 -0.162293 -0.142312   \n",
       "Ticket_len_5   0.200178 -0.377124  0.007149  0.003978  0.263112  0.182356   \n",
       "Ticket_len_6  -0.124049  0.157908 -0.112502 -0.033182 -0.194354 -0.062603   \n",
       "Ticket_len_8   0.097727 -0.324370  0.132163  0.004982  0.314787  0.157564   \n",
       "\n",
       "                IsAlone  FamilySize  Sex_female  Sex_male  ...  Title_Misc  \\\n",
       "Survived       0.203367    0.016639    0.543351 -0.543351  ...    0.022030   \n",
       "Pclass        -0.135207    0.065997   -0.131900  0.131900  ...   -0.206333   \n",
       "SibSp          0.584471    0.890712    0.114631 -0.114631  ...   -0.036364   \n",
       "Parch          0.583398    0.783111    0.245489 -0.245489  ...   -0.067480   \n",
       "FareBin        0.520277    0.418125    0.244943 -0.244943  ...    0.112454   \n",
       "AgeBin        -0.161040   -0.240237   -0.093198  0.093198  ...    0.176985   \n",
       "IsAlone        1.000000    0.690922    0.303646 -0.303646  ...   -0.049870   \n",
       "FamilySize     0.690922    1.000000    0.200988 -0.200988  ...   -0.058565   \n",
       "Sex_female     0.303646    0.200988    1.000000 -1.000000  ...   -0.034471   \n",
       "Sex_male      -0.303646   -0.200988   -1.000000  1.000000  ...    0.034471   \n",
       "Embarked_C     0.095298   -0.046215    0.082853 -0.082853  ...    0.065432   \n",
       "Embarked_Q    -0.086464   -0.058592    0.074115 -0.074115  ...   -0.007767   \n",
       "Embarked_S    -0.029074    0.077359   -0.119224  0.119224  ...   -0.052433   \n",
       "Title_Master   0.267024    0.372472   -0.159934  0.159934  ...   -0.038326   \n",
       "Title_Misc    -0.049870   -0.058565   -0.034471  0.034471  ...    1.000000   \n",
       "Title_Miss     0.055127    0.112838    0.686808 -0.686808  ...   -0.089565   \n",
       "Title_Mr      -0.396920   -0.338014   -0.867334  0.867334  ...   -0.207843   \n",
       "Title_Mrs      0.365454    0.156168    0.547600 -0.547600  ...   -0.071411   \n",
       "Ticket_len_10  0.018724    0.032924    0.006179 -0.006179  ...   -0.038825   \n",
       "Ticket_len_30  0.027469    0.072100   -0.084090  0.084090  ...   -0.032784   \n",
       "Ticket_len_4  -0.000926   -0.042513    0.010421 -0.010421  ...   -0.063208   \n",
       "Ticket_len_5   0.122750    0.006873    0.091776 -0.091776  ...    0.056025   \n",
       "Ticket_len_6  -0.130834   -0.093468   -0.045475  0.045475  ...   -0.009143   \n",
       "Ticket_len_8   0.031241    0.092818    0.052287 -0.052287  ...    0.086656   \n",
       "\n",
       "               Title_Miss  Title_Mr  Title_Mrs  Ticket_len_10  Ticket_len_30  \\\n",
       "Survived         0.327093 -0.549199   0.339040      -0.019137      -0.081703   \n",
       "Pclass          -0.000576  0.142698  -0.149209       0.027858       0.155894   \n",
       "SibSp            0.087932 -0.250489   0.063407      -0.011875       0.084638   \n",
       "Parch            0.105567 -0.333905   0.225852       0.082150       0.028529   \n",
       "FareBin          0.059106 -0.312117   0.245302      -0.024758      -0.079605   \n",
       "AgeBin          -0.242363  0.169465   0.146407      -0.035189      -0.072051   \n",
       "IsAlone          0.055127 -0.396920   0.365454       0.018724       0.027469   \n",
       "FamilySize       0.112838 -0.338014   0.156168       0.032924       0.072100   \n",
       "Sex_female       0.686808 -0.867334   0.547600       0.006179      -0.084090   \n",
       "Sex_male        -0.686808  0.867334  -0.547600      -0.006179       0.084090   \n",
       "Embarked_C       0.026215 -0.072567   0.061395      -0.105869      -0.068141   \n",
       "Embarked_Q       0.171117 -0.078338  -0.089739      -0.048484      -0.123085   \n",
       "Embarked_S      -0.130650  0.112870   0.002689       0.123257       0.137152   \n",
       "Title_Master    -0.109844 -0.254903  -0.087580       0.029992       0.038938   \n",
       "Title_Misc      -0.089565 -0.207843  -0.071411      -0.038825      -0.032784   \n",
       "Title_Miss       1.000000 -0.595692  -0.204670      -0.004981      -0.057497   \n",
       "Title_Mr        -0.595692  1.000000  -0.474952      -0.008576       0.070078   \n",
       "Title_Mrs       -0.204670 -0.474952   1.000000       0.019250      -0.039872   \n",
       "Ticket_len_10   -0.004981 -0.008576   0.019250       1.000000      -0.087893   \n",
       "Ticket_len_30   -0.057497  0.070078  -0.039872      -0.087893       1.000000   \n",
       "Ticket_len_4     0.020804  0.002834  -0.001728      -0.078529      -0.143093   \n",
       "Ticket_len_5     0.033341 -0.083562   0.078680      -0.091182      -0.166150   \n",
       "Ticket_len_6    -0.008851  0.035888  -0.043914      -0.206928      -0.377058   \n",
       "Ticket_len_8     0.024675 -0.041512   0.015478      -0.067067      -0.122208   \n",
       "\n",
       "               Ticket_len_4  Ticket_len_5  Ticket_len_6  Ticket_len_8  \n",
       "Survived          -0.012868      0.200178     -0.124049      0.097727  \n",
       "Pclass             0.270416     -0.377124      0.157908     -0.324370  \n",
       "SibSp             -0.031555      0.007149     -0.112502      0.132163  \n",
       "Parch             -0.041927      0.003978     -0.033182      0.004982  \n",
       "FareBin           -0.162293      0.263112     -0.194354      0.314787  \n",
       "AgeBin            -0.142312      0.182356     -0.062603      0.157564  \n",
       "IsAlone           -0.000926      0.122750     -0.130834      0.031241  \n",
       "FamilySize        -0.042513      0.006873     -0.093468      0.092818  \n",
       "Sex_female         0.010421      0.091776     -0.045475      0.052287  \n",
       "Sex_male          -0.010421     -0.091776      0.045475     -0.052287  \n",
       "Embarked_C         0.361630      0.026735     -0.339198      0.325325  \n",
       "Embarked_Q        -0.097372      0.018938      0.206393     -0.093921  \n",
       "Embarked_S        -0.255526     -0.035339      0.167268     -0.225893  \n",
       "Title_Master       0.007963     -0.044095      0.012919     -0.046801  \n",
       "Title_Misc        -0.063208      0.056025     -0.009143      0.086656  \n",
       "Title_Miss         0.020804      0.033341     -0.008851      0.024675  \n",
       "Title_Mr           0.002834     -0.083562      0.035888     -0.041512  \n",
       "Title_Mrs         -0.001728      0.078680     -0.043914      0.015478  \n",
       "Ticket_len_10     -0.078529     -0.091182     -0.206928     -0.067067  \n",
       "Ticket_len_30     -0.143093     -0.166150     -0.377058     -0.122208  \n",
       "Ticket_len_4       1.000000     -0.148449     -0.336886     -0.109188  \n",
       "Ticket_len_5      -0.148449      1.000000     -0.391169     -0.126782  \n",
       "Ticket_len_6      -0.336886     -0.391169      1.000000     -0.287716  \n",
       "Ticket_len_8      -0.109188     -0.126782     -0.287716      1.000000  \n",
       "\n",
       "[24 rows x 24 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap all preprocesses to a single function\n",
    "\n",
    "Wrapping our data cleaning and feature engineering processes into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_p (train, test):\n",
    "    train_c = data_clean(train)\n",
    "    train_f = f_eng(train_c)\n",
    "    y_train = train_f.Survived\n",
    "    X_train = train_f.drop('Survived', axis=1)\n",
    "    \n",
    "    test_c = data_clean(test)\n",
    "    test_f = f_eng(test_c)\n",
    "    X_test = test_f\n",
    "    \n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test = pre_p (train_raw, test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "In this effort, we will first build a collection of base models with a set of base scores. Then, we are going perform hyperparameter optimization using Grid Search to find the best parameter combination for each model to find the top five tuned models for the final prediction. In addition, we will take an ensemble approach taking all the tuned model and combine them with VotingClassifier to create an aggregated model that we are also going to use for the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building out a base model set\n",
    "The objective is to have a baseline score set to compare with the resulting scores in subsequent optimization efforts. Also, with this baseline score set, we know roughly how good the predictions will be with the dataset we crafted as a result of the above feature engineering effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model (X_tr, y_tr):\n",
    "    #this is from https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "    #Machine Learning Algorithm (MLA) Selection and Initialization\n",
    "    MLA = [\n",
    "        #Ensemble Methods\n",
    "        ensemble.AdaBoostClassifier(),\n",
    "        ensemble.BaggingClassifier(),\n",
    "        ensemble.ExtraTreesClassifier(),\n",
    "        ensemble.GradientBoostingClassifier(),\n",
    "        ensemble.RandomForestClassifier(),\n",
    "\n",
    "        #Gaussian Processes\n",
    "        gaussian_process.GaussianProcessClassifier(),\n",
    "\n",
    "        #GLM\n",
    "        linear_model.LogisticRegressionCV(),\n",
    "        linear_model.PassiveAggressiveClassifier(),\n",
    "        linear_model.RidgeClassifierCV(),\n",
    "        linear_model.SGDClassifier(),\n",
    "        linear_model.Perceptron(),\n",
    "\n",
    "        #Navies Bayes\n",
    "        naive_bayes.BernoulliNB(),\n",
    "        naive_bayes.GaussianNB(),\n",
    "\n",
    "        #Nearest Neighbor\n",
    "        neighbors.KNeighborsClassifier(),\n",
    "\n",
    "        #SVM\n",
    "        svm.SVC(probability=True),\n",
    "        svm.NuSVC(probability=True),\n",
    "        svm.LinearSVC(),\n",
    "\n",
    "        #Trees    \n",
    "        tree.DecisionTreeClassifier(),\n",
    "        tree.ExtraTreeClassifier(),\n",
    "\n",
    "        #Discriminant Analysis\n",
    "        discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "        discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "\n",
    "        #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "        XGBClassifier()    \n",
    "        ]\n",
    "    \n",
    "    #split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
    "    #note: this is an alternative to train_test_split\n",
    "    #cv_split = model_selection.ShuffleSplit(test_size = .2, train_size = .8, random_state = 0 ) # run model 10x with 80/20 split intentionally leaving out 10%\n",
    "\n",
    "    #create table to compare MLA metrics\n",
    "    MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
    "    MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "    #create table to compare MLA predictions\n",
    "    MLA_predict = y_tr\n",
    "\n",
    "    #index through MLA and save performance to table\n",
    "    row_index = 0\n",
    "    for alg in MLA:\n",
    "\n",
    "        #set name and parameters\n",
    "        MLA_name = alg.__class__.__name__\n",
    "        #print(MLA_name)\n",
    "        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "        MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "        #print(y_tr.shape)\n",
    "\n",
    "        #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "        cv_results = model_selection.cross_validate(alg, X_tr, y_tr, cv = 5, scoring='accuracy', return_train_score=True)\n",
    "        \n",
    "\n",
    "        MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
    "        MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "        MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
    "        #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "        MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "\n",
    "\n",
    "        #save MLA predictions - see section 6 for usage\n",
    "        #alg.fit(X_tr, y_tr)\n",
    "        #MLA_predict[MLA_name] = alg.predict(X_tr)\n",
    "\n",
    "        row_index+=1\n",
    "\n",
    "\n",
    "    #print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "    MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "    return MLA_compare\n",
    "    #MLA_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_alg = base_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'verbose': False, ...</td>\n",
       "      <td>0.833335</td>\n",
       "      <td>0.830549</td>\n",
       "      <td>0.0611035</td>\n",
       "      <td>0.0991999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'presort': 'auto', 'loss': 'deviance', 'min_i...</td>\n",
       "      <td>0.874864</td>\n",
       "      <td>0.829488</td>\n",
       "      <td>0.0951147</td>\n",
       "      <td>0.0880001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'loss': 'squared_hinge', 'C': 1.0, 'verbose':...</td>\n",
       "      <td>0.838387</td>\n",
       "      <td>0.828333</td>\n",
       "      <td>0.0801202</td>\n",
       "      <td>0.0536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>{'scoring': None, 'n_jobs': None, 'verbose': 0...</td>\n",
       "      <td>0.841753</td>\n",
       "      <td>0.827203</td>\n",
       "      <td>0.0862662</td>\n",
       "      <td>0.2896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'solver': 'svd', 'priors': None, 'n_component...</td>\n",
       "      <td>0.835302</td>\n",
       "      <td>0.827184</td>\n",
       "      <td>0.0831936</td>\n",
       "      <td>0.00700002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>{'kernel': 'rbf', 'verbose': False, 'probabili...</td>\n",
       "      <td>0.831933</td>\n",
       "      <td>0.827165</td>\n",
       "      <td>0.0576147</td>\n",
       "      <td>0.1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'reg_alpha': 0, 'colsample_bytree': 1, 'silen...</td>\n",
       "      <td>0.861957</td>\n",
       "      <td>0.824981</td>\n",
       "      <td>0.0958777</td>\n",
       "      <td>0.0405999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>{'normalize': False, 'alphas': array([ 0.1,  1...</td>\n",
       "      <td>0.834741</td>\n",
       "      <td>0.824924</td>\n",
       "      <td>0.0747722</td>\n",
       "      <td>0.00800004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>{'warm_start': False, 'kernel': None, 'n_jobs'...</td>\n",
       "      <td>0.894507</td>\n",
       "      <td>0.820468</td>\n",
       "      <td>0.0602524</td>\n",
       "      <td>0.3644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'n_estimators': 50, 'base_estimator': None, '...</td>\n",
       "      <td>0.832777</td>\n",
       "      <td>0.815998</td>\n",
       "      <td>0.0581527</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'n_neighbors': 5, 'n_jobs': None, 'algorithm'...</td>\n",
       "      <td>0.866168</td>\n",
       "      <td>0.811554</td>\n",
       "      <td>0.0807268</td>\n",
       "      <td>0.00599999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'warm_start': False, 'oob_score': False, 'n_j...</td>\n",
       "      <td>0.918073</td>\n",
       "      <td>0.798064</td>\n",
       "      <td>0.0898239</td>\n",
       "      <td>0.0290001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'warm_start': False, 'max_samples': 1.0, 'bas...</td>\n",
       "      <td>0.911901</td>\n",
       "      <td>0.796884</td>\n",
       "      <td>0.0787063</td>\n",
       "      <td>0.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>0.803593</td>\n",
       "      <td>0.789069</td>\n",
       "      <td>0.0616201</td>\n",
       "      <td>0.00379996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'binarize': 0.0, 'alpha': 1.0, 'fit_prior': T...</td>\n",
       "      <td>0.79377</td>\n",
       "      <td>0.784543</td>\n",
       "      <td>0.0559523</td>\n",
       "      <td>0.00279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'warm_start': False, 'oob_score': False, 'n_j...</td>\n",
       "      <td>0.913021</td>\n",
       "      <td>0.782334</td>\n",
       "      <td>0.0510728</td>\n",
       "      <td>0.0218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'splitter': 'random', 'min_impurity_decrease'...</td>\n",
       "      <td>0.918073</td>\n",
       "      <td>0.77563</td>\n",
       "      <td>0.0894311</td>\n",
       "      <td>0.00400004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'presort': False, 'splitter': 'best', 'min_im...</td>\n",
       "      <td>0.918073</td>\n",
       "      <td>0.77337</td>\n",
       "      <td>0.0909213</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>{'warm_start': False, 'n_iter': None, 'n_jobs'...</td>\n",
       "      <td>0.777776</td>\n",
       "      <td>0.764356</td>\n",
       "      <td>0.118068</td>\n",
       "      <td>0.00439997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>{'warm_start': False, 'loss': 'hinge', 'C': 1....</td>\n",
       "      <td>0.716074</td>\n",
       "      <td>0.726092</td>\n",
       "      <td>0.51888</td>\n",
       "      <td>0.00679989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'n_jobs': None, 'shuffle': True, 'verbose': 0...</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.703996</td>\n",
       "      <td>0.33642</td>\n",
       "      <td>0.00419998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>{'priors': None, 'store_covariances': None, 'r...</td>\n",
       "      <td>0.684626</td>\n",
       "      <td>0.68475</td>\n",
       "      <td>0.0960356</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "14                            SVC   \n",
       "3      GradientBoostingClassifier   \n",
       "16                      LinearSVC   \n",
       "6            LogisticRegressionCV   \n",
       "19     LinearDiscriminantAnalysis   \n",
       "15                          NuSVC   \n",
       "21                  XGBClassifier   \n",
       "8               RidgeClassifierCV   \n",
       "5       GaussianProcessClassifier   \n",
       "0              AdaBoostClassifier   \n",
       "13           KNeighborsClassifier   \n",
       "2            ExtraTreesClassifier   \n",
       "1               BaggingClassifier   \n",
       "12                     GaussianNB   \n",
       "11                    BernoulliNB   \n",
       "4          RandomForestClassifier   \n",
       "18            ExtraTreeClassifier   \n",
       "17         DecisionTreeClassifier   \n",
       "10                     Perceptron   \n",
       "7     PassiveAggressiveClassifier   \n",
       "9                   SGDClassifier   \n",
       "20  QuadraticDiscriminantAnalysis   \n",
       "\n",
       "                                       MLA Parameters MLA Train Accuracy Mean  \\\n",
       "14  {'kernel': 'rbf', 'C': 1.0, 'verbose': False, ...                0.833335   \n",
       "3   {'presort': 'auto', 'loss': 'deviance', 'min_i...                0.874864   \n",
       "16  {'loss': 'squared_hinge', 'C': 1.0, 'verbose':...                0.838387   \n",
       "6   {'scoring': None, 'n_jobs': None, 'verbose': 0...                0.841753   \n",
       "19  {'solver': 'svd', 'priors': None, 'n_component...                0.835302   \n",
       "15  {'kernel': 'rbf', 'verbose': False, 'probabili...                0.831933   \n",
       "21  {'reg_alpha': 0, 'colsample_bytree': 1, 'silen...                0.861957   \n",
       "8   {'normalize': False, 'alphas': array([ 0.1,  1...                0.834741   \n",
       "5   {'warm_start': False, 'kernel': None, 'n_jobs'...                0.894507   \n",
       "0   {'n_estimators': 50, 'base_estimator': None, '...                0.832777   \n",
       "13  {'n_neighbors': 5, 'n_jobs': None, 'algorithm'...                0.866168   \n",
       "2   {'warm_start': False, 'oob_score': False, 'n_j...                0.918073   \n",
       "1   {'warm_start': False, 'max_samples': 1.0, 'bas...                0.911901   \n",
       "12           {'priors': None, 'var_smoothing': 1e-09}                0.803593   \n",
       "11  {'binarize': 0.0, 'alpha': 1.0, 'fit_prior': T...                 0.79377   \n",
       "4   {'warm_start': False, 'oob_score': False, 'n_j...                0.913021   \n",
       "18  {'splitter': 'random', 'min_impurity_decrease'...                0.918073   \n",
       "17  {'presort': False, 'splitter': 'best', 'min_im...                0.918073   \n",
       "10  {'warm_start': False, 'n_iter': None, 'n_jobs'...                0.777776   \n",
       "7   {'warm_start': False, 'loss': 'hinge', 'C': 1....                0.716074   \n",
       "9   {'n_jobs': None, 'shuffle': True, 'verbose': 0...                0.723577   \n",
       "20  {'priors': None, 'store_covariances': None, 'r...                0.684626   \n",
       "\n",
       "   MLA Test Accuracy Mean MLA Test Accuracy 3*STD    MLA Time  \n",
       "14               0.830549               0.0611035   0.0991999  \n",
       "3                0.829488               0.0951147   0.0880001  \n",
       "16               0.828333               0.0801202      0.0536  \n",
       "6                0.827203               0.0862662      0.2896  \n",
       "19               0.827184               0.0831936  0.00700002  \n",
       "15               0.827165               0.0576147      0.1146  \n",
       "21               0.824981               0.0958777   0.0405999  \n",
       "8                0.824924               0.0747722  0.00800004  \n",
       "5                0.820468               0.0602524      0.3644  \n",
       "0                0.815998               0.0581527       0.125  \n",
       "13               0.811554               0.0807268  0.00599999  \n",
       "2                0.798064               0.0898239   0.0290001  \n",
       "1                0.796884               0.0787063      0.0282  \n",
       "12               0.789069               0.0616201  0.00379996  \n",
       "11               0.784543               0.0559523  0.00279999  \n",
       "4                0.782334               0.0510728      0.0218  \n",
       "18                0.77563               0.0894311  0.00400004  \n",
       "17                0.77337               0.0909213      0.0046  \n",
       "10               0.764356                0.118068  0.00439997  \n",
       "7                0.726092                 0.51888  0.00679989  \n",
       "9                0.703996                 0.33642  0.00419998  \n",
       "20                0.68475               0.0960356      0.0026  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Algorithm')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\n",
    "sns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = base_alg, color = 'm')\n",
    "\n",
    "#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\n",
    "plt.title('Machine Learning Algorithm Accuracy Score \\n')\n",
    "plt.xlabel('Accuracy Score (%)')\n",
    "plt.ylabel('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "Test Accuracy Mean will be the only indicator we will be using in this evaluation. The best score is from the SVC classifier, with an accuracy score of 0.830549. This is pretty good for an pre-tune model. The others follow are, GBC, LinearSVC, LinearSVC, etc. all in the 0.82-0.83 range.\n",
    "\n",
    "#### Action Plan\n",
    "Perform hyperparameter tuning to see how much impovement we could gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "\n",
    "Now we know the baseline score set, let's tune the model to see how much we can improve our models. We will use Grid Search to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is borrowed from the Kaggle notebook https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "#the original idea was to take the top ten from our list above, but since the alg list below covers a large portion of our top ten, we will use it directly\n",
    "def hp_tune(X_tr, y_tr, base_alg):\n",
    "    \n",
    "    vote_est = [\n",
    "                #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n",
    "                ('ada', ensemble.AdaBoostClassifier()),\n",
    "                ('bc', ensemble.BaggingClassifier()),\n",
    "                ('etc',ensemble.ExtraTreesClassifier()),\n",
    "                ('gbc', ensemble.GradientBoostingClassifier()),\n",
    "                ('rfc', ensemble.RandomForestClassifier()),\n",
    "\n",
    "                #Gaussian Processes: http://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process-classification-gpc\n",
    "                ('gpc', gaussian_process.GaussianProcessClassifier()),\n",
    "\n",
    "                #GLM: http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "                ('lr', linear_model.LogisticRegressionCV()),\n",
    "\n",
    "                #Navies Bayes: http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "                ('bnb', naive_bayes.BernoulliNB()),\n",
    "                ('gnb', naive_bayes.GaussianNB()),\n",
    "\n",
    "                #Nearest Neighbor: http://scikit-learn.org/stable/modules/neighbors.html\n",
    "                ('knn', neighbors.KNeighborsClassifier()),\n",
    "\n",
    "                #SVM: http://scikit-learn.org/stable/modules/svm.html\n",
    "                ('svc', svm.SVC(probability=True)),\n",
    "\n",
    "                #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "               ('xgb', XGBClassifier())\n",
    "\n",
    "                ]\n",
    "    \n",
    "    #Hyperparameter Tune with GridSearchCV: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "    grid_n_estimator = [10, 50, 100, 300, 500]\n",
    "    grid_ratio = [.1, .25, .5, .75, 1.0]\n",
    "    grid_learn = [.01, .03, .05, .1, .25]\n",
    "    grid_max_depth = [2, 4, 6, 8, 10, None]\n",
    "    grid_min_samples = [5, 10, .03, .05, .10]\n",
    "    grid_criterion = ['gini', 'entropy']\n",
    "    grid_bool = [True, False]\n",
    "    grid_seed = [0]\n",
    "\n",
    "\n",
    "    grid_param = [\n",
    "                [{\n",
    "                #AdaBoostClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "                'n_estimators': grid_n_estimator, #default=50\n",
    "                'learning_rate': grid_learn, #default=1\n",
    "                #'algorithm': ['SAMME', 'SAMME.R'], #default=SAMME.R\n",
    "                'random_state': grid_seed\n",
    "                }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #BaggingClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier\n",
    "                'n_estimators': grid_n_estimator, #default=10\n",
    "                'max_samples': grid_ratio, #default=1.0\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #ExtraTreesClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier\n",
    "                'n_estimators': grid_n_estimator, #default=10\n",
    "                'criterion': grid_criterion, #default=gini\n",
    "                'max_depth': grid_max_depth, #default=None\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #GradientBoostingClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n",
    "                #'loss': ['deviance', 'exponential'], #default=deviance\n",
    "                'learning_rate': [.05], #default=0.1 -- 12/31/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.\n",
    "                'n_estimators': [300], #default=100 -- 12/31/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.\n",
    "                #'criterion': ['friedman_mse', 'mse', 'mae'], #default=friedman_mse\n",
    "                'max_depth': grid_max_depth, #default=3   \n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #RandomForestClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "                'n_estimators': grid_n_estimator, #default=10\n",
    "                'criterion': grid_criterion, #default=gini\n",
    "                'max_depth': grid_max_depth, #default=None\n",
    "                'oob_score': [True], #default=False -- 12/31/17 set to reduce runtime -- The best parameter for RandomForestClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'oob_score': True, 'random_state': 0} with a runtime of 146.35 seconds.\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "                [{    \n",
    "                #GaussianProcessClassifier\n",
    "                'max_iter_predict': grid_n_estimator, #default: 100\n",
    "                'random_state': grid_seed\n",
    "                }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #LogisticRegressionCV - http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV\n",
    "                'fit_intercept': grid_bool, #default: True\n",
    "                #'penalty': ['l1','l2'],\n",
    "                'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], #default: lbfgs\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #BernoulliNB - http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB\n",
    "                'alpha': grid_ratio, #default: 1.0\n",
    "                 }],\n",
    "\n",
    "\n",
    "                #GaussianNB - \n",
    "                [{}],\n",
    "\n",
    "                [{\n",
    "                #KNeighborsClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "                'n_neighbors': [1,2,3,4,5,6,7], #default: 5\n",
    "                'weights': ['uniform', 'distance'], #default = uniform\n",
    "                'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "                }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #SVC - http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "                #http://blog.hackerearth.com/simple-tutorial-svm-parameter-tuning-python-r\n",
    "                #'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                'C': [1,2,3,4,5], #default=1.0\n",
    "                'gamma': grid_ratio, #edfault: auto\n",
    "                'decision_function_shape': ['ovo', 'ovr'], #default:ovr\n",
    "                'probability': [True],\n",
    "                'random_state': grid_seed\n",
    "                 }],\n",
    "\n",
    "\n",
    "                [{\n",
    "                #XGBClassifier - http://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "                'learning_rate': grid_learn, #default: .3\n",
    "                'max_depth': [1,2,4,6,8,10], #default 2\n",
    "                'n_estimators': grid_n_estimator, \n",
    "                'seed': grid_seed  \n",
    "                 }]   \n",
    "            ]\n",
    "\n",
    "    \n",
    "    #create a table to display key metrics\n",
    "    hp_columns = ['Alg Name', 'Best Score', 'Score Before Tuning', 'Best Parameters']\n",
    "    hp_compare = pd.DataFrame(columns = hp_columns)\n",
    "\n",
    "    #index through MLA and save performance to table\n",
    "    row_index = 0\n",
    "\n",
    "    for clf, param in zip (vote_est, grid_param): #https://docs.python.org/3/library/functions.html#zip\n",
    "\n",
    "     \n",
    "        best_search = model_selection.GridSearchCV(estimator = clf[1], param_grid = param, cv = 5, scoring = 'accuracy', n_jobs = -1)\n",
    "        best_search.fit(X_tr, y_tr)\n",
    "\n",
    "        best_param = best_search.best_params_\n",
    "        best_score = best_search.best_score_\n",
    "        alg_name = clf[1].__class__.__name__\n",
    "        #print('The best parameter for {} is {} with a runtime of {:.2f} seconds.'.format(clf[1].__class__.__name__, best_param, run))\n",
    "        clf[1].set_params(**best_param) \n",
    "        \n",
    "        hp_compare.loc[row_index, 'Alg Name'] = alg_name\n",
    "        hp_compare.loc[row_index, 'Best Parameters'] = str(best_param)\n",
    "        hp_compare.loc[row_index, 'Best Score'] = best_score\n",
    "        hp_compare.loc[row_index, 'Score Before Tuning'] = base_alg.loc[base_alg['MLA Name'] == alg_name]['MLA Test Accuracy Mean'].tolist()[0]\n",
    "        row_index+=1\n",
    "\n",
    "\n",
    "    print('Done')\n",
    "    print('-'*10)\n",
    "    \n",
    "    return vote_est, hp_compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "tuned_algs, hp_compare = hp_tune(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alg Name</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Score Before Tuning</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.824981</td>\n",
       "      <td>{'n_estimators': 50, 'learning_rate': 0.05, 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.830549</td>\n",
       "      <td>{'C': 3, 'random_state': 0, 'decision_function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.829405</td>\n",
       "      <td>0.796884</td>\n",
       "      <td>{'n_estimators': 500, 'max_samples': 0.5, 'ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.829405</td>\n",
       "      <td>0.782334</td>\n",
       "      <td>{'n_estimators': 100, 'oob_score': True, 'rand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.815998</td>\n",
       "      <td>{'n_estimators': 300, 'learning_rate': 0.03, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.798064</td>\n",
       "      <td>{'n_estimators': 100, 'random_state': 0, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.82716</td>\n",
       "      <td>0.827203</td>\n",
       "      <td>{'solver': 'newton-cg', 'random_state': 0, 'fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.824916</td>\n",
       "      <td>0.829488</td>\n",
       "      <td>{'n_estimators': 300, 'learning_rate': 0.05, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.822671</td>\n",
       "      <td>0.811554</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'uniform', 'algo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.820468</td>\n",
       "      <td>{'max_iter_predict': 10, 'random_state': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.789001</td>\n",
       "      <td>0.789069</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.784512</td>\n",
       "      <td>0.784543</td>\n",
       "      <td>{'alpha': 0.25}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Alg Name Best Score Score Before Tuning  \\\n",
       "11               XGBClassifier   0.838384            0.824981   \n",
       "10                         SVC   0.830527            0.830549   \n",
       "1            BaggingClassifier   0.829405            0.796884   \n",
       "4       RandomForestClassifier   0.829405            0.782334   \n",
       "0           AdaBoostClassifier   0.828283            0.815998   \n",
       "2         ExtraTreesClassifier   0.828283            0.798064   \n",
       "6         LogisticRegressionCV    0.82716            0.827203   \n",
       "3   GradientBoostingClassifier   0.824916            0.829488   \n",
       "9         KNeighborsClassifier   0.822671            0.811554   \n",
       "5    GaussianProcessClassifier   0.820426            0.820468   \n",
       "8                   GaussianNB   0.789001            0.789069   \n",
       "7                  BernoulliNB   0.784512            0.784543   \n",
       "\n",
       "                                      Best Parameters  \n",
       "11  {'n_estimators': 50, 'learning_rate': 0.05, 's...  \n",
       "10  {'C': 3, 'random_state': 0, 'decision_function...  \n",
       "1   {'n_estimators': 500, 'max_samples': 0.5, 'ran...  \n",
       "4   {'n_estimators': 100, 'oob_score': True, 'rand...  \n",
       "0   {'n_estimators': 300, 'learning_rate': 0.03, '...  \n",
       "2   {'n_estimators': 100, 'random_state': 0, 'crit...  \n",
       "6   {'solver': 'newton-cg', 'random_state': 0, 'fi...  \n",
       "3   {'n_estimators': 300, 'learning_rate': 0.05, '...  \n",
       "9   {'n_neighbors': 5, 'weights': 'uniform', 'algo...  \n",
       "5         {'max_iter_predict': 10, 'random_state': 0}  \n",
       "8                                                  {}  \n",
       "7                                     {'alpha': 0.25}  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_compare.sort_values(by='Best Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "There are some changes in the ranking position, mostly noticeably XGBClassifier replaced SVC as the best performing model with a score of 0.838384, that 0.005 better than the un-tuned SVC model, which is not a lot. For SVC, the pre-tune score is roughly the same as the post-tune score. Overall, the scores are in the 0.83 range, which is pretty good. \n",
    "\n",
    "#### Action Plan\n",
    "See if we can get even better scores with the ensemble approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Ensemble Approach\n",
    "\n",
    "Let's combine the tuned models to create aggregated model to see if we can get even better prediction scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_alg (algs, X_tr, y_tr):\n",
    "    \n",
    "    grid_hard = ensemble.VotingClassifier(estimators = algs , voting = 'hard')\n",
    "    grid_hard_cv = model_selection.cross_validate(grid_hard, X_tr, y_tr, cv  = 5, return_train_score=True)\n",
    "    grid_hard.fit(X_tr, y_tr)\n",
    "\n",
    "    print(\"Hard Voting w/Tuned Hyperparameters Training w/bin score mean: {:.2f}\". format(grid_hard_cv['train_score'].mean()*100)) \n",
    "    print(\"Hard Voting w/Tuned Hyperparameters Test w/bin score mean: {:.2f}\". format(grid_hard_cv['test_score'].mean()*100))\n",
    "    print(\"Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- {:.2f}\". format(grid_hard_cv['test_score'].std()*100*3))\n",
    "    print('-'*10)\n",
    "\n",
    "    #Soft Vote or weighted probabilities w/Tuned Hyperparameters\n",
    "    grid_soft = ensemble.VotingClassifier(estimators = algs , voting = 'soft')\n",
    "    grid_soft_cv = model_selection.cross_validate(grid_soft, X_tr, y_tr, cv  = 5, return_train_score=True)\n",
    "    grid_soft.fit(X_tr, y_tr)\n",
    "\n",
    "    print(\"Soft Voting w/Tuned Hyperparameters Training w/bin score mean: {:.2f}\". format(grid_soft_cv['train_score'].mean()*100)) \n",
    "    print(\"Soft Voting w/Tuned Hyperparameters Test w/bin score mean: {:.2f}\". format(grid_soft_cv['test_score'].mean()*100))\n",
    "    print(\"Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- {:.2f}\". format(grid_soft_cv['test_score'].std()*100*3))\n",
    "    print('-'*10)\n",
    "    \n",
    "    return grid_hard, grid_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting w/Tuned Hyperparameters Training w/bin score mean: 85.58\n",
      "Hard Voting w/Tuned Hyperparameters Test w/bin score mean: 82.94\n",
      "Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 5.82\n",
      "----------\n",
      "Soft Voting w/Tuned Hyperparameters Training w/bin score mean: 85.19\n",
      "Soft Voting w/Tuned Hyperparameters Test w/bin score mean: 83.17\n",
      "Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 8.00\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "vc_hard_all, vc_soft_all = en_alg(tuned_algs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obervation\n",
    "We see that in an ensemble approach Soft Voting has a higher test scroe, 83.17, only slightly better than the Hard Voting approach\n",
    "\n",
    "#### Action Plan\n",
    "We will include the soft voting model in the final model list to generate our submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus attempt - an ensemble model with only the top five models\n",
    "\n",
    "We want to see if we could improve our voting score by combining only the top five models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11                 XGBClassifier\n",
       "10                           SVC\n",
       "1              BaggingClassifier\n",
       "4         RandomForestClassifier\n",
       "0             AdaBoostClassifier\n",
       "2           ExtraTreesClassifier\n",
       "6           LogisticRegressionCV\n",
       "3     GradientBoostingClassifier\n",
       "9           KNeighborsClassifier\n",
       "5      GaussianProcessClassifier\n",
       "8                     GaussianNB\n",
       "7                    BernoulliNB\n",
       "Name: Alg Name, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_compare.sort_values(by='Best Score', ascending=False)['Alg Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AdaBoostClassifier'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_algs[0][1].__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_algs (sorted_score_df, algs, num_algs):\n",
    "    top_alg_ls = []\n",
    "    \n",
    "    for alg_name in sorted_score_df:\n",
    "        for alg in algs:\n",
    "            if alg[1].__class__.__name__ == alg_name:\n",
    "                top_alg_ls.append(alg)\n",
    "        \n",
    "    return top_alg_ls[:num_algs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_alg_names = hp_compare.sort_values(by='Best Score', ascending=False)['Alg Name']\n",
    "top_five_algs = top_algs(sorted_alg_names, tuned_algs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting w/Tuned Hyperparameters Training w/bin score mean: 86.48\n",
      "Hard Voting w/Tuned Hyperparameters Test w/bin score mean: 82.94\n",
      "Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 6.01\n",
      "----------\n",
      "Soft Voting w/Tuned Hyperparameters Training w/bin score mean: 87.94\n",
      "Soft Voting w/Tuned Hyperparameters Test w/bin score mean: 82.61\n",
      "Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 7.70\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "vc_hard_tfive, vc_soft_tfive = en_alg(top_five_algs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "While significant imporvments are acheived on the training score for both hard and soft voting, a slight decrease on the test scores are observed. However, juding from the degree of imporvement observed on training score, we hypothesized that the top five approach might result more accurate models\n",
    "\n",
    "#### Action Plan\n",
    "We will using the top five approach to generate our submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_submissions(top_five, b_vc_hard, b_vc_soft, X_tr, y_tr, X_test, tag):\n",
    "    \n",
    "    #create submissions for each alg in the top_five list\n",
    "    for alg in top_five:\n",
    "        alg[1].fit(X_tr, y_tr)\n",
    "        y_pred = alg[1].predict(X_test).astype(int)\n",
    "        final_data = {'PassengerId': test_raw.PassengerId, 'Survived': y_pred}\n",
    "        submission = pd.DataFrame(data=final_data)\n",
    "        submission.to_csv('submissions/submission_'+tag+'_'+alg[0]+'.csv', index =False)\n",
    "        \n",
    "    #create submissions best hard and soft vc\n",
    "    #they are already fitted in the evaluation steps\n",
    "    y_pred_b_vc_hard = b_vc_hard.predict(X_test).astype(int)\n",
    "    y_pred_b_vc_soft = b_vc_soft.predict(X_test) .astype(int)\n",
    "    vc_hard_sub_data = {'PassengerId': test_raw.PassengerId, 'Survived': y_pred_b_vc_hard}\n",
    "    vc_soft_sub_data = {'PassengerId': test_raw.PassengerId, 'Survived': y_pred_b_vc_soft}\n",
    "    vc_hard_sub = pd.DataFrame(data=vc_hard_sub_data)\n",
    "    vc_soft_sub = pd.DataFrame(data=vc_soft_sub_data)\n",
    "    vc_hard_sub.to_csv('submissions/submission_'+tag+'_vc_hard.csv', index =False) \n",
    "    vc_soft_sub.to_csv('submissions/submission_'+tag+'vc_soft.csv', index =False) \n",
    "    \n",
    "    print('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after some debugging, we found that Ticket_len_10 is missing from the X_test, as it was auto generated in X_train, need to improve the process in the next project\n",
    "X_test.insert(17, \"Ticket_len_10\", 0, allow_duplicates = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "gen_submissions(top_five_algs, vc_hard_all, vc_soft_all, X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 1 - Post submission conclusion\n",
    "We obtained the highest score from the Soft Voting model (with top five models included), with a score of 0.78229. This put us into the top 23% in the competion. While it is a satisfactory result, it is still less than expected. Specifically, it is 0.05 less then our validation score of 0.8317. \n",
    "\n",
    "### Plan for improvement\n",
    "We might be able to tune the model to a more accurate state with the following techniques:\n",
    "- evaluate the causation effect of each engineered features\n",
    "- employ other feature engineering technique to generate more relavent features for better trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 2\n",
    "We are not satisfy with the results we got from the first attempt, we want to try some advance feature engineering techniques\n",
    "\n",
    "### Objective\n",
    "Evaluate the effect on model accuracy for each feature engineering step taken in our last attempt, and try new feature engineering techniques \n",
    "\n",
    "### Action Plan\n",
    "- create a base model\n",
    "- evaluate each new feature created in iteration 1\n",
    "    - Agebin\n",
    "    - Farebin\n",
    "    - FamilySize\n",
    "    - IsAlone\n",
    "- Try new techniques\n",
    "    - Interactions\n",
    "    - normalizing continouse features\n",
    "    - Target Encoding\n",
    "    - CatBoost Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a base model, the best result we got from single model approach was XGB, we will use it as our base model in this experiment\n",
    "xgb = XGBClassifier(n_estimators=500)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Ticket      0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "(891, 10)\n"
     ]
    }
   ],
   "source": [
    "#prepare data for baseline evaluation \n",
    "train_i2 = train_raw.copy()\n",
    "train_i2 = data_clean(train_i2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the base model\n",
    "\n",
    "We are going to borrow all the handy functions we created in the previous attempt with small tweaks to build out our base model to evalue each engineered feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_f_eng (clean_data):\n",
    "    \n",
    "    #next we work on text data\n",
    "    #extrat title from Name\n",
    "    clean_data['Title'] = clean_data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    \n",
    "    stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "    title_names = (clean_data['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n",
    "    #apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n",
    "    clean_data['Title'] = clean_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "    \n",
    "    \n",
    "    #do imputation on txt data\n",
    "    OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    imp_cols = OH_en.fit_transform(clean_data[['Sex','Embarked', 'Title']])\n",
    "    imp_cols = pd.DataFrame(imp_cols)\n",
    "    #now we align the index and col names\n",
    "    imp_cols.index = clean_data[['Sex','Embarked', 'Title']].index\n",
    "    imp_cols.columns = OH_en.get_feature_names(['Sex','Embarked', 'Title'])\n",
    "    clean_data = clean_data.drop(['Sex','Embarked', 'Title'], axis=1).join(imp_cols)\n",
    "    \n",
    "    clean_data = clean_data.drop('Ticket', axis=1)\n",
    "    clean_data = clean_data.drop('Name', axis=1)\n",
    "\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score (X, y):\n",
    "    cv_agebin_results = model_selection.cross_validate(xgb, X, y, cv = 5, scoring='accuracy', return_train_score=True)\n",
    "    return cv_agebin_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xysplit (df):\n",
    "    X = df.drop('Survived', axis=1)\n",
    "    y = df['Survived']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_i2_base = base_f_eng (train_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base = train_i2_base.drop('Survived', axis=1)\n",
    "y_base = train_i2_base['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8238130752429171\n"
     ]
    }
   ],
   "source": [
    "score (X_base, y_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "\n",
    "Accuracy score we got from our base model (xgb) is 0.82381, which is pretty close to the score we got from the Soft Voting model in the previous effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_bin (clean_data):\n",
    "    AgeBin = pd.cut(clean_data['Age'].astype(int), 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    AgeBin.name = 'AgeBin'\n",
    "    train_i2_agebin = train_i2_base.join(AgeBin)\n",
    "    train_i2_agebin = train_i2_agebin.drop('Age', axis =1)\n",
    "    \n",
    "    X, y = xysplit(train_i2_agebin)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8305672024163527\n"
     ]
    }
   ],
   "source": [
    "X_agebin, y_agebin = age_bin (train_i2)\n",
    "score (X_agebin, y_agebin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "Converting Age data to Agebin improve prediction result by roughtly, 0.07%. base score: 0.8238130752429171 vs imporved score 0.8305672024163527\n",
    "\n",
    "#### Action to take\n",
    "Add AgeBin and drop Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_bin (clean_data):\n",
    "    FareBin = pd.cut(clean_data['Fare'].astype(int), 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    FareBin.name = 'FareBin'\n",
    "    train_i2_agebin = train_i2_base.join(FareBin)\n",
    "    train_i2_agebin = train_i2_agebin.drop('Fare', axis =1)\n",
    "    \n",
    "    X, y = xysplit(train_i2_agebin)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8283140180446253\n"
     ]
    }
   ],
   "source": [
    "X_farebin, y_farebin = fare_bin (train_i2)\n",
    "score (X_farebin, y_farebin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "The FareBin feature imporve score by 0.05, base score: 0.8238130752429171 vs imporved score 0.8283140180446253\n",
    "\n",
    "#### Action\n",
    "Generate FareBin and drop Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have all Fare values plus one to remove zeros\n",
    "fare_po = train_i2['Fare']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_fare = stats.boxcox(fare_po)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xd7c9ec8>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_i2['Fare'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_fare = pd.Series(boxcox_fare[0], index=train_i2['Fare'].index, name='boxcox_fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10bf06c8>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxcox_fare.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_fare = np.sqrt(train_i2['Fare'])\n",
    "sqrt_fare.name = 'sqrt_fare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fare = np.log(train_i2['Fare'])\n",
    "log_fare.name = 'log_fare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x109c3888>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAD+dJREFUeJzt3V+MXGd9xvHvU0JRlUX5o5CVcdwurVxEwGpKVlEkqmotVAjhwuEiVaIIHKA1FwGBmosaboiEIuWiQItKI5kmihF/tlEDjZWkLanFKkWCgo2iOMGKsMANdixHlMjJQkXl8OvFHms2ya53PTvj2X3n+5FWc+ad95zz7k/jZ47fOedsqgpJUrt+a9QDkCQNl0EvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJatwFox4AwGWXXVZTU1N9rfvLX/6SCy+8cLAD2sCsR4+16LEWPS3V4uDBgz+vqjes1G9dBP3U1BQHDhzoa925uTlmZmYGO6ANzHr0WIsea9HTUi2S/Pdq+jl1I0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS41YM+iRbknw7yeEkTyX5eNd+R5LjSR7vfq5ftM4nkxxJ8nSSdw/zF5Aknd1qLpg6DdxeVT9M8nrgYJJHu9c+X1V/s7hzkiuBm4C3Am8E/iPJH1bVS4McuCRpdVYM+qo6AZzoll9MchjYfJZVdgCzVfVr4KdJjgDXAN8dwHg3hKndDy/ZfvSu957nkUgSpKpW3zmZAh4D3gb8FXAr8AJwgIWj/ueT/D3wvar6SrfOPcC/VtU/v2Jbu4BdAJOTk1fPzs729QvMz88zMTHR17rDcuj4qSXbt22+aOj7Xo/1GBVr0WMtelqqxfbt2w9W1fRK/VZ9r5skE8ADwCeq6oUkdwOfAap7/CzwISBLrP6qT5Oq2gPsAZienq5+7z2xHu9bcetyR/S3zAx93+uxHqNiLXqsRc841mJVZ90keS0LIf/VqvoGQFWdrKqXquo3wJdYmJ4BOAZsWbT6FcCzgxuyJOlcrOasmwD3AIer6nOL2jct6vY+4MlueR9wU5LXJXkTsBX4/uCGLEk6F6uZunkH8H7gUJLHu7ZPATcnuYqFaZmjwEcAquqpJPcDP2LhjJ3bPONGkkZnNWfdfIel590fOcs6dwJ3rmFckqQB8cpYSWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuNWDPokW5J8O8nhJE8l+XjXfmmSR5P8uHu8pGtPki8kOZLkiSRvH/YvIUla3mqO6E8Dt1fVW4BrgduSXAnsBvZX1VZgf/cc4D3A1u5nF3D3wEctSVq1FYO+qk5U1Q+75ReBw8BmYAewt+u2F7ihW94BfLkWfA+4OMmmgY9ckrQqqarVd06mgMeAtwHPVNXFi157vqouSfIQcFdVfadr3w/8dVUdeMW2drFwxM/k5OTVs7Ozff0C8/PzTExM9LXusBw6fmrJ9m2bLxr6vtdjPUbFWvRYi56WarF9+/aDVTW9Ur8LVrvBJBPAA8AnquqFJMt2XaLtVZ8mVbUH2AMwPT1dMzMzqx3Ky8zNzdHvusNy6+6Hl2w/esvM0Pe9HusxKtaix1r0jGMtVnXWTZLXshDyX62qb3TNJ89MyXSPz3Xtx4Ati1a/Anh2MMOVJJ2r1Zx1E+Ae4HBVfW7RS/uAnd3yTuDBRe0f6M6+uRY4VVUnBjhmSdI5WM3UzTuA9wOHkjzetX0KuAu4P8mHgWeAG7vXHgGuB44AvwI+ONARS5LOyYpB332putyE/DuX6F/AbWsclyRpQLwyVpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4FYM+yb1Jnkvy5KK2O5IcT/J493P9otc+meRIkqeTvHtYA5ckrc5qjujvA65bov3zVXVV9/MIQJIrgZuAt3br/EOS1wxqsJKkc7di0FfVY8AvVrm9HcBsVf26qn4KHAGuWcP4JElrtJY5+o8meaKb2rmka9sM/GxRn2NdmyRpRFJVK3dKpoCHqupt3fNJ4OdAAZ8BNlXVh5J8EfhuVX2l63cP8EhVPbDENncBuwAmJyevnp2d7esXmJ+fZ2Jioq91h+XQ8VNLtm/bfNHQ970e6zEq1qLHWvS0VIvt27cfrKrplfpd0M/Gq+rkmeUkXwIe6p4eA7Ys6noF8Owy29gD7AGYnp6umZmZfobC3Nwc/a47LLfufnjJ9qO3zAx93+uxHqNiLXqsRc841qKvqZskmxY9fR9w5oycfcBNSV6X5E3AVuD7axuiJGktVjyiT/J1YAa4LMkx4NPATJKrWJi6OQp8BKCqnkpyP/Aj4DRwW1W9NJyhS5JWY8Wgr6qbl2i+5yz97wTuXMugJEmD45WxktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMatGPRJ7k3yXJInF7VdmuTRJD/uHi/p2pPkC0mOJHkiyduHOXhJ0spWc0R/H3DdK9p2A/uraiuwv3sO8B5ga/ezC7h7MMOUJPVrxaCvqseAX7yieQewt1veC9ywqP3LteB7wMVJNg1qsJKkc9fvHP1kVZ0A6B4v79o3Az9b1O9Y1yZJGpELBry9LNFWS3ZMdrEwvcPk5CRzc3N97XB+fr7vdYfl9m2nl2w/H+Ncj/UYFWvRYy16xrEW/Qb9ySSbqupENzXzXNd+DNiyqN8VwLNLbaCq9gB7AKanp2tmZqavgczNzdHvusNy6+6Hl2w/esvM0Pe9HusxKtaix1r0jGMt+p262Qfs7JZ3Ag8uav9Ad/bNtcCpM1M8kqTRWPGIPsnXgRngsiTHgE8DdwH3J/kw8AxwY9f9EeB64AjwK+CDQxizJOkcrBj0VXXzMi+9c4m+Bdy21kFJkgbHK2MlqXGDPutGZzG13Je0d733PI9E0jgx6Bsytfthbt92+lVn/fhBIo03p24kqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxvk3Y9dguT/2LUnriUG/Diz3geEf9ZY0CE7dSFLjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhq3pgumkhwFXgReAk5X1XSSS4F/AqaAo8CfV9XzaxumJKlfgzii315VV1XVdPd8N7C/qrYC+7vnkqQRGcbUzQ5gb7e8F7hhCPuQJK3SWoO+gG8lOZhkV9c2WVUnALrHy9e4D0nSGqSq+l85eWNVPZvkcuBR4GPAvqq6eFGf56vqkiXW3QXsApicnLx6dna2rzHMz88zMTHR17prdej4qaFuf9vmi86p/6Hjp5j8HTj5v2vbTitG+d5Yb6xFT0u12L59+8FF0+bLWlPQv2xDyR3APPCXwExVnUiyCZirqjefbd3p6ek6cOBAX/udm5tjZmamr3XXati3KT7Xu1dO7X6Y27ed5rOHXv4d+7jeBXOU7431xlr0tFSLJKsK+r6nbpJcmOT1Z5aBdwFPAvuAnV23ncCD/e5DkrR2azm9chL4ZpIz2/laVf1bkh8A9yf5MPAMcOPahylJ6lffQV9VPwH+aIn2/wHeuZZBSZIGx78wNQbO9l3CuM7fS+PEWyBIUuMMeklqnEEvSY0z6CWpcX4ZuwEN+0ItSW3xiF6SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOC+Y0kAsdxGXd8eURs+gX8fOxxWwBrTUPoNe64ofPNLgOUcvSY3ziF7nxBuqSRuPR/SS1DiP6DUS/s9AOn88opekxhn0ktS4DT91c+j4KW71lLzmedql1D+P6CWpcQa9JDXOoJekxhn0ktS4Df9lrHQuznb+vl/sqlUe0UtS4zyi11C1cAXsuZ7a6amgWm8Mekkv4/RWe4YW9EmuA/4OeA3wj1V117D2Jcn/SWh5Qwn6JK8Bvgj8GXAM+EGSfVX1o2HsT4O3UaZcBhluG+V3PldTux/m9m2nX3UFuR8A59coP4iHdUR/DXCkqn4CkGQW2AFsyKBvNQBatly4DXofg+g/qsD1fT0+hnXWzWbgZ4ueH+vaJEnnWapq8BtNbgTeXVV/0T1/P3BNVX1sUZ9dwK7u6ZuBp/vc3WXAz9cw3NZYjx5r0WMtelqqxe9V1RtW6jSsqZtjwJZFz68Anl3coar2AHvWuqMkB6pqeq3baYX16LEWPdaiZxxrMaypmx8AW5O8KclvAzcB+4a0L0nSWQzliL6qTif5KPDvLJxeeW9VPTWMfUmSzm5o59FX1SPAI8Pa/iJrnv5pjPXosRY91qJn7GoxlC9jJUnrhzc1k6TGbeigT3JdkqeTHEmye9TjGaUkR5McSvJ4kgOjHs/5luTeJM8leXJR26VJHk3y4+7xklGO8XxZphZ3JDnevT8eT3L9KMd4viTZkuTbSQ4neSrJx7v2sXpvbNigX3SbhfcAVwI3J7lytKMaue1VddW4nTrWuQ+47hVtu4H9VbUV2N89Hwf38epaAHy+e39c1X2HNg5OA7dX1VuAa4HbupwYq/fGhg16Ft1moar+DzhzmwWNoap6DPjFK5p3AHu75b3ADed1UCOyTC3GUlWdqKofdssvAodZuEp/rN4bGznovc3CyxXwrSQHu6uOBZNVdQIW/sEDl494PKP20SRPdFM7TU9VLCXJFPDHwH8xZu+NjRz0WaJtnE8hekdVvZ2FqazbkvzpqAekdeVu4A+Aq4ATwGdHO5zzK8kE8ADwiap6YdTjOd82ctCveJuFcVJVz3aPzwHfZGFqa9ydTLIJoHt8bsTjGZmqOllVL1XVb4AvMUbvjySvZSHkv1pV3+iax+q9sZGD3tssdJJcmOT1Z5aBdwFPnn2tsbAP2Nkt7wQeHOFYRupMqHXex5i8P5IEuAc4XFWfW/TSWL03NvQFU90pYn9L7zYLd454SCOR5PdZOIqHhaudvzZutUjydWCGhTsTngQ+DfwLcD/wu8AzwI1V1fyXlMvUYoaFaZsCjgIfOTNH3bIkfwL8J3AI+E3X/CkW5unH5r2xoYNekrSyjTx1I0laBYNekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TG/T8sPLZ1i5+HsgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sqrt_fare.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x106ad548>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_fare.hist(range=(0, 8), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_val (base_df, nor_fare):\n",
    "    \n",
    "    train_i2_nor_fare = base_df.join(nor_fare)\n",
    "    train_i2_nor_fare_final = train_i2_nor_fare.drop('Fare', axis=1)\n",
    "    X, y = xysplit(train_i2_nor_fare_final)\n",
    "    score (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8249556438128127\n"
     ]
    }
   ],
   "source": [
    "fare_val(train_i2_base, log_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8238130752429171\n"
     ]
    }
   ],
   "source": [
    "fare_val(train_i2_base, sqrt_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8238130752429171\n"
     ]
    }
   ],
   "source": [
    "fare_val(train_i2_base, boxcox_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what if we include both Farebin and nor_fare in the data\n",
    "def fare_w_fbin_val (base_df, nor_fare):\n",
    "    \n",
    "    train_i2_nor_fare = base_df.join(nor_fare)\n",
    "    train_i2_nor_fare_final = train_i2_nor_fare.drop('Fare', axis=1)\n",
    "    train_i2_nor_fare_final['FareBin'] = X_farebin['FareBin']\n",
    "    X, y = xysplit(train_i2_nor_fare_final)\n",
    "    score (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8249556438128127\n"
     ]
    }
   ],
   "source": [
    "fare_w_fbin_val(train_i2_base, log_fare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obervation\n",
    "Only Boxcox showed improvement on the result, and including FareBin with Boxcox did not improve the result. Comparing having just the FareBin, the score decreased.\n",
    "\n",
    "#### Action to take\n",
    "Not to include the normalized Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
       "0         0       3  22.0      1      0   7.2500         0.0       1.0   \n",
       "1         1       1  38.0      1      0  71.2833         1.0       0.0   \n",
       "2         1       3  26.0      0      0   7.9250         1.0       0.0   \n",
       "3         1       1  35.0      1      0  53.1000         1.0       0.0   \n",
       "4         0       3  35.0      0      0   8.0500         0.0       1.0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Misc  Title_Miss  \\\n",
       "0         0.0         0.0         1.0           0.0         0.0         0.0   \n",
       "1         1.0         0.0         0.0           0.0         0.0         0.0   \n",
       "2         0.0         0.0         1.0           0.0         0.0         1.0   \n",
       "3         0.0         0.0         1.0           0.0         0.0         0.0   \n",
       "4         0.0         0.0         1.0           0.0         0.0         0.0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  \n",
       "0       1.0        0.0  \n",
       "1       0.0        1.0  \n",
       "2       0.0        0.0  \n",
       "3       0.0        1.0  \n",
       "4       1.0        0.0  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_i2_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
       "0         0       3  22.0      1      0   7.2500         0.0       1.0   \n",
       "1         1       1  38.0      1      0  71.2833         1.0       0.0   \n",
       "2         1       3  26.0      0      0   7.9250         1.0       0.0   \n",
       "3         1       1  35.0      1      0  53.1000         1.0       0.0   \n",
       "4         0       3  35.0      0      0   8.0500         0.0       1.0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Misc  Title_Miss  \\\n",
       "0         0.0         0.0         1.0           0.0         0.0         0.0   \n",
       "1         1.0         0.0         0.0           0.0         0.0         0.0   \n",
       "2         0.0         0.0         1.0           0.0         0.0         1.0   \n",
       "3         0.0         0.0         1.0           0.0         0.0         0.0   \n",
       "4         0.0         0.0         1.0           0.0         0.0         0.0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  FamilySize  \n",
       "0       1.0        0.0           2  \n",
       "1       0.0        1.0           2  \n",
       "2       0.0        0.0           1  \n",
       "3       0.0        1.0           2  \n",
       "4       1.0        0.0           1  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FamilySize evaluation\n",
    "train_i2_fz = train_i2_base.copy()\n",
    "train_i2_fz['FamilySize'] = train_i2_fz['SibSp']+train_i2_fz['Parch']+1\n",
    "train_i2_fz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8361728385867444\n"
     ]
    }
   ],
   "source": [
    "X_fz, y_fz = xysplit(train_i2_fz)\n",
    "score (X_fz, y_fz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8384009856063596\n"
     ]
    }
   ],
   "source": [
    "train_i2_fz_noraw = train_i2_fz.drop(['SibSp', 'Parch'], axis=1)\n",
    "X_fz_nr, y_fz_nr = xysplit(train_i2_fz_noraw)\n",
    "score (X_fz_nr, y_fz_nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation \n",
    "Engineering the FamilySize feature improves the model, base score: 0.8238130752429171 vs imporved score 0.8361728385867444. And removing the original features further imporved the result by 0.002 \n",
    "\n",
    "#### Action\n",
    "Add the FamilySize feature in our final modeling, and remove the raw data ['SibSp', 'Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_i2_fz_isAlone = train_i2_fz_noraw.copy()\n",
    "train_i2_fz_isAlone['IsAlone'] = train_i2_fz_isAlone['FamilySize'] == 1\n",
    "train_i2_fz_isAlone['IsAlone'] = train_i2_fz_isAlone['IsAlone'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8384009856063596\n"
     ]
    }
   ],
   "source": [
    "X_fz_ia, y_fz_ia = xysplit(train_i2_fz_isAlone)\n",
    "score (X_fz_ia, y_fz_ia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "Adding the IsAlone does not improve the result\n",
    "\n",
    "#### Action\n",
    "Not to add this new feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try Ticketlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticket_len (df):\n",
    "    #making sure we are not massing with the raw data\n",
    "    clean_data = df.copy()\n",
    "    #cat tickets by length\n",
    "    Ticket_len = clean_data.Ticket.apply(len)\n",
    "    stat_min_ti = 30\n",
    "    Ticket_len_ls = (Ticket_len.value_counts() < stat_min_ti)\n",
    "    Ticket_len = Ticket_len.apply(lambda x: '30' if Ticket_len_ls.loc[x] == True else x)\n",
    "    Ticket_len = Ticket_len.astype(str)\n",
    "    \n",
    "    \n",
    "    #do imputation on txt data\n",
    "    OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    imp_cols = OH_en.fit_transform(pd.DataFrame(Ticket_len))\n",
    "    imp_cols = pd.DataFrame(imp_cols)\n",
    "    #now we align the index and col names\n",
    "    imp_cols.index = Ticket_len.index\n",
    "    imp_cols.columns = OH_en.get_feature_names(['Ticket_len'])\n",
    "        \n",
    "\n",
    "    return imp_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ticket_len = ticket_len (train_i2)\n",
    "train_i2_tl = train_i2_base.copy()\n",
    "train_i2_tl = train_i2_tl.join(Ticket_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8451384093904964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8451384093904964"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fz_tl, y_fz_tl = xysplit(train_i2_tl)\n",
    "score (X_fz_tl, y_fz_tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "Engineering the Ticket_len feature improves the result by 0.02, base score: 0.8238130752429171 vs imporved score 0.8440442841959339.\n",
    "\n",
    "#### Action\n",
    "Add Ticket_len feature to the final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Techniques\n",
    "The plan is to evaluate\n",
    "- Interation\n",
    "- Target Encoding - we did not implement this, as the data is relatively small, onehot is better suited\n",
    "- CatBoost Encoding - we did not implement this, as the data is relatively small, onehot is better suited\n",
    "\n",
    "### Interactions\n",
    "We want to combine corrolating categorical features to create new features with stronger corrolation with the target, and based on our analysis, we decided to conduct an attempt with Pclass_Sex_Embarked combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Embarked Title  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500        S    Mr  \n",
       "1  female  38.0      1      0          PC 17599  71.2833        C   Mrs  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250        S  Miss  \n",
       "3  female  35.0      1      0            113803  53.1000        S   Mrs  \n",
       "4    male  35.0      0      0            373450   8.0500        S    Mr  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_i2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactions (df):\n",
    "    \n",
    "    PSE = df.Pclass.astype(str) + df.Sex + df.Embarked\n",
    "    \n",
    "    #do imputation on txt data\n",
    "    OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    imp_cols = OH_en.fit_transform(pd.DataFrame(PSE))\n",
    "    imp_cols = pd.DataFrame(imp_cols)\n",
    "    #now we align the index and col names\n",
    "    imp_cols.index = PSE.index\n",
    "    imp_cols.columns = OH_en.get_feature_names(['Pclass_Sex_Embarked'])\n",
    "    \n",
    "    return imp_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pse = interactions(train_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8327788588286987"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_i2_pse = train_i2_base.copy()\n",
    "train_i2_pse = train_i2_pse.join(pse)\n",
    "X_pse, y_pse = xysplit(train_i2_pse)\n",
    "score (X_pse, y_pse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.840606364948842"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_i2_pse_noraw = train_i2_pse.drop(['Pclass', 'Sex_male','Sex_female','Embarked_C','Embarked_Q','Embarked_S'], axis=1)\n",
    "X_pse_nr, y_pse_nr = xysplit(train_i2_pse_noraw)\n",
    "score (X_pse_nr, y_pse_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female',\n",
       "       'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Title_Master',\n",
       "       'Title_Misc', 'Title_Miss', 'Title_Mr', 'Title_Mrs',\n",
       "       'Pclass_Sex_Embarked_1femaleC', 'Pclass_Sex_Embarked_1femaleQ',\n",
       "       'Pclass_Sex_Embarked_1femaleS', 'Pclass_Sex_Embarked_1maleC',\n",
       "       'Pclass_Sex_Embarked_1maleQ', 'Pclass_Sex_Embarked_1maleS',\n",
       "       'Pclass_Sex_Embarked_2femaleC', 'Pclass_Sex_Embarked_2femaleQ',\n",
       "       'Pclass_Sex_Embarked_2femaleS', 'Pclass_Sex_Embarked_2maleC',\n",
       "       'Pclass_Sex_Embarked_2maleQ', 'Pclass_Sex_Embarked_2maleS',\n",
       "       'Pclass_Sex_Embarked_3femaleC', 'Pclass_Sex_Embarked_3femaleQ',\n",
       "       'Pclass_Sex_Embarked_3femaleS', 'Pclass_Sex_Embarked_3maleC',\n",
       "       'Pclass_Sex_Embarked_3maleQ', 'Pclass_Sex_Embarked_3maleS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_i2_pse.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Age', 'SibSp', 'Parch', 'Fare', 'Title_Master',\n",
       "       'Title_Misc', 'Title_Miss', 'Title_Mr', 'Title_Mrs',\n",
       "       'Pclass_Sex_Embarked_1femaleC', 'Pclass_Sex_Embarked_1femaleQ',\n",
       "       'Pclass_Sex_Embarked_1femaleS', 'Pclass_Sex_Embarked_1maleC',\n",
       "       'Pclass_Sex_Embarked_1maleQ', 'Pclass_Sex_Embarked_1maleS',\n",
       "       'Pclass_Sex_Embarked_2femaleC', 'Pclass_Sex_Embarked_2femaleQ',\n",
       "       'Pclass_Sex_Embarked_2femaleS', 'Pclass_Sex_Embarked_2maleC',\n",
       "       'Pclass_Sex_Embarked_2maleQ', 'Pclass_Sex_Embarked_2maleS',\n",
       "       'Pclass_Sex_Embarked_3femaleC', 'Pclass_Sex_Embarked_3femaleQ',\n",
       "       'Pclass_Sex_Embarked_3femaleS', 'Pclass_Sex_Embarked_3maleC',\n",
       "       'Pclass_Sex_Embarked_3maleQ', 'Pclass_Sex_Embarked_3maleS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_i2_pse_noraw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "We got a ~0.02 improvement on the score by engineering the Pclass_Sex_Embarked feature in our data, with the raw features removed\n",
    "\n",
    "#### Action Plan\n",
    "Include Pclass_Sex_Embarked in our final data set and remove the raw features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our hypothesis\n",
    "We are going to aggregate our finds to a feature engineering function and test the model using cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_eng_i2 (clean_data):\n",
    "    #let's start with num cols\n",
    "    #create value bins for continuouse values\n",
    "    clean_data['FareBin'] = pd.qcut(clean_data['Fare'], 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    clean_data['AgeBin'] = pd.cut(clean_data['Age'].astype(int), 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    #now we drop the original features\n",
    "    clean_data = clean_data.drop(['Fare', 'Age'], axis=1)\n",
    "    \n",
    "    #create new features\n",
    "    FamilySize = clean_data['SibSp']+clean_data['Parch']+1\n",
    "    clean_data['FamilySize'] = FamilySize\n",
    "    \n",
    "    #next we work on text data\n",
    "    #extrat title from Name\n",
    "    clean_data['Title'] = clean_data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    \n",
    "    stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "    title_names = (clean_data['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n",
    "    #apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n",
    "    clean_data['Title'] = clean_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "    \n",
    "    #cat tickets by length\n",
    "    Ticket_len = clean_data.Ticket.apply(len)\n",
    "    stat_min_ti = 30\n",
    "    Ticket_len_ls = (Ticket_len.value_counts() < stat_min_ti)\n",
    "    Ticket_len = Ticket_len.apply(lambda x: '30' if Ticket_len_ls.loc[x] == True else x)\n",
    "    Ticket_len.value_counts()\n",
    "    clean_data['Ticket_len'] = Ticket_len\n",
    "    #imputer only works on str or numbers\n",
    "    clean_data['Ticket_len'] = clean_data['Ticket_len'].astype(str)\n",
    "    clean_data = clean_data.drop(['Name', 'Ticket'], axis=1)\n",
    "    \n",
    "    #adding Pclass_Sex_Embarked\n",
    "    PSE = clean_data.Pclass.astype(str) + clean_data.Sex + clean_data.Embarked\n",
    "    clean_data['Pclass_Sex_Embarked'] = PSE\n",
    "    \n",
    "    \n",
    "    #do imputation on txt data\n",
    "    OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    imp_cols = OH_en.fit_transform(clean_data[['Title', 'Ticket_len', 'Pclass_Sex_Embarked']])\n",
    "    imp_cols = pd.DataFrame(imp_cols)\n",
    "    #now we align the index and col names\n",
    "    imp_cols.index = clean_data[['Title', 'Ticket_len', 'Pclass_Sex_Embarked']].index\n",
    "    imp_cols.columns = OH_en.get_feature_names(['Title', 'Ticket_len', 'Pclass_Sex_Embarked'])\n",
    "    clean_data = clean_data.drop(['Sex','Embarked', 'Title', 'Ticket_len', 'SibSp', 'Parch', 'Pclass', 'Pclass_Sex_Embarked'], axis=1).join(imp_cols)\n",
    "\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_i2_af = f_eng_i2(train_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'FareBin', 'AgeBin', 'FamilySize', 'Title_Master',\n",
       "       'Title_Misc', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Ticket_len_10',\n",
       "       'Ticket_len_30', 'Ticket_len_4', 'Ticket_len_5', 'Ticket_len_6',\n",
       "       'Ticket_len_8', 'Pclass_Sex_Embarked_1femaleC',\n",
       "       'Pclass_Sex_Embarked_1femaleQ', 'Pclass_Sex_Embarked_1femaleS',\n",
       "       'Pclass_Sex_Embarked_1maleC', 'Pclass_Sex_Embarked_1maleQ',\n",
       "       'Pclass_Sex_Embarked_1maleS', 'Pclass_Sex_Embarked_2femaleC',\n",
       "       'Pclass_Sex_Embarked_2femaleQ', 'Pclass_Sex_Embarked_2femaleS',\n",
       "       'Pclass_Sex_Embarked_2maleC', 'Pclass_Sex_Embarked_2maleQ',\n",
       "       'Pclass_Sex_Embarked_2maleS', 'Pclass_Sex_Embarked_3femaleC',\n",
       "       'Pclass_Sex_Embarked_3femaleQ', 'Pclass_Sex_Embarked_3femaleS',\n",
       "       'Pclass_Sex_Embarked_3maleC', 'Pclass_Sex_Embarked_3maleQ',\n",
       "       'Pclass_Sex_Embarked_3maleS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_i2_af.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8159625886636119\n"
     ]
    }
   ],
   "source": [
    "X_af, y_af = xysplit(train_i2_af)\n",
    "score (X_af, y_af)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "The result is surprisingly bad, even worse than the original prediction score by 0.005. \n",
    "\n",
    "#### Action\n",
    "We hypothesized that we that keeping all the features and use feature selection to craft the optimal dataset for the training would yeild a better score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a feature engineering function that retains all features\n",
    "def f_eng_all (clean_data):\n",
    "    #let's start with num cols\n",
    "    #create value bins for continuouse values\n",
    "    clean_data['FareBin'] = pd.qcut(clean_data['Fare'], 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    clean_data['AgeBin'] = pd.cut(clean_data['Age'].astype(int), 5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "    \n",
    "    #create new features\n",
    "    FamilySize = clean_data['SibSp']+clean_data['Parch']+1\n",
    "    clean_data['FamilySize'] = FamilySize\n",
    "    \n",
    "    #next we work on text data\n",
    "    #extrat title from Name\n",
    "    clean_data['Title'] = clean_data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    \n",
    "    stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "    title_names = (clean_data['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n",
    "    #apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n",
    "    clean_data['Title'] = clean_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "    \n",
    "    #cat tickets by length\n",
    "    Ticket_len = clean_data.Ticket.apply(len)\n",
    "    stat_min_ti = 30\n",
    "    Ticket_len_ls = (Ticket_len.value_counts() < stat_min_ti)\n",
    "    Ticket_len = Ticket_len.apply(lambda x: '30' if Ticket_len_ls.loc[x] == True else x)\n",
    "    Ticket_len.value_counts()\n",
    "    clean_data['Ticket_len'] = Ticket_len\n",
    "    #imputer only works on str or numbers\n",
    "    clean_data['Ticket_len'] = clean_data['Ticket_len'].astype(str)\n",
    "    clean_data = clean_data.drop(['Name', 'Ticket'], axis=1)\n",
    "    \n",
    "    #adding Pclass_Sex_Embarked\n",
    "    PSE = clean_data.Pclass.astype(str) + clean_data.Sex + clean_data.Embarked\n",
    "    clean_data['Pclass_Sex_Embarked'] = PSE\n",
    "    \n",
    "    \n",
    "    #do imputation on txt data\n",
    "    OH_en = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    imp_cols = OH_en.fit_transform(clean_data[['Sex','Embarked','Title', 'Ticket_len', 'Pclass_Sex_Embarked']])\n",
    "    imp_cols = pd.DataFrame(imp_cols)\n",
    "    #now we align the index and col names\n",
    "    imp_cols.index = clean_data[['Sex','Embarked','Title', 'Ticket_len', 'Pclass_Sex_Embarked']].index\n",
    "    imp_cols.columns = OH_en.get_feature_names(['Sex','Embarked','Title', 'Ticket_len', 'Pclass_Sex_Embarked'])\n",
    "    clean_data = clean_data.drop(['Sex','Embarked', 'Title', 'Ticket_len', 'Pclass_Sex_Embarked'], axis=1).join(imp_cols)\n",
    "\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_i2_all = f_eng_all(train_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8496076831335133"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a base score with all features included\n",
    "X_all, y_all = xysplit(train_i2_all)\n",
    "score (X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_class (X, y, kc):\n",
    "    \n",
    "    #borrowed from https://www.kaggle.com/matleonard/feature-selection\n",
    "    # Keep 5 features\n",
    "    selector = feature_selection.SelectKBest(feature_selection.f_classif, k=kc)\n",
    "\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "\n",
    "    # Get back the features we've kept, zero out all other features\n",
    "    selected_features = pd.DataFrame(selector.inverse_transform(X_new), \n",
    "                                     index=X.index, \n",
    "                                     columns=X.columns)\n",
    "\n",
    "    # Dropped columns have values of all 0s, so var is 0, drop them\n",
    "    selected_columns = selected_features.columns[selected_features.var() != 0]\n",
    "    selected_columns = selected_columns.insert(0, 'Survived')\n",
    "\n",
    "    return selected_columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kc (X, y, kc_ls):\n",
    "    for kc in kc_ls:\n",
    "        k_cols = k_class(X, y, kc)\n",
    "        X_kc, y_kc = xysplit(train_i2_all[k_cols])\n",
    "        auc_score = score (X_kc, y_kc)\n",
    "        print('k value {0} score {1}'.format(kc, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785606678802335\n",
      "k value 5 score 0.785606678802335\n",
      "0.8069612704789405\n",
      "k value 10 score 0.8069612704789405\n",
      "0.8182286108844392\n",
      "k value 15 score 0.8182286108844392\n",
      "0.8126231874960768\n",
      "k value 20 score 0.8126231874960768\n"
     ]
    }
   ],
   "source": [
    "kc_ls = [5, 10, 15, 20]\n",
    "run_kc (X_all, y_all, kc_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "With k=5 we have the worse score, best scoure at 0.8182286108844392 when k=15, however still below the base score\n",
    "\n",
    "#### Action Plan\n",
    "Not going to use k_class for feature selection, going to try the same procedure with L_one feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_one (X, y):\n",
    "\n",
    "    # Set the regularization parameter C=1\n",
    "    logistic = linear_model.LogisticRegression(C=1, penalty=\"l1\", solver='liblinear', random_state=7).fit(X, y)\n",
    "    model = feature_selection.SelectFromModel(logistic, prefit=True)\n",
    "    X_new = model.transform(X)\n",
    "    # Get back the kept features as a DataFrame with dropped columns as all 0s\n",
    "    selected_features = pd.DataFrame(model.inverse_transform(X_new), \n",
    "                                 index=X.index,\n",
    "                                 columns=X.columns)\n",
    "\n",
    "    # Dropped columns have values of all 0s, keep other columns \n",
    "    selected_columns = selected_features.columns[selected_features.var() != 0]\n",
    "    selected_columns = selected_columns.insert(0, 'Survived')\n",
    "    return selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8496265143431045"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_cols = L_one(X_all, y_all)\n",
    "X_lc, y_lc = xysplit(train_i2_all[L_cols])\n",
    "score (X_lc, y_lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "The score obtained from our effort where all features are included (raw and engineered) is slightly better then the base score.\n",
    "\n",
    "#### Action Plan\n",
    "We are going to conduct the same model training process with features selected from L_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_L1_alg = base_model(X_lc, y_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>0.914983</td>\n",
       "      <td>0.844009</td>\n",
       "      <td>0.0621931</td>\n",
       "      <td>0.118161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'cols...</td>\n",
       "      <td>0.890572</td>\n",
       "      <td>0.838403</td>\n",
       "      <td>0.072953</td>\n",
       "      <td>0.0757958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n",
       "      <td>0.845681</td>\n",
       "      <td>0.826056</td>\n",
       "      <td>0.0849041</td>\n",
       "      <td>1.0472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.852134</td>\n",
       "      <td>0.82605</td>\n",
       "      <td>0.0407919</td>\n",
       "      <td>0.0893611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n",
       "      <td>0.841751</td>\n",
       "      <td>0.824926</td>\n",
       "      <td>0.0776612</td>\n",
       "      <td>0.00562201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'n_components': None, 'priors': None, 'shrink...</td>\n",
       "      <td>0.842311</td>\n",
       "      <td>0.823809</td>\n",
       "      <td>0.0791386</td>\n",
       "      <td>0.00678215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.974184</td>\n",
       "      <td>0.813722</td>\n",
       "      <td>0.0547678</td>\n",
       "      <td>0.0281243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.989057</td>\n",
       "      <td>0.810288</td>\n",
       "      <td>0.0668377</td>\n",
       "      <td>0.168745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n",
       "      <td>0.832772</td>\n",
       "      <td>0.806986</td>\n",
       "      <td>0.0939094</td>\n",
       "      <td>0.261306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>0.81005</td>\n",
       "      <td>0.801437</td>\n",
       "      <td>0.147143</td>\n",
       "      <td>0.00239339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>0.812576</td>\n",
       "      <td>0.795788</td>\n",
       "      <td>0.109467</td>\n",
       "      <td>0.089959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.989057</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.034335</td>\n",
       "      <td>0.143823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
       "      <td>0.786478</td>\n",
       "      <td>0.786768</td>\n",
       "      <td>0.0362623</td>\n",
       "      <td>0.00299172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.989057</td>\n",
       "      <td>0.773316</td>\n",
       "      <td>0.0607386</td>\n",
       "      <td>0.00379004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>0.989057</td>\n",
       "      <td>0.76879</td>\n",
       "      <td>0.0540253</td>\n",
       "      <td>0.00259318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n",
       "      <td>0.777766</td>\n",
       "      <td>0.767774</td>\n",
       "      <td>0.175693</td>\n",
       "      <td>0.00438776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.810046</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>0.0696024</td>\n",
       "      <td>0.005585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
       "      <td>0.722238</td>\n",
       "      <td>0.718291</td>\n",
       "      <td>0.217797</td>\n",
       "      <td>0.00299215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
       "      <td>0.967733</td>\n",
       "      <td>0.717199</td>\n",
       "      <td>0.0762903</td>\n",
       "      <td>0.679187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>0.687155</td>\n",
       "      <td>0.675739</td>\n",
       "      <td>0.129356</td>\n",
       "      <td>0.107436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
       "      <td>0.666429</td>\n",
       "      <td>0.663185</td>\n",
       "      <td>0.391831</td>\n",
       "      <td>0.00478759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
       "      <td>0.657937</td>\n",
       "      <td>0.635334</td>\n",
       "      <td>0.160024</td>\n",
       "      <td>0.00498667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "3      GradientBoostingClassifier   \n",
       "21                  XGBClassifier   \n",
       "6            LogisticRegressionCV   \n",
       "0              AdaBoostClassifier   \n",
       "8               RidgeClassifierCV   \n",
       "19     LinearDiscriminantAnalysis   \n",
       "1               BaggingClassifier   \n",
       "4          RandomForestClassifier   \n",
       "15                          NuSVC   \n",
       "12                     GaussianNB   \n",
       "16                      LinearSVC   \n",
       "2            ExtraTreesClassifier   \n",
       "11                    BernoulliNB   \n",
       "17         DecisionTreeClassifier   \n",
       "18            ExtraTreeClassifier   \n",
       "7     PassiveAggressiveClassifier   \n",
       "13           KNeighborsClassifier   \n",
       "10                     Perceptron   \n",
       "5       GaussianProcessClassifier   \n",
       "14                            SVC   \n",
       "9                   SGDClassifier   \n",
       "20  QuadraticDiscriminantAnalysis   \n",
       "\n",
       "                                       MLA Parameters MLA Train Accuracy Mean  \\\n",
       "3   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...                0.914983   \n",
       "21  {'base_score': 0.5, 'booster': 'gbtree', 'cols...                0.890572   \n",
       "6   {'Cs': 10, 'class_weight': None, 'cv': None, '...                0.845681   \n",
       "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...                0.852134   \n",
       "8   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...                0.841751   \n",
       "19  {'n_components': None, 'priors': None, 'shrink...                0.842311   \n",
       "1   {'base_estimator': None, 'bootstrap': True, 'b...                0.974184   \n",
       "4   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...                0.989057   \n",
       "15  {'break_ties': False, 'cache_size': 200, 'clas...                0.832772   \n",
       "12           {'priors': None, 'var_smoothing': 1e-09}                 0.81005   \n",
       "16  {'C': 1.0, 'class_weight': None, 'dual': True,...                0.812576   \n",
       "2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...                0.989057   \n",
       "11  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...                0.786478   \n",
       "17  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...                0.989057   \n",
       "18  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...                0.989057   \n",
       "7   {'C': 1.0, 'average': False, 'class_weight': N...                0.777766   \n",
       "13  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.810046   \n",
       "10  {'alpha': 0.0001, 'class_weight': None, 'early...                0.722238   \n",
       "5   {'copy_X_train': True, 'kernel': None, 'max_it...                0.967733   \n",
       "14  {'C': 1.0, 'break_ties': False, 'cache_size': ...                0.687155   \n",
       "9   {'alpha': 0.0001, 'average': False, 'class_wei...                0.666429   \n",
       "20  {'priors': None, 'reg_param': 0.0, 'store_cova...                0.657937   \n",
       "\n",
       "   MLA Test Accuracy Mean MLA Test Accuracy 3*STD    MLA Time  \n",
       "3                0.844009               0.0621931    0.118161  \n",
       "21               0.838403                0.072953   0.0757958  \n",
       "6                0.826056               0.0849041      1.0472  \n",
       "0                 0.82605               0.0407919   0.0893611  \n",
       "8                0.824926               0.0776612  0.00562201  \n",
       "19               0.823809               0.0791386  0.00678215  \n",
       "1                0.813722               0.0547678   0.0281243  \n",
       "4                0.810288               0.0668377    0.168745  \n",
       "15               0.806986               0.0939094    0.261306  \n",
       "12               0.801437                0.147143  0.00239339  \n",
       "16               0.795788                0.109467    0.089959  \n",
       "2                0.787879                0.034335    0.143823  \n",
       "11               0.786768               0.0362623  0.00299172  \n",
       "17               0.773316               0.0607386  0.00379004  \n",
       "18                0.76879               0.0540253  0.00259318  \n",
       "7                0.767774                0.175693  0.00438776  \n",
       "13                 0.7217               0.0696024    0.005585  \n",
       "10               0.718291                0.217797  0.00299215  \n",
       "5                0.717199               0.0762903    0.679187  \n",
       "14               0.675739                0.129356    0.107436  \n",
       "9                0.663185                0.391831  0.00478759  \n",
       "20               0.635334                0.160024  0.00498667  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_L1_alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "tuned_L1_algs, hp_compare = hp_tune(X_lc, y_lc, base_L1_alg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alg Name</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Score Before Tuning</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.84849</td>\n",
       "      <td>0.838403</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.842872</td>\n",
       "      <td>0.813722</td>\n",
       "      <td>{'max_samples': 0.5, 'n_estimators': 50, 'rand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.83728</td>\n",
       "      <td>0.844009</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 4, 'n_est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.832791</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'n_estim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.83276</td>\n",
       "      <td>0.810288</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.830557</td>\n",
       "      <td>0.826056</td>\n",
       "      <td>{'fit_intercept': False, 'random_state': 0, 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.83055</td>\n",
       "      <td>0.82605</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 300, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.801437</td>\n",
       "      <td>0.801437</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.786768</td>\n",
       "      <td>0.786768</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.737405</td>\n",
       "      <td>0.675739</td>\n",
       "      <td>{'C': 2, 'decision_function_shape': 'ovo', 'ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.730689</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 3, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>0.717199</td>\n",
       "      <td>0.717199</td>\n",
       "      <td>{'max_iter_predict': 10, 'random_state': 0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Alg Name Best Score Score Before Tuning  \\\n",
       "11               XGBClassifier    0.84849            0.838403   \n",
       "1            BaggingClassifier   0.842872            0.813722   \n",
       "3   GradientBoostingClassifier    0.83728            0.844009   \n",
       "2         ExtraTreesClassifier   0.832791            0.787879   \n",
       "4       RandomForestClassifier    0.83276            0.810288   \n",
       "6         LogisticRegressionCV   0.830557            0.826056   \n",
       "0           AdaBoostClassifier    0.83055             0.82605   \n",
       "8                   GaussianNB   0.801437            0.801437   \n",
       "7                  BernoulliNB   0.786768            0.786768   \n",
       "10                         SVC   0.737405            0.675739   \n",
       "9         KNeighborsClassifier   0.730689              0.7217   \n",
       "5    GaussianProcessClassifier   0.717199            0.717199   \n",
       "\n",
       "                                      Best Parameters  \n",
       "11  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...  \n",
       "1   {'max_samples': 0.5, 'n_estimators': 50, 'rand...  \n",
       "3   {'learning_rate': 0.05, 'max_depth': 4, 'n_est...  \n",
       "2   {'criterion': 'gini', 'max_depth': 4, 'n_estim...  \n",
       "4   {'criterion': 'entropy', 'max_depth': 4, 'n_es...  \n",
       "6   {'fit_intercept': False, 'random_state': 0, 's...  \n",
       "0   {'learning_rate': 0.05, 'n_estimators': 300, '...  \n",
       "8                                                  {}  \n",
       "7                                      {'alpha': 0.1}  \n",
       "10  {'C': 2, 'decision_function_shape': 'ovo', 'ga...  \n",
       "9   {'algorithm': 'ball_tree', 'n_neighbors': 3, '...  \n",
       "5         {'max_iter_predict': 10, 'random_state': 0}  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_compare.sort_values(by='Best Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting w/Tuned Hyperparameters Training w/bin score mean: 89.17\n",
      "Hard Voting w/Tuned Hyperparameters Test w/bin score mean: 83.16\n",
      "Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 7.15\n",
      "----------\n",
      "Soft Voting w/Tuned Hyperparameters Training w/bin score mean: 90.63\n",
      "Soft Voting w/Tuned Hyperparameters Test w/bin score mean: 83.39\n",
      "Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 7.85\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "vc_hard_L1, vc_soft_L1 = en_alg(tuned_L1_algs, X_lc, y_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_L1_algs = hp_compare.sort_values(by='Best Score', ascending=False)['Alg Name']\n",
    "top_five_L1_algs = top_algs(sorted_L1_algs, tuned_L1_algs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Ticket      0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "(418, 9)\n"
     ]
    }
   ],
   "source": [
    "X_test_i2_clean = data_clean(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_i2_fe = f_eng_all(X_test_i2_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aligning columns\n",
    "X_test_i2_fe.insert(14, \"Ticket_len_10\", 0, allow_duplicates = False)\n",
    "X_test_i2_lc = X_test_i2_fe[X_lc.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "gen_submissions(top_five_L1_algs, vc_hard_L1, vc_soft_L1, X_lc, y_lc, X_test_i2_lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 2 - Post submission conclusion\n",
    "The best score obtained from this round of submission was 0.78708, which is rougly 0.005 improvement from the best score we obtained from Iteration 1, and this put us into the top 15% in the competition. This score is obtained from the ETC model generated in our Iteration 2 effort.\n",
    "\n",
    "While a slight imporment was able to obtain from this second round of efforts, however, we were expecting more judging from the average 0.85 score obtained in our feature analysis. This could be due to overfitting or features we are using are simply not good enough.\n",
    "\n",
    "### Suggestion for improvment\n",
    "- Attempt other feature engineering techniques (e.g. Target encoding, other feature combinations, etc.)\n",
    "- Try out other models (neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_tuned_L1_algs[2][1].fit(X_lc, y_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0346\n",
       "                \n",
       "                    &plusmn; 0.0078\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Sex_female\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0328\n",
       "                \n",
       "                    &plusmn; 0.0096\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Title_Mr\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.03%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0166\n",
       "                \n",
       "                    &plusmn; 0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Pclass_Sex_Embarked_3femaleS\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0139\n",
       "                \n",
       "                    &plusmn; 0.0018\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Title_Master\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.35%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0088\n",
       "                \n",
       "                    &plusmn; 0.0104\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Pclass\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Fare\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0079\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Title_Mrs\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0013\n",
       "                \n",
       "                    &plusmn; 0.0052\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Pclass_Sex_Embarked_2femaleS\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.18%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0011\n",
       "                \n",
       "                    &plusmn; 0.0014\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Age\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0009\n",
       "                \n",
       "                    &plusmn; 0.0048\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Embarked_S\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0009\n",
       "                \n",
       "                    &plusmn; 0.0048\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Ticket_len_5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.04%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0011\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Ticket_len_6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.04%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0011\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Parch\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.04%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0018\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Pclass_Sex_Embarked_3maleC\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0002\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Pclass_Sex_Embarked_3femaleC\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0002\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                FamilySize\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Ticket_len_10\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Ticket_len_30\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0002\n",
       "                \n",
       "                    &plusmn; 0.0026\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                FareBin\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0002\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SibSp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.04%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0004\n",
       "                \n",
       "                    &plusmn; 0.0011\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Ticket_len_4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0007\n",
       "                \n",
       "                    &plusmn; 0.0046\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Pclass_Sex_Embarked_2maleS\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 97.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0016\n",
       "                \n",
       "                    &plusmn; 0.0064\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Embarked_C\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(tuned_L1_algs[2][1], random_state=1).fit(X_lc, y_lc)\n",
    "eli5.show_weights(perm, feature_names = X_lc.columns.tolist(), top = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x684 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(tuned_L1_algs[2][1])\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\n",
    "shap_values = explainer.shap_values(X_lc)\n",
    "\n",
    "# Make plot. Index of [1] is explained in text below.\n",
    "shap.summary_plot(shap_values[1], X_lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance analysis\n",
    "To understand what factors contribute to the survival rate in the Titanic event and their respective weight on the result, we ran PermutationImportance and generated a Shap value table for all feature with the best model observed in our Iteration 2 effort. \n",
    "\n",
    "From the PermutationImportance table we immediately see that Sex, Title and Pclass_Sex_Embarked are the top three features which have the most positive effect on the surival rate. On the other hands, we don't see too many features that contribute to the negative side of the surival rate. We evaluate this with our Shap chart and see the result being relatively consistent with the ranking we see in the PermutationImportance table with strong clustering, meaning that the conclusion we drew from the PermutationImportance table represents the norm of the data.\n",
    "\n",
    "Finally, we can say with confident that a passenger who is a female, in first class, and onboraded from Southampton has the best chance of suriving the Titanic disaster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
